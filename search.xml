<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>tinyfecvpn、tinyPortmapper、ss科学上网</title>
      <link href="/2019/09/29/tinyvpn%E3%80%81tinymapper%E3%80%81ss%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91/"/>
      <url>/2019/09/29/tinyvpn%E3%80%81tinymapper%E3%80%81ss%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91/</url>
      
        <content type="html"><![CDATA[<p>外面的世界很精彩，外面的世界很无奈。</p><a id="more"></a><!-- toc --><ul><li><a href="#tinyfecyvpn">tinyfecyvpn</a></li><li><a href="#tinyportmapper">tinyPortmapper</a></li><li><a href="#shadowsocks">shadowsocks</a></li><li><a href="#原理">原理</a></li><li><a href="#搭建tinyvpn">搭建tinyvpn</a><ul><li><a href="#服务端">服务端</a></li><li><a href="#客户端">客户端</a></li><li><a href="#效果测试">效果测试</a></li></ul></li><li><a href="#搭建tinyportmapper">搭建tinyPortmapper</a></li><li><a href="#搭建shadowsocks">搭建shadowsocks</a><ul><li><a href="#服务端-1">服务端</a></li><li><a href="#客户端-1">客户端</a></li><li><a href="#测试效果">测试效果</a></li></ul></li></ul><!-- tocstop --><h4><span id="tinyfecyvpn">tinyfecyvpn</span></h4><p>tinyfecyvpn主要是在两台机器相互之间网络很差的情况下使用，比如，一台是国外机器，一台是国内的，或者其他一些因素导致两端网络不稳定。此时tinyfecyvpn为两端建立一个vpn通道。再通过一些参数设置，可以轻易把网络丢包率降低到万分之一以下。</p><p><a href="https://github.com/wangyu-/tinyfecVPN" target="_blank" rel="noopener">tinfecyvpn  Github地址</a></p><p>可以直接看作者的github中文说明，已经很详细了。</p><h4><span id="tinyportmapper">tinyPortmapper</span></h4><p>主要负责端口和流量的转发，后面的搭建过程中我们就可以看到，tinyfecyvpn直接是UDP协议。而tinyPortmapper是TCP协议。</p><p><a href="https://github.com/wangyu-/tinyPortMapper" target="_blank" rel="noopener">tinyPortmapper Github地址</a></p><h4><span id="shadowsocks">shadowsocks</span></h4><p>我们最后实则需要使用到的FAN墙软件。搭建过程比较简单。分为客户端和服务端。原理其实就是我们通过客户端访问服务端这个软件，服务端再去访问我们想要的网站。服务端需要是国外服务器。</p><p><a href="https://github.com/shadowsocks/shadowsocks-windows" target="_blank" rel="noopener">shadowsocks-windows版本Github地址</a></p><p>注：linux版本通过命令安装，后续会讲。</p><h4><span id="原理">原理</span></h4><p><img src="/2019/09/29/tinyvpn、tinymapper、ss科学上网/vpn.png" alt></p><p>基本原理就如上图所示，然后这里说明一下：</p><p>为了方便，我这里用 </p><p><strong>1.1.1.1</strong> 替代 <strong>SS客户端IP</strong></p><p><strong>2.2.2.2</strong> 代替 <strong>国内转发服务器IP</strong></p><p><strong>3.3.3.3</strong> 代替 <strong>国外SS服务端IP</strong></p><p>在接下来需要使用到真实IP的地方，我都会使用以上对应的IP来代替。</p><p>SS是shadowsocks的简称，以下用SS来代替（防止和谐）。</p><h4><span id="搭建tinyvpn">搭建tinyvpn</span></h4><p>首先在国外我们需要作为SS服务端和国内转发端的服务器之间搭建tinyfecyvpn。也就是上面代替IP中的2.2.2.2和3.3.3.3之间搭建。</p><p><a href="https://github.com/wangyu-/tinyfecVPN" target="_blank" rel="noopener">tinfecyvpn  Github地址</a></p><p>从上面给的Github里下载tinyfecyvpn并解压：</p><p><img src="/2019/09/29/tinyvpn、tinymapper、ss科学上网/download_vpn.png" alt></p><p>这里面是有好多个版本的，这时候要看你要使用的机器是什么版本，我的机器是linux，系统是Centos7。可以通过在命令行里执行：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]# uname -m</span><br><span class="line">x86_64</span><br></pre></td></tr></table></figure><p>返回：x86_64。所以只使用上图中的tinyvpn_amd64这个文件就可以了。（这里我为了展示，所以使用windows的截图，软件使用过程中都是在centos7上面配置）</p><p><img src="/2019/09/29/tinyvpn、tinymapper、ss科学上网/vpn1.png" alt></p><p>如上图，我们先配置服务端，将”tinyvpn_amd64”拷贝到服务器上，查看一下默认是没有执行权限的，所以”chmod +x”一下，然后按照官方的文档运行。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]# chmod +x tinyvpn_amd64</span><br><span class="line">[root@localhost ~]# ./tinyvpn_amd64 -s -l0.0.0.0:4096 -f20:10 -k &quot;passwd&quot; --sub-net 10.22.22.0</span><br></pre></td></tr></table></figure><p>注意：这里我们是将这台作为服务端，也就是3.3.3.3这台。而tinyvpn服务端和客户端的命令参数是不一样的，下面放上官方给出的例子来进行对比。</p><table><thead><tr><th>服务端</th><th>./tinyvpn -s -l0.0.0.0:4096 -f20:10 -k “passwd” –sub-net 10.22.22.0</th></tr></thead><tbody><tr><td>客户端</td><td>./tinyvpn -c -r44.55.66.77:4096 -f20:10 -k “passwd” –sub-net 10.22.22.0</td></tr></tbody></table><h5><span id="服务端">服务端</span></h5><p>其中参数选项和参数之间是可以不存在空格的，就比如其中的”-l0.0.0.0:4096”，但是你写成”-l 0.0.0.0:4096”也是可以的。</p><table><thead><tr><th>-l0.0.0.0:4096</th><th>因为是服务端，0.0.0.0代表允许所有IP访问。端口号自定义</th></tr></thead><tbody><tr><td>-f20:10</td><td>表示对每20个原始数据发送10个冗余包。后期通过调整这个值来达到最佳效果</td></tr><tr><td>-k “passwd”</td><td>指定一个字符串，开启简单的异或加密</td></tr><tr><td>–sub-net 10.22.22.0</td><td>指定VPN的子网，格式为xxx.xxx.xxx.0</td></tr></tbody></table><p>注: 对于–sub-net 10.10.10.0, server的IP会被设置成10.10.10.1,client的IP会被设置成10.10.10.2 。按照我的理解，这里就相当于两台机器组成了一个内网。</p><p>从下图中我们看出端口和IP情况：</p><p><img src="/2019/09/29/tinyvpn、tinymapper、ss科学上网/vpn2.png" alt></p><h5><span id="客户端">客户端</span></h5><p><img src="/2019/09/29/tinyvpn、tinymapper、ss科学上网/vpn3.png" alt></p><p>客户端基本和服务端没有太大区别，记得参数改一下就好，我这里就没截图，使用一下以前的截图。</p><p>注意”-c -r IP”这里的IP要填你服务端的公网IP。比如我们的例子IP，那么这里就是要填”3.3.3.3”。</p><h5><span id="效果测试">效果测试</span></h5><p>我们先关闭tinyvpn。ping一下看看网络情况（这里直接ping服务端的公网IP，比如例子IP：3.3.3.3）：</p><p><img src="/2019/09/29/tinyvpn、tinymapper、ss科学上网/vpn4.png" alt></p><p>可以看到，因为是在国外，掉包率还是很高的。这样情况下操作服务器或者传输文件基本用起来是很痛苦。</p><p>然后再打开tinyvpn，ping一下看看网络情况（这里ping我们tinyvpn配置好的内网IP，也就是10.10.10.x。这里分清自己的IP是多少，然后ping另外一台IP测试就可以了。不要傻傻的ping自己的IP，那肯定是很稳定的…）</p><p><img src="/2019/09/29/tinyvpn、tinymapper、ss科学上网/vpn5.png" alt></p><p>我们看到效果好了不少。但还差一些。这时候就要调整上面的”-f20:10”参数了。根据实际情况来调整，注意x:y，x+y的值不能超过255即可。（早中晚的网络情况可能都稍有不同，然后你国外服务器的地理位置也有可能会影响）</p><p>我再调整参数的值（这个值意义不是特别清楚，网络方面的知识，官方也是一笔带过，总之多尝试吧），我这里是直接改到”100:150”，看下效果：</p><p><img src="/2019/09/29/tinyvpn、tinymapper、ss科学上网/vpn6.png" alt></p><p>基本不会掉包了。那么tinyvpn的搭建就算完成了。</p><p>注：</p><p>把程序后台运行输出到日志，例如通过”nohup”和”&amp;”：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]# /tinyvpn/tinyvpn_amd64 -s -l0.0.0.0:4096 -f100:150 -k tb123 --sub-net 10.22.22.0 &gt;&gt;/root/tinyvpn_output.log 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure><p>还有如果是云主机，记得在控制台开放安全组策略，也就是开放我们需要访问的端口</p><table><thead><tr><th>类型</th><th>测试端口开放情况命令</th></tr></thead><tbody><tr><td>TCP</td><td>telnet 1.1.1.1 4096</td></tr><tr><td>UDP</td><td>nc -vu 1.1.1.1 4096</td></tr></tbody></table><h4><span id="搭建tinyportmapper">搭建tinyPortmapper</span></h4><p>VPN隧道已经搭建完成，接下来就需要为转发服务器配置转发流量和端口了。（也就是在例子IP：2.2.2.2这台上完成）</p><p><a href="https://github.com/wangyu-/tinyPortMapper" target="_blank" rel="noopener">tinyPortmapper Github地址</a></p><p>一样的我们可以看到有几个版本，选择我们需要的版本上传到服务器就可以了：</p><p><img src="/2019/09/29/tinyvpn、tinymapper、ss科学上网/vpn7.png" alt></p><p>按照官方的命令，执行命令:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]#/usr/software/tinymapper_amd64 -l0.0.0.0:2333 -r10.22.22.1:18092 -t -u</span><br></pre></td></tr></table></figure><p>参数 -t 和 -u 代表 TCP和UDP流量都转发，具体可以查看最上面的官方说明。</p><p><img src="/2019/09/29/tinyvpn、tinymapper、ss科学上网/vpn8.png" alt></p><table><thead><tr><th>-l0.0.0.0:2333</th><th>0.0.0.0代表允许所有IP访问。端口号自定义，不存在冲突即可</th></tr></thead><tbody><tr><td>-r10.22.22.1:18092</td><td>10.22.22.1就是我们服务端的VPN IP。我们这台客户端的IP是10.22.22.2</td></tr></tbody></table><p>18092是我们指定服务端接收的端口号，程序正常启动后，可以在服务端通过”netstat -tunlp | grep 18092”查看。</p><p>我上面的输出是因为我已经用ss来连接了。如果你没有这么多输出，不用管，程序运行没有报错就好。扔到后台去运行，我们下面去配置ss。</p><h4><span id="搭建shadowsocks">搭建shadowsocks</span></h4><h5><span id="服务端">服务端</span></h5><p>ss我们需要一个客户端，一个服务端。客户端我们用自己电脑就好，总归是要上浏览器的。所以我们去官网下载windows版本的就好。<a href="https://github.com/shadowsocks/shadowsocks-windows" target="_blank" rel="noopener">shadowsocks-windows版本Github地址</a></p><p>不急着先配置windows的连接。打开ss的服务端，比如我们例子IP中的3.3.3.3这台。</p><p>因为这台是centos7的，我们直接命令行安装，需要安装pip（python提供的一种类似yum的仓库，解决各种依赖问题，然后再通过pip安装）</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]#yum install python-setuptools &amp;&amp; easy_install pip</span><br><span class="line">[root@localhost ~]#pip install shadowsocks</span><br><span class="line"><span class="meta">#</span>安装完查看一下是否成功</span><br><span class="line">[root@localhost ~]#whereis shadowsocks</span><br><span class="line">shadowsocks: /etc/shadowsocks.json_old /etc/shadowsocks.json~ /etc/shadowsocks.json /usr/local/shadowsocks</span><br></pre></td></tr></table></figure><p>然后编辑”<strong>/etc/shadowsocks.json</strong>“，这个是ss最重要的文件，如果没有，就新建一个名字相同的文件。下面是我的配置：</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    "server":"0.0.0.0",#表示所有IP可访问</span><br><span class="line">    "server_ipv6":"[::]",</span><br><span class="line">    "server_port":18092,#这里要记得和我们上面tinyPortmapper配置转发的端口保持一致</span><br><span class="line">    "local_address":"127.0.0.1",</span><br><span class="line">    "local_port":1092,</span><br><span class="line">    "password":"123456",#连接的密码</span><br><span class="line">    "timeout":120,</span><br><span class="line">    "method":"aes-256-cfb",#加密方式</span><br><span class="line">    "protocol":"origin",</span><br><span class="line">    "protocol_param":"",</span><br><span class="line">    "obfs":"plain",</span><br><span class="line">    "obfs_param":"",</span><br><span class="line">    "redirect":"",</span><br><span class="line">    "dns_ipv6":false,</span><br><span class="line">    "fast_open":false,</span><br><span class="line">    "workers":1</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>配置好后执行运行命令:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]#ssserver -c /etc/shadowsocks.json -d start</span><br><span class="line"><span class="meta">#</span>停止命令：</span><br><span class="line">[root@localhost ~]#ssserver -c /etc/shadowsocks.json -d stop</span><br></pre></td></tr></table></figure><p>如果报错，就好好检查一下”shadowsocks.json”文件。</p><h5><span id="客户端">客户端</span></h5><p><img src="/2019/09/29/tinyvpn、tinymapper、ss科学上网/ss1.png" alt></p><p>客户端安装好后，勾选启用代理，选择PAC模式。</p><p>然后再点击”系统代理模式”下方的”服务器”，编辑服务器。</p><p><img src="/2019/09/29/tinyvpn、tinymapper、ss科学上网/ss2.png" alt></p><p>这里填入我们转发服务器（例子IP中的2.2.2.2）的公网IP和tinyPortmapper设置的转发端口：</p><p><img src="/2019/09/29/tinyvpn、tinymapper、ss科学上网/ss3.png" alt></p><p>加密方式和密码，就是我们在ss服务器（例子IP中的3.3.3.3）上配置的”<strong>shadowsocks.json</strong>“文件。</p><p>到这里你应该大致明白了这一套流程下来，我们这么做的意义和方式了。</p><p>接下来配置好后就试试看能不能访问外面的世界吧！</p><h5><span id="测试效果">测试效果</span></h5><p><img src="/2019/09/29/tinyvpn、tinymapper、ss科学上网/goog.png" alt></p><p><u>外面的世界很精彩，外面的世界很无奈。</u></p>]]></content>
      
      
      <categories>
          
          <category> 科学上网 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tinyfecvpn </tag>
            
            <tag> tinyPortmapper </tag>
            
            <tag> shadowsocks </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>利用zabbix远程执行python脚本</title>
      <link href="/2019/09/27/%E5%88%A9%E7%94%A8zabbix%E8%BF%9C%E7%A8%8B%E6%89%A7%E8%A1%8Cpython%E8%84%9A%E6%9C%AC/"/>
      <url>/2019/09/27/%E5%88%A9%E7%94%A8zabbix%E8%BF%9C%E7%A8%8B%E6%89%A7%E8%A1%8Cpython%E8%84%9A%E6%9C%AC/</url>
      
        <content type="html"><![CDATA[<p>本文通过zabbix与python结合，实现对服务器上日志自动化的清理。</p><a id="more"></a><!-- toc --><ul><li><a href="#开启zabbix_agent端远程命令权限">开启zabbix_agent端远程命令权限</a></li><li><a href="#zabbix_get验证连通性">zabbix_get验证连通性</a></li><li><a href="#编写python脚本">编写python脚本</a></li><li><a href="#为触发器添加动作">为触发器添加动作</a></li><li><a href="#效果图">效果图</a></li></ul><!-- tocstop --><p>服务器其实最基本的问题就是容量的问题，秉承着，能不花钱就不花钱的理念。基本像web服务器，这种基本不占什么容量的服务来说，服务器的容量都很小。所以基本云主机都是买一个容量最小最便宜的放在线上。</p><p>不过一段时间下来，web产生的大量日志就是一个头疼的问题了。一共就那么几十G，再放上web程序，日志没几天就占满了磁盘空间。这些日志很多都不是那么重要的，基本是记录操作记录的信息，所以时间比较久远的日志参考意义就不大了，而且假如真的需要保存这些信息的话，其实已经可以通过elk采集到我们需要保存的服务器上进行备份。</p><h4><span id="开启zabbix_agent端远程命令权限">开启zabbix_agent端远程命令权限</span></h4><p>首先第一步就是要先开启agent端允许server端远程执行命令的权限。找到配置文件，每个人配置文件名称可能不通。我这里是windows主机，名称为：“zabbix_agentd.win.conf”。找到如下图这行：</p><p><img src="/2019/09/27/利用zabbix远程执行python脚本/agent_remote.png" alt></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">#默认0代表关闭，1为启用</span><br><span class="line">EnableRemoteCommands=1</span><br></pre></td></tr></table></figure><p>设置保存后，需要<strong>重启</strong>对应的agent端的zabbix服务才会生效。</p><h4><span id="zabbix_get验证连通性">zabbix_get验证连通性</span></h4><p>zabbix_get是zabbix官方提供的一个工具。将这个工具安装在server端，即可实现对agent端的数据采集。通过这个工具可以测试我们的配置是否有问题。<a href="https://www.zabbix.com/documentation/3.0/manpages/zabbix_get" target="_blank" rel="noopener">zabbix_get官方文档</a></p><p>如果没有安装该工具，通过yum或者下载镜像方式安装，yum安装：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install -y zabbix-get.x86_64</span><br></pre></td></tr></table></figure><p>安装完成后测试是否正常：</p><p><img src="/2019/09/27/利用zabbix远程执行python脚本/zabbix_get_v.png" alt></p><p>zabbix_get使用方法（直接引用官网文档，点击上面那个链接一样可以看到）：</p><p><strong>zabbix_get -s</strong> <em>host-name-or-IP</em> [<strong>-p</strong> <em>port-number<em>] [*</em>-I** <em>IP-address</em>] <strong>-k</strong> *item-key</em><br><strong>zabbix_get -s</strong> <em>host-name-or-IP</em> [<strong>-p</strong> <em>port-number<em>] [*</em>-I** <em>IP-address</em>] <strong>–tls-connect</strong> <strong>cert</strong> <strong>–tls-ca-file</strong> *CA-file</em> [<strong>–tls-crl-file</strong> <em>CRL-file<em>] [*</em>–tls-agent-cert-issuer** <em>cert-issuer</em>] [<strong>–tls-agent-cert-subject</strong> <em>cert-subject</em>] <strong>–tls-cert-file</strong> *cert-file</em> <strong>–tls-key-file</strong> <em>key-file</em> <strong>-k</strong> <em>item-key</em><br><strong>zabbix_get -s</strong> <em>host-name-or-IP</em> [<strong>-p</strong> <em>port-number<em>] [*</em>-I** <em>IP-address</em>] <strong>–tls-connect</strong> <strong>psk</strong> <strong>–tls-psk-identity</strong> *PSK-identity</em> <strong>–tls-psk-file*</strong>PSK-file* <strong>-k</strong> <em>item-key</em><br><strong>zabbix_get -h</strong><br><strong>zabbix_get -V</strong>  </p><p>我们刚才已经开启了agent端的远程执行功能，现在直接在server端测试一下：</p><p><img src="/2019/09/27/利用zabbix远程执行python脚本/zabbix_get.png" alt></p><p>这是一个获取所有cpu平均1分钟负载值的命令。看到我们已经返回了结果，证明连通正常，可以远程执行命令。</p><h4><span id="编写python脚本">编写python脚本</span></h4><p>完成上面两个步骤后，zabbix方面可以先放一放，因为这个才是我们最重要的步骤，编写python脚本。话不多说，直接先上脚本：</p><p><strong>注：本脚本在windows主机，python3的环境下运行。若为python2，脚本中的一些模块可能会运行报错，建议先测试一下正常后再使用。</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># encoding:utf-8</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">功能:</span></span><br><span class="line"><span class="string">1）判断文件/文件夹最后修改日期</span></span><br><span class="line"><span class="string">2）按照if语句删除（天数作为条件）</span></span><br><span class="line"><span class="string">说明：此脚本由内网40.17zabbix服务器触发触发器执行动作，远程执行</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">import</span> logging</span><br><span class="line"><span class="keyword">import</span> shutil</span><br><span class="line">logging.basicConfig(level=logging.INFO,</span><br><span class="line">                    filename=<span class="string">"C:/python/python_scripts/del_dir.log"</span> </span><br><span class="line">                    <span class="comment">#有了filename参数就不会直接输出显示到控制台，而是直接写入文件</span></span><br><span class="line">                    )</span><br><span class="line"></span><br><span class="line"><span class="comment">#定义删除文件夹的函数 del_directory(),参数my_path</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">del_directory</span><span class="params">(my_path)</span>:</span></span><br><span class="line"><span class="comment">#定义日期时间格式</span></span><br><span class="line">format=<span class="string">'%Y-%m-%d'</span></span><br><span class="line"><span class="comment">#获取当前的时间转换成字符串格式</span></span><br><span class="line">current_time=str(time.strftime(format,time.localtime()))</span><br><span class="line"><span class="comment">#删除时间，方便日志查看</span></span><br><span class="line">del_time=time.strftime(<span class="string">"%Y-%m-%d %H:%M:%S"</span>,time.localtime())</span><br><span class="line"><span class="comment">#遍历目标路径下的文件夹</span></span><br><span class="line"><span class="keyword">for</span> d_f_name <span class="keyword">in</span> os.listdir(my_path):</span><br><span class="line"><span class="comment">#获取文件绝对路径</span></span><br><span class="line">full_dirct_path=os.path.join(my_path,d_f_name)</span><br><span class="line"><span class="comment">#获取文件最后修改时间</span></span><br><span class="line">modifiedTime=time.localtime(os.stat(full_dirct_path).st_mtime)</span><br><span class="line">mTime=str(time.strftime(format,modifiedTime))</span><br><span class="line"><span class="comment">#判断修改日期距离今天为止的间隔时间（天）</span></span><br><span class="line">interval_time=datetime.datetime.strptime(current_time,format) - datetime.datetime.strptime(mTime,format)</span><br><span class="line"><span class="comment">#判断修改日期距离今天是否大于x天</span></span><br><span class="line"><span class="keyword">if</span> interval_time.days &gt; <span class="number">5</span>:</span><br><span class="line"><span class="comment">#判断是否为文件夹</span></span><br><span class="line"><span class="keyword">if</span> os.path.isdir(full_dirct_path):</span><br><span class="line"><span class="comment">#删除非空文件夹 注：直接删除整个非空文件夹</span></span><br><span class="line">shutil.rmtree(full_dirct_path)</span><br><span class="line">logging.info(del_time+<span class="string">" 已成功删除[目录]: "</span>+full_dirct_path)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line"><span class="comment">#删除文件</span></span><br><span class="line">os.remove(full_dirct_path)</span><br><span class="line">logging.info(del_time+<span class="string">" 已成功删除_文件_: "</span>+full_dirct_path)</span><br><span class="line"></span><br><span class="line">del_directory(<span class="string">'D:\\wwwlog\\commctrl\\dir1\\'</span>)</span><br><span class="line">del_directory(<span class="string">'D:\\wwwlog\\dir2\\'</span>)</span><br></pre></td></tr></table></figure><p>基本上面每一步的作用，我都有在注释里面标注了。主要是运用几个模块，定义了一个删除文件和目录的函数。最后再实例化。</p><p>唯一需要注意的是最下面实例化，添加路径的时候，一定要写对绝对路径，不要删错文件就好。</p><p>编写完毕测试正常后，我们把脚本放在一个目录下，我这里放在“C:/python/python_scripts/del_dir_20.py”</p><h4><span id="为触发器添加动作">为触发器添加动作</span></h4><p>首先要在zabbix web的界面建好我们的触发器（我这边已经建好了，是一个D盘容量小于百分之5就触发的报警）：</p><p><img src="/2019/09/27/利用zabbix远程执行python脚本/triggers.png" alt></p><p>触发器好了以后，我们为触发器添加一个动作，configuration-&gt;Actions-&gt;Event source(选择Triggers)-&gt;Create action。因为我们想要触发触发器后执行脚本，所以创建动作时，选择Triggers。</p><p><img src="/2019/09/27/利用zabbix远程执行python脚本/create_action.png" alt></p><p>填入名称，增加触发器：</p><p><img src="/2019/09/27/利用zabbix远程执行python脚本/create1.png" alt></p><p>选择对应的触发器：</p><p><img src="/2019/09/27/利用zabbix远程执行python脚本/create2.png" alt></p><p>选择完一定要记得点击“add”，如果没有“add”，触发器是没有添加上去的：</p><p><img src="/2019/09/27/利用zabbix远程执行python脚本/create3.png" alt></p><p>最后的状态：</p><p><img src="/2019/09/27/利用zabbix远程执行python脚本/create4.png" alt></p><p>下面也是比较关键的一步，添加我们的动作内容，点击Action旁边的Operations:</p><p><img src="/2019/09/27/利用zabbix远程执行python脚本/create5.png" alt></p><p>每步的步骤的作用都有详细说明了，单机图片可放大查看。</p><p>Target list的部分忘记标注了，这里记得新建一个把我们要执行脚本的主机添加进来，选择host-&gt;选择主机：</p><p><img src="/2019/09/27/利用zabbix远程执行python脚本/create6.png" alt></p><hr><h4><span id="效果图">效果图</span></h4><p>以上一切做好后，就可以静静的等待触发器被触发，自动远程执行我们的python脚本了。</p><p>如果报警触发，我们可以在Reports-&gt;Action log中查看我们的动作详情，我们看到触发器触发后，自动就恢复了，不需要人工参与：</p><p><img src="/2019/09/27/利用zabbix远程执行python脚本/report1.png" alt></p><p>如果想看什么时间都删除了哪些文件，可以看看在目标服务器上，我们利用python输出的日志内容：</p><p><img src="/2019/09/27/利用zabbix远程执行python脚本/del_log.png" alt></p>]]></content>
      
      
      <categories>
          
          <category> zabbix </category>
          
      </categories>
      
      
        <tags>
            
            <tag> zabbix </tag>
            
            <tag> python </tag>
            
            <tag> 自动化运维 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>利用性能分析工具sar、iotop对linux服务器高负载问题排查</title>
      <link href="/2019/09/25/%E5%88%A9%E7%94%A8%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E5%B7%A5%E5%85%B7sar%E3%80%81iotop%E5%AF%B9linux%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%AB%98%E8%B4%9F%E8%BD%BD%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5/"/>
      <url>/2019/09/25/%E5%88%A9%E7%94%A8%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E5%B7%A5%E5%85%B7sar%E3%80%81iotop%E5%AF%B9linux%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%AB%98%E8%B4%9F%E8%BD%BD%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5/</url>
      
        <content type="html"><![CDATA[<p>sar、iotop的使用。</p><a id="more"></a><!-- toc --><ul><li><a href="#1sar的使用">1.sar的使用</a><ul><li><a href="#11-iostat">1.1 iostat</a></li></ul></li><li><a href="#2iotop">2.iotop</a></li></ul><!-- tocstop --><p>工作中我们有时候会遇到一些服务器性能上的问题。比如：内存不足、io等待时间过长、cpu使用率高等等等等。其实原本这些东西在我们服务器上线之前就应该经过压力测验了，所以不管是云服务器还是实体机，最开始的配置其实还是可以满足实际业务需求的。</p><p>但是随着机器年限的提升，为了节约成本或者一些新的需求，又或者是长时间运行，一些问题还是会暴露出来。</p><p>这几天工作中同事经常会和我说一台linux的服务器cpu负载偶尔会变得很高。</p><p>这里说下这台服务器的配置：</p><table><thead><tr><th>说明</th><th>详细</th></tr></thead><tbody><tr><td>系统</td><td>centos7</td></tr><tr><td>性质</td><td>腾讯云主机</td></tr><tr><td>内存</td><td>4G</td></tr><tr><td>物理CPU个数</td><td>1</td></tr><tr><td>CPU核数</td><td>2</td></tr><tr><td>逻辑CPU个数（即物理CPU个数×核数）</td><td>2</td></tr></tbody></table><p>因为是用作web网站的，基本不太需要很大的资源，这样配置的主机已经是够了的。</p><p>我们先从zabbix报警的图形中看一下cpu负载的状况：</p><p><img src="/2019/09/25/利用性能分析工具sar、iotop对linux服务器高负载问题排查/cpu_load.png" alt></p><p>从上图可以看出，1分钟的平均负载已经达到了5，5分钟的平均负载则达到了2.0多，15分钟的负载就相对正常。如果这样看还好，只是短暂的负载飙升。这个值的正常大小主要取决于你的CPU逻辑个数。即，不超过2以上系统就基本没啥问题正常运行。一旦超过这个最大值以后，其实你的系统会变得非常的卡，就好比我们用windows时，鼠标直接都没办法移动的这种情况。这种情况下，web服务器基本属于宕机状态，是没办法为客户提供服务的。虽说偶尔才会出现，而且每次的影响也就是十几个连接超时。但我们遇到问题，还是要先排查一下，排查的过程中还是可以学习到非常多的知识的。</p><p>虽然linux自带的top命令一样可以查看关于各类报告的数值，但是比较局限，一是不能按时间戳查看（比如想看昨天的，或者统计数据），二是也无法对数据进行细化查看（查看到底是哪个进程，或者占用比例）。</p><p>所以我们使用以下两种软件来达到我们的目的：sar和iotop</p><h4><span id="1sar的使用">1.sar的使用</span></h4><p>sar，全称：”System Activity Reporter” ，直译就是：系统活动情况报告。例如：文件读写情况报告、CPU效率报告、内存使用情况报告、磁盘I/O报告等。</p><p>安装我们使用yum方式安装，保证镜像源可用后直接输入</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@padim ~]#yum -y install sysstat</span><br></pre></td></tr></table></figure><p>开箱即用，先输入”sar –help”查看一下是否安装正常，并且查看可用的参数，如下图：</p><p><img src="/2019/09/25/利用性能分析工具sar、iotop对linux服务器高负载问题排查/sar_help.png" alt></p><p>以下列出一些常用的参数详解：</p><table><thead><tr><th>参数选项</th><th>参数说明</th></tr></thead><tbody><tr><td>-A</td><td>所有报告的总和</td></tr><tr><td>-u</td><td>输出<a href="http://lovesoo.org/tag/cpu" target="_blank" rel="noopener">CPU</a>使用情况的统计信息</td></tr><tr><td>-v</td><td>输出inode、文件和其他内核表的统计信息</td></tr><tr><td>-d</td><td>输出每一个块设备的活动信息</td></tr><tr><td>-r</td><td>输出<a href="http://lovesoo.org/tag/内存" target="_blank" rel="noopener">内存</a>和交换空间的统计信息</td></tr><tr><td>-b</td><td>显示<a href="http://lovesoo.org/tag/io" target="_blank" rel="noopener">I/O</a>和传送速率的统计信息</td></tr><tr><td>-a</td><td>文件读写情况</td></tr><tr><td>-c</td><td>输出进程统计信息，每秒创建的进程数</td></tr><tr><td>-R</td><td>输出内存页面的统计信息</td></tr><tr><td>-y</td><td>终端设备活动情况</td></tr><tr><td>-w</td><td>输出系统交换活动信息</td></tr></tbody></table><p>因为我们想看CPU相关的信息，直接输入：”sar -u”，找到我们监控对应的上午08:30分左右，如下图：</p><p><img src="/2019/09/25/利用性能分析工具sar、iotop对linux服务器高负载问题排查/sar_u.png" alt></p><p>太好了，果然08:30跟其他的凡夫俗子不一样啊。很突出的彰显着自己的王霸之气。可以看到%iowait比其他的高出非常多。已经达到了百分之10+。</p><p>说实话我对iowait理解也不是特别透彻，比较浅显的理解就是，系统在做io，进程在等到io完成。所以此时进程是不工作的，如果iowait值很大，那么进程的等待时间就越长，所以进程等待这么长的时间，换谁也坐不住了，生命就这样流逝啊。</p><p>知道了可能是iowait的问题后，那么可以查看是哪些进程在做IO导致系统在等待。</p><h5><span id="11-iostat">1.1 iostat</span></h5><p>sysstat包下还有一个iostat的软件，iostat是专门来查看io相关信息的软件，有如下几个参数：</p><table><thead><tr><th>参数选项</th><th>参数说明</th></tr></thead><tbody><tr><td>-c</td><td>仅显示CPU使用情况</td></tr><tr><td>-d</td><td>仅显示设备利用率</td></tr><tr><td>-k</td><td>显示状态以千字节每秒为单位，而不适用块每秒</td></tr><tr><td>-m</td><td>显示状态以兆字节每秒为单位</td></tr><tr><td>-p</td><td>仅显示块设备和所有被使用的其他分区的状态</td></tr><tr><td>-t</td><td>显示每个报告产生时的时间</td></tr><tr><td>-V</td><td>显示版号并退出</td></tr><tr><td>-x</td><td>显示扩展状态</td></tr></tbody></table><p>我们使用一个”-t”的参数看下效果，如下图：</p><p><img src="/2019/09/25/利用性能分析工具sar、iotop对linux服务器高负载问题排查/iostat_t.png" alt></p><p>各属性说明：</p><table><thead><tr><th>属性</th><th>属性说明</th><th>备注</th></tr></thead><tbody><tr><td>%user</td><td>CPU处在用户模式下的时间百分比</td><td></td></tr><tr><td>%nice</td><td>CPU处于带NICE值的用户模式下的时间百分比</td><td></td></tr><tr><td>%system</td><td>CPU处于系统模式下的时间百分比</td><td></td></tr><tr><td>%iowait</td><td>CPU等待输入输出完成时间的百分比</td><td>如果%iowait值过高，表示硬盘存在I/O瓶颈</td></tr><tr><td>%steal</td><td>管理程序维护另一个虚拟处理器时，虚拟CPU的无意识等待时间百分比</td><td></td></tr><tr><td>%idle</td><td>CPU空闲时间百分比</td><td><strong>1）</strong>如果%idle值持续低于10，表明CPU处理能力相对较低，系统中最需要解决的资源是CPU。<strong>2）</strong>如果%idle值高，表示CPU较空闲。<strong>3）</strong>如果%idle值高但系统响应慢时，可能是CPU等待分配内存，应加大内存容量</td></tr><tr><td>tps</td><td>该设备每秒的传输次数</td><td></td></tr><tr><td>kB_read/s</td><td>每秒从设备读取的数据量</td><td></td></tr><tr><td>kB_wrtn/s</td><td>每秒从设备写入的数据量</td><td></td></tr><tr><td>kB_read</td><td>读取的数据总量</td><td></td></tr><tr><td>kB_wrtn</td><td>写入的数据总量</td><td></td></tr></tbody></table><p>如果你对top很熟悉，那么上面的输出内容基本也是看得懂的。基本可以看出，是vda这块盘的读写量很大。但是不能细化到是哪个进程。这时候就要用到下面所说的”iotop”了。</p><h4><span id="2iotop">2.iotop</span></h4><p>iotop和top名字很像，也是可以动态监视并查看系统状态的工具，是用python来编写的。</p><p>安装iotop我们也是使用yum方式安装：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@padim ~]#yum -y install iotop</span><br></pre></td></tr></table></figure><p>iotop参数说明：</p><table><thead><tr><th>参数选项</th><th>参数说明</th></tr></thead><tbody><tr><td>–version</td><td>表示显示版本号</td></tr><tr><td>-h</td><td>–help 表示显示帮助信息</td></tr><tr><td>-o，–only</td><td>表示显示进程或者线程实际上正在做的I/O，而不是全部的，可以随时切换按o</td></tr><tr><td>-b，–batch</td><td>表示运行在非交互式的模式</td></tr><tr><td>-n，NUM, –iter=NUM</td><td>表示在非交互式模式下，设置显示的次数</td></tr><tr><td>-d，SEC, –delay=SEC</td><td>表示设置显示的间隔秒数</td></tr><tr><td>-p，PID, –pid=PID</td><td>表示显示指定PID的信息</td></tr><tr><td>-u，USER, –user=USER</td><td>表示显示指定用户的进程信息</td></tr><tr><td>-P，–processes</td><td>表示只显示进程信息</td></tr><tr><td>-a，–accumulated</td><td>表示显示从iotop启动后每个线程完成了的IO总数</td></tr><tr><td>-k，–kilobytes</td><td>表示以千字节显示</td></tr><tr><td>-t，–time</td><td>表示在每一行前添加一个当前的时间</td></tr></tbody></table><p>我们输入”iotop -oPa”来查看当前服务器上运行的程序的I/O情况：</p><p><img src="/2019/09/25/利用性能分析工具sar、iotop对linux服务器高负载问题排查/iotop.png" alt></p><p>可以通过键盘左右键选则，选中想要排序的项目对其进行排序查看。这里我选中磁盘的写操作排序。</p><p>可以看到第一行是一个名为”systemd-journald”的命令。该命令是linux系统自带的系统服务。第二行是www用户运行的一个node脚本。</p><p>因为我们之前使用过命令iostat查看过%user和%system的情况。%user占用的比例是比%system高的。所以非常有可能的是当时占用cpu资源的是user用户执行的程序，如下图（之前iostat查看到的信息）：</p><p><img src="/2019/09/25/利用性能分析工具sar、iotop对linux服务器高负载问题排查/iostat_t2.png" alt></p><p>所以到这里我们猜测，可能是node这个脚本，存在着较大的读写操作，导致服务器iowait变长，从而增加了CPU的负载值。</p><p>那其实到底是不是…还需要来看看这个js脚本。这时候需要呼叫开发小哥了。然后其他的进程也去网上百度一下，搜搜看哪里是不是需要优化的地方。改完以后再去观察监控，看是不是还会出现之前的问题。</p><p>不过说到底不管是不是，我们至少学会了如何使用sar和iotop去查找问题的根源。在这方面自己也是还算个新手，如果有不对的地方，希望大家指出。</p>]]></content>
      
      
      <categories>
          
          <category> linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> sar </tag>
            
            <tag> iotop </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>还能欢笑如此吗</title>
      <link href="/2019/09/21/%E8%BF%98%E8%83%BD%E6%AC%A2%E7%AC%91%E5%A6%82%E6%AD%A4%E5%90%97/"/>
      <url>/2019/09/21/%E8%BF%98%E8%83%BD%E6%AC%A2%E7%AC%91%E5%A6%82%E6%AD%A4%E5%90%97/</url>
      
        <content type="html"><![CDATA[<div id="hbe-security">  <div class="hbe-input-container">  <input type="password" class="hbe-form-control" id="pass" placeholder="抱歉，此文暂时不对外开放.">    <label for="pass">抱歉，此文暂时不对外开放.</label>    <div class="bottom-line"></div>  </div></div><div id="decryptionError" style="display:none;">Incorrect Password!</div><div id="noContentError" style="display:none;">No content to display!</div><div id="encrypt-blog" style="display:none">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</div><script src="/lib/crypto-js.js"></script><script src="/lib/blog-encrypt.js"></script><link href="/css/blog-encrypt.css" rel="stylesheet" type="text/css">]]></content>
      
      
      
        <tags>
            
            <tag> Ref:rain </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>多端更新hexo博客</title>
      <link href="/2019/09/21/%E5%A4%9A%E7%AB%AF%E6%9B%B4%E6%96%B0hexo%E5%8D%9A%E5%AE%A2/"/>
      <url>/2019/09/21/%E5%A4%9A%E7%AB%AF%E6%9B%B4%E6%96%B0hexo%E5%8D%9A%E5%AE%A2/</url>
      
        <content type="html"><![CDATA[<p>正义的键盘侠，不能对这个悲惨的世界坐视不管！</p><a id="more"></a><!-- toc --><ul><li><a href="#1把本地hexo代码上传到github">1.把本地hexo代码上传到github</a><ul><li><a href="#11-git文件夹的删除">1.1 .git文件夹的删除</a></li><li><a href="#12上传需要的文件夹">1.2上传需要的文件夹</a><ul><li><a href="#121添加远程仓库">1.2.1添加远程仓库</a></li><li><a href="#122上传文件夹到仓库">1.2.2上传文件夹到仓库</a></li></ul></li></ul></li><li><a href="#2clone仓库代码到新机器上继续使用">2.clone仓库代码到新机器上继续使用</a></li></ul><!-- tocstop --><p>在公司的电脑上部署了hexo，想要家里也可以更新。就想着把整个文件夹上传到github或者coding上面，再clone下来更新。其中还是遇到蛮多坑的。主要还是hexo框架的问题。还有git这个工具其实单独拿出来就可以写好几篇教程，本文对git部分稍微介绍，只列出此过程中使用到的git命令。</p><h4><span id="1把本地hexo代码上传到github">1.把本地hexo代码上传到github</span></h4><p>首先先把本地正常运行的hexo框架上传到github上面去。（原本想上传到coding，但是不知道coding抽什么风，直接不通。难怪有时候访问网站时都超时（网站访问的源是coding的仓库），国内这个做的还是稍微差点）</p><p>这里有几个需要注意的地方：</p><p>1）git文件夹的问题</p><p>2）上传的文件夹中需要剔除的部分，通过.gitignore文件</p><p>3）已经下载过的第三方插件问题（在最后面clone到本地时再说）</p><p>那么接下来一个个来说。</p><h5><span id="11-git文件夹的删除">1.1 .git文件夹的删除</span></h5><p><img src="/2019/09/21/多端更新hexo博客/git.png" alt></p><p>如上图，git是不支持嵌套的，这就意味着，假如我在A文件夹中初始化了本地仓库git，想要上传A仓库中所有的文件夹包括其中的B文件夹，但是B文件夹我们看到也是存在git仓库的。所以这时候我们去上传文件夹时，B文件夹中的内容是不能被上传的。</p><p>所以我们使用hexo时，像themes中我们下载的next主题是从github上面下载来的，所以里面会自带一个.git文件夹。所以我们要把所有的.git文件夹删除才行。</p><p><strong><img src="/2019/09/21/多端更新hexo博客/delgit.png" alt></strong></p><p>我们平时使用hexo部署时，上传到github或者coding的文件夹里面只是包含我们使用hexo编译生成的静态页面，其中是没有我们的主题、配置文件、插件等等的文件的。我们可以看一下仓库里面的文件夹：</p><p><img src="/2019/09/21/多端更新hexo博客/gitdir.png" alt></p><p>我们本地所有的文件：</p><p><img src="/2019/09/21/多端更新hexo博客/hexodir.png" alt></p><p>其实我们上传到仓库的代码仅仅是上图中.deploy_git中的部署文件，点开就可以看到。public是hexo引擎编译生成的静态页面文件。</p><h5><span id="12上传需要的文件夹">1.2上传需要的文件夹</span></h5><p>我们可以在文件夹中找到一个名为”.gitignore”的文件，此文件是为了在git push过程中过滤掉不需要的文件，下面贴出我的这个文件的内容：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">.DS_Store</span><br><span class="line">Thumbs.db</span><br><span class="line">db.json</span><br><span class="line">*.log</span><br><span class="line">node_modules/</span><br><span class="line">public/</span><br><span class="line">.deploy*/</span><br><span class="line">/.deploy_git</span><br><span class="line">/public</span><br></pre></td></tr></table></figure><p>我这里除了一些默认的文件以外，还在末尾加上了：/.deploy_git和/public。这是为了不包含这两个文件夹。这两个文件夹我们是不需要的。</p><p>然后就可以初始化本地文件夹：git init 。文件夹中出现.git文件夹即可。</p><h6><span id="121添加远程仓库">1.2.1添加远程仓库</span></h6><p>在github新建一个仓库，设为私有，名字随意，清晰就好。</p><p>打开git bash：</p><p>1)测试连通性：ssh -T <a href="mailto:git@github.com" target="_blank" rel="noopener">git@github.com</a></p><p><img src="/2019/09/21/多端更新hexo博客/ssh_test.png" alt></p><p>2)添加远程仓库</p><p><img src="/2019/09/21/多端更新hexo博客/ssh2.png" alt></p><p>git remote add <em>仓库名 git地址</em></p><p>git remote -v :查看已经添加的远程仓库地址</p><h6><span id="122上传文件夹到仓库">1.2.2上传文件夹到仓库</span></h6><p>1) git add .    #注意后面的 “.” ，代表当前文件夹中所有文件。</p><p>2)git commit -m “说明”   #提交到本地仓库，说明随意。</p><p>3)git push -u <em>仓库名 分支</em>    #推送到远程仓库地址，仓库名要对应你上面添加的远程仓库名，分支默认是master，你也可以推送到其他分支，根据实际情况而定。</p><p><img src="/2019/09/21/多端更新hexo博客/ssh3.png" alt></p><p> 我已经推送过一次了，所以这里就简单演示一下。如果你第一次推送，会打印非常多的信息，只要没报错就万事大吉了。我的远程库名字为”github”，这里要看你自己的远程库起的名字是什么，对应替换就可以了。</p><p>这时候我们打开github的仓库进行查看，就可以看到我们推送上来所有我们需要在另外一台电脑使用的文件夹了。</p><p><img src="/2019/09/21/多端更新hexo博客/gitdir2.png" alt></p><h4><span id="2clone仓库代码到新机器上继续使用">2.clone仓库代码到新机器上继续使用</span></h4><p>如果你是自己部署搭建的hexo环境的话，那么接下来问题就不大了。同样的遵循以下几个步骤：</p><p>1)新机添加ssh秘钥，github或coding上面添加公钥</p><p>2)测试连通性确保链接正常</p><p>3)新机下载安装   <a href="https://nodejs.org/en/" target="_blank" rel="noopener">node官网下载地址</a>        #cmd中使用 node -v 检验是否安装成功</p><p>4)新机下载安装   <a href="https://gitforwindows.org/" target="_blank" rel="noopener">git windows版本官网下载地址</a>  #同样cmd中 git –version检测。或者在菜单栏中能看到新安装的git bash就可以了</p><p> 5)安装hexo框架（切换到你要保存的目录右键选择”Git Bash here”）：npm install hexo –save</p><p> <img src="/2019/09/21/多端更新hexo博客/gitbash.png" alt></p><p>6)克隆远程仓库代码到本地</p><p><img src="/2019/09/21/多端更新hexo博客/gitclone.png" alt></p><p>看到我们需要的都在这里了：</p><p><img src="/2019/09/21/多端更新hexo博客/gitclone2.png" alt></p><p>我们先尝试 hexo g 看看编译会不会出错，果然出错了，一开始还算顺利，但是到后面提示我们有个文件找不到：</p><p><img src="/2019/09/21/多端更新hexo博客/error1.png" alt></p><p>这里的”calendar.swing”是因为我的博客中有使用了一些网上写好的插件，如提交日历插件、加载动画插件、官方提供的动态背景插件等等。</p><p>我们顺着路径去找：/themes/next/source/lib</p><p>发现路径下竟然是空的，因为之前是安装官方的文档，把几个插件下载在这个文件夹中，不知道为什么git过程中这几个文件夹没有上传上去。原本这几个文件夹中因为是git clone下来的，所以是带有”.git”文件夹，但是我删除后，再上传，这几个文件夹还是空的。</p><p>不过不是很重要，这几个文件很小，我们直接从公司的电脑复制这几个文件夹到我们家里的电脑相对应的路径中就可以了。</p><p><img src="/2019/09/21/多端更新hexo博客/error2.png" alt></p><p>然后再次编译：</p><p><img src="/2019/09/21/多端更新hexo博客/error3.png" alt></p><p>没有错误了。大功告成，再在本地”hexo s”启动一下试试，访问本地”localhost:4000”:</p><p><img src="/2019/09/21/多端更新hexo博客/end.png" alt></p><p>一切正常。终于可以在家更新博客了。不容易啊。因为其他配置都是原先那台电脑的，所以也不用更改任何东西。一样的”hexo d”部署就可以了。</p><p>不过想要实现电脑和家中的所有配置文件，文章等等都是同步的，那么还是需要借助git仓库，每次更新完文章，或者更改配置后，都要去git push和git pull保持多端同步的状态。</p><p>更多git使用教程后续：</p><p><a href>git使用教程(待更新)</a></p>]]></content>
      
      
      <categories>
          
          <category> hexo </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hexo </tag>
            
            <tag> git </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ansible批量添加用户及配置用户秘钥</title>
      <link href="/2019/09/12/ansible%E6%89%B9%E9%87%8F%E6%B7%BB%E5%8A%A0%E7%94%A8%E6%88%B7%E5%8F%8A%E9%85%8D%E7%BD%AE%E7%94%A8%E6%88%B7%E7%A7%98%E9%92%A5/"/>
      <url>/2019/09/12/ansible%E6%89%B9%E9%87%8F%E6%B7%BB%E5%8A%A0%E7%94%A8%E6%88%B7%E5%8F%8A%E9%85%8D%E7%BD%AE%E7%94%A8%E6%88%B7%E7%A7%98%E9%92%A5/</url>
      
        <content type="html"><![CDATA[<p>使用自动化运维工具 ansible 为多台服务器添加用户，并配置秘钥。</p><a id="more"></a><!-- toc --><ul><li><a href="#1ansible简介">1.ansible简介</a></li><li><a href="#2ansible安装及基本文件配置">2.ansible安装及基本文件配置</a><ul><li><a href="#21-hosts文件配置">2.1 hosts文件配置</a></li><li><a href="#22-ansiblecfg文件配置">2.2 ansible.cfg文件配置</a></li></ul></li><li><a href="#3编写playbook">3.编写playbook</a><ul><li><a href="#31-adduseryaml">3.1 adduser.yaml</a></li><li><a href="#32-deluseryaml">3.2 deluser.yaml</a></li><li><a href="#33关于模块">3.3关于模块</a></li></ul></li></ul><!-- tocstop --><h4><span id="1ansible简介">1.ansible简介</span></h4><p>ansible是一款基于python编写的自动化运维工具，多应用的场景是需要批量统一操作，类似：为多台服务器增加指定用户；更改多台服务器上某一配置文件；为多台服务器安装应用程序等等。</p><p>试想，如果是只有3台服务器，那么还好办，用xshell这类的远程工具，一台台远程过去操作就好。但是如果有30台，300台，光是想想这个数量就难免让人沮丧了。</p><p>其实市面上有很多款类似的开源软件。这里说下ansible的优缺点。</p><p>优点：</p><p>​            （1）python语言开发（意味着基本不需要搭建语言环境，开箱即用，因为大多，像red hat的centos系列装机都是自带python2.7版本的）</p><p>​            （2）基于ssh远程连接执行命令（也就意味着不需要在远程主机上安装任何代理端）</p><p>​            （3）使用YAML语法（学习简单，yaml配置文件格式清晰）</p><p>​            （4）内置模块（模块后面的配置会接触到。这里记住模块是<strong>幂等性</strong>的就可以了。幂等性举个例子就是：你在一台机器上创建用户“user01”，如果“user01”不存在，则创建他，如果“user01”存在，ansible就不会做任何事情。所以在同一台机器上执行同一个ansible playbook是安全的）</p><p>缺点：</p><p>​            （1）无web界面（其实是有<a href="https://www.ansible.com/products/tower" target="_blank" rel="noopener">ansible tower</a>可以使用的。但是据说是商业版才有的，暂时没有深入了解）</p><p>​            （2）因内置模块的特殊性，即使是简单任务也是要花一些时间来编写playbook的（其实熟悉了以后很快，重点还是前期的学习过程）</p><p>​            （3）速度中等（因为不是多通道执行任务，一个任务执行成功返回结果后才执行下一个任务）</p><p>注：上面有提到playbook，这里简单说下。直接使用ansible+命令是可以对目标主机进行操作的。但是如果命令很多，比如要先增加user01，然后为他分配组，为他增加ssh秘钥。一条一条输入显然不现实。而playbook就相当于ansible的剧本，将所有的步骤写在playbook中一次性去执行。</p><h4><span id="2ansible安装及基本文件配置">2.ansible安装及基本文件配置</span></h4><p>ansible的安装很简单，可以通过yum方式安装。这里可以参考官网文档：<a href="https://docs.ansible.com/" target="_blank" rel="noopener">docs.ansible.com</a></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@padim ~]#yum install ansible</span><br></pre></td></tr></table></figure><p>还可以通过github下载安装等等方式。</p><p>使用yum方式安装后，默认安装目录是在<strong>/etc/ansible/</strong>下。</p><h5><span id="21-hosts文件配置">2.1 hosts文件配置</span></h5><p>这里的hosts不是linux主机上的hosts文件。是指ansible安装目录下的hosts文件，这个hosts文件就是来规定你连接的主机ip，或者主机群组的。默认位置在下面要说到的 ansible.cfg 中指定。我这里的位置是：/etc/ansible/playbooks/hosts</p><p>下面举个hosts文件的例子：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[nginx]</span><br><span class="line">192.168.40.10</span><br><span class="line">192.168.40.11</span><br><span class="line">[mysql]</span><br><span class="line">192.168.40.20</span><br><span class="line">192.168.40.21</span><br><span class="line">[all]</span><br><span class="line">192.168.40.10</span><br><span class="line">192.168.40.11</span><br><span class="line">192.168.40.20</span><br><span class="line">192.168.40.21</span><br></pre></td></tr></table></figure><h5><span id="22-ansiblecfg文件配置">2.2 ansible.cfg文件配置</span></h5><p>首先配置ansible.cfg文件，相当于整个程序的默认启动配置文件。下面是我的配置：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[defaults]</span><br><span class="line">inventory       =/etc/ansible/playbooks/hosts</span><br><span class="line">remote_user     =root</span><br><span class="line">private_key_file=/root/.ssh/my_private</span><br><span class="line">host_key_checking=False</span><br></pre></td></tr></table></figure><p>如果不在这里配置的话，等要写playbook时，是需要再配置的。所以我们这里进行默认的统一配置，有非常多可以增加的项目。这里只说明，如何使用本地的私钥来连接目标服务器上的公钥。（几台服务器上的公钥都是统一的，相当于一把钥匙开好几个锁）</p><table><thead><tr><th>参数选项</th><th>参数说明</th></tr></thead><tbody><tr><td>inventory</td><td>指定hosts文件的路径</td></tr><tr><td>remote_user</td><td>远程连接使用的用户名，此处为root</td></tr><tr><td>private_key_file</td><td>私钥文件路径</td></tr><tr><td>host_key_checking</td><td>首次连接会提示输入yes来确认连接主机。这里选择False来关闭这个提示。</td></tr></tbody></table><h4><span id="3编写playbook">3.编写playbook</span></h4><p>playbook就是ansible的剧本，也是使用ansible中最重要的一环。我们把所有要进行操作的步骤，统一放在yaml文件中，让ansible去执行。</p><p>yaml文件格式编写时要注意缩进，因为yaml文件对缩进的要求是非常严格的。刚刚入门编写yaml可能会被缩进逼疯，经常调试半天还是有错误。不过只要多编写几个，熟悉了套路，yaml文件的优势就慢慢体现出来。主要是体现在易于阅读和更改。对后期维护等操作非常的有益。</p><p>下面直接贴出我的adduser.yaml配置文件，然后对文件一一进行解读：</p><h5><span id="31-adduseryaml">3.1 adduser.yaml</span></h5><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">- name:</span> <span class="string">增加指定用户并添加秘钥</span> <span class="string">清理自动生成的秘钥</span> </span><br><span class="line">  <span class="comment">#指定远程命令的主机组</span></span><br><span class="line"><span class="attr">  hosts:</span> <span class="string">all</span> </span><br><span class="line">  <span class="comment">#动作</span></span><br><span class="line"><span class="attr">  tasks:</span> </span><br><span class="line"><span class="attr">    - name:</span> <span class="string">增加用户user01</span></span><br><span class="line">      <span class="comment">#使用模块user</span></span><br><span class="line"><span class="attr">      user:</span> </span><br><span class="line">         <span class="comment">#指定增加用户名为：</span></span><br><span class="line"><span class="attr">         name:</span> <span class="string">user01</span> </span><br><span class="line">         <span class="comment">#增加用户说明</span></span><br><span class="line"><span class="attr">         comment:</span> <span class="string">developer</span> </span><br><span class="line">         <span class="comment">#用户所属组</span></span><br><span class="line"><span class="attr">         group:</span> <span class="string">dev</span> </span><br><span class="line">         <span class="comment">#登陆所使用的shell路径</span></span><br><span class="line"><span class="attr">         shell:</span> <span class="string">/bin/bash</span> </span><br><span class="line">         <span class="comment">#是否在.ssh/路径下生成id_rsa及id_rsa.pub</span></span><br><span class="line"><span class="attr">         generate_ssh_key:</span> <span class="literal">yes</span> </span><br><span class="line">         <span class="comment">#指定生成的路径和名称，公钥自动以.pub结尾</span></span><br><span class="line"><span class="attr">         ssh_key_file:</span> <span class="string">.ssh/id_rsa</span> </span><br><span class="line">         <span class="comment">#默认值present，表示用户需要存在</span></span><br><span class="line"><span class="attr">         state:</span> <span class="string">present</span> </span><br><span class="line"><span class="attr">    - name:</span> <span class="string">复制本机192.168.50.50指定路径文件到目标服务器上</span></span><br><span class="line">      <span class="comment">#使用copy模块</span></span><br><span class="line"><span class="attr">      copy:</span> </span><br><span class="line">         <span class="comment">#源路径，本机文件路径</span></span><br><span class="line"><span class="attr">         src:</span> <span class="string">/home/padim/.ssh/authorized_keys</span> </span><br><span class="line">         <span class="comment">#目标主机路径</span></span><br><span class="line"><span class="attr">         dest:</span> <span class="string">/home/user01/.ssh/authorized_keys</span> </span><br><span class="line">         <span class="comment">#文件所有人</span></span><br><span class="line"><span class="attr">         owner:</span> <span class="string">user01</span> </span><br><span class="line">         <span class="comment">#文件所有组</span></span><br><span class="line"><span class="attr">         group:</span> <span class="string">dev</span> </span><br><span class="line">         <span class="comment">#文件权限</span></span><br><span class="line"><span class="attr">         mode:</span> <span class="string">'0600'</span> </span><br><span class="line"><span class="attr">    - name:</span> <span class="string">清理自动生成的id_rsa文件</span> </span><br><span class="line">      <span class="comment">#使用file模块</span></span><br><span class="line"><span class="attr">      file:</span> </span><br><span class="line">         <span class="comment">#指定路径，删除多个文件时使用，&#123;&#123;item&#125;&#125;为变量，不可变</span></span><br><span class="line"><span class="attr">         path:</span> <span class="string">'/home/user01/.ssh/<span class="template-variable">&#123;&#123; item &#125;&#125;</span>'</span> </span><br><span class="line">         <span class="comment">#状态，删除</span></span><br><span class="line"><span class="attr">         state:</span> <span class="string">absent</span> </span><br><span class="line">         <span class="comment">#定义变量的多个值</span></span><br><span class="line"><span class="attr">      with_items:</span></span><br><span class="line"><span class="bullet">         -</span> <span class="string">id_rsa</span></span><br><span class="line"><span class="bullet">         -</span> <span class="string">id_rsa.pub</span></span><br></pre></td></tr></table></figure><p>以上文件基本都有注释了，这里说明几个地方：</p><table><thead><tr><th>参数名称</th><th>参数说明</th></tr></thead><tbody><tr><td><strong>name</strong></td><td>类似整个文件的说明，随意填写，清楚表达即可。</td></tr><tr><td><strong>tasks</strong></td><td>步骤。每一个tasks为一步，比如上面就是在一步里面完成创建user01。如果要再删除user01，可以在下面再新建一个tasks用来删除。</td></tr><tr><td><strong>tasks中的name</strong></td><td>一样是说明性语句，可随意填写。执行playbook时这项说明语句会打印在屏幕上，告诉你playbook的进展情况。</td></tr></tbody></table><p>编辑好playbook后直接检查并运行该文件就可以了，命令如下：</p><p>检查(使用check参数)：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@padim ~]#ansible-playbook --check adduser.yaml</span><br></pre></td></tr></table></figure><p>无报错后运行：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@padim ~]#ansible-playbook adduser.yaml</span><br></pre></td></tr></table></figure><h5><span id="32-deluseryaml">3.2 deluser.yaml</span></h5><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#删除用户</span></span><br><span class="line"><span class="attr">- name:</span> <span class="string">删除用户user01</span></span><br><span class="line">  <span class="comment">#指定执行的主机组</span></span><br><span class="line"><span class="attr">  hosts:</span> <span class="string">all</span></span><br><span class="line"><span class="attr">  tasks:</span></span><br><span class="line"><span class="attr">    - name:</span> <span class="string">删除用户user01</span></span><br><span class="line">      <span class="comment">#使用user模块</span></span><br><span class="line"><span class="attr">      user:</span>  </span><br><span class="line"><span class="attr">        name:</span> <span class="string">user01</span></span><br><span class="line">        <span class="comment">#absent参数代表删除</span></span><br><span class="line"><span class="attr">        state:</span> <span class="string">absent</span></span><br><span class="line">        <span class="comment">#删除家目录</span></span><br><span class="line"><span class="attr">        remove:</span> <span class="literal">yes</span></span><br></pre></td></tr></table></figure><h5><span id="33关于模块">3.3关于模块</span></h5><p>ansible的官方文档编写的已经是非常的详细了。而且每个功能或者说是模块的使用。官方都会在下面给出一个例子来详细说明，只要耐心的对例子进行阅读，很快就能明白模块的使用方法。下面给出几个链接供学习和参考：</p><p><a href="https://docs.ansible.com/ansible/latest/modules/list_of_all_modules.html" target="_blank" rel="noopener">ansible官方所有模块列表</a></p><p><a href="https://docs.ansible.com/ansible/latest/modules/user_module.html#user-module" target="_blank" rel="noopener">user模块</a></p><p><a href="https://docs.ansible.com/ansible/latest/modules/list_of_files_modules.html" target="_blank" rel="noopener">文件模块</a></p><p><a href="https://docs.ansible.com/ansible/latest/modules/shell_module.html#shell-module" target="_blank" rel="noopener">shell模块</a></p><p><a href="https://docs.ansible.com/ansible/latest/modules/user_module.html#user-module" target="_blank" rel="noopener">模块索引</a></p><p><a href="https://docs.ansible.com/ansible/latest/modules/copy_module.html#copy-module" target="_blank" rel="noopener">copy模块</a></p><p>因为本文旨在说明如果使用 ansible 批量批量添加用户及配置用户秘钥。所以以上列出一些相关的模块链接。如果有其他需求，对单独模块进行学习即可。</p>]]></content>
      
      
      <categories>
          
          <category> ansible </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 自动化运维 </tag>
            
            <tag> ansible </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>zabbix监控docker</title>
      <link href="/2019/09/10/zabbix%E7%9B%91%E6%8E%A7docker/"/>
      <url>/2019/09/10/zabbix%E7%9B%91%E6%8E%A7docker/</url>
      
        <content type="html"><![CDATA[<p>使用 zabbix 对 docker 运行容器使用的 CPU 和内存情况等进行监控</p><a id="more"></a><!-- toc --><ul><li><a href="#1zabbix监控原理">1.zabbix监控原理</a></li><li><a href="#2增加键值">2.增加键值</a><ul><li><a href="#21查看agent端配置">2.1查看agent端配置</a></li><li><a href="#22配置键值">2.2配置键值</a></li></ul></li><li><a href="#3增加-python-脚本">3.增加 python 脚本</a></li><li><a href="#4server端进行简单测试">4.server端进行简单测试</a></li><li><a href="#5web界面增加监控模板">5.web界面增加监控模板</a><ul><li><a href="#51创建发现规则">5.1创建发现规则</a></li><li><a href="#52添加监控项原形">5.2添加监控项原形</a></li></ul></li><li><a href="#6为主机链接模板">6.为主机链接模板</a></li></ul><!-- tocstop --><p>官网有提供了一些监控 docker 信息的模板。具体可以通过点击 zabbix 主页的 share 进入官网网址后搜索下载，并按步骤进行安装即可（如下图）</p><p><img src="/2019/09/10/zabbix监控docker/zabbix_share1.png" alt></p><p>搜索框里直接搜索docker即可。还有各种各样的其他模板共使用。</p><p><img src="/2019/09/10/zabbix监控docker/zabbix_share2.png" alt></p><h4><span id="1zabbix监控原理">1.zabbix监控原理</span></h4><p>本文使用自建的 python 脚本对 docker 进行监控。zabbix 监控大致原理可以分为：</p><p>增加键值 –&gt; 采集数据 –&gt;  agent 端传递键值给server端 –&gt; web 界面增加模板 –&gt; 为主机添加模板 –&gt; 添加触发器/图形等</p><h4><span id="2增加键值">2.增加键值</span></h4><p>那第一步我们就是要来采集数据了。</p><p>采集数据有多种方式，可以是 shell 脚本、python 脚本、又或者是程序自带的信息界面</p><p>如：</p><p>redis 中： redis-cli -h 127.0.0.1 -p 端口号 -a 密码 </p><p>nginx 配置时增加’–with-http_stub_status_module’模块，配置 nginx.conf 后在地址 “<a href="http://127.0.0.1/status&quot;" target="_blank" rel="noopener">http://127.0.0.1/status&quot;</a> 中查看，诸如此类这样的命令，截取其中想要的信息保存到一个文件内读取。</p><p>注：脚本是放在 agent 端，增加键值等也是在 agent 端增加。</p><h5><span id="21查看agent端配置">2.1查看agent端配置</span></h5><p>首先找到 zabbix_agentd.conf 配置文件，在配置文件中搜索包含”Include”的行。如我的配置文件是：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Include=/etc/zabbix/zabbix_agentd.d/</span><br></pre></td></tr></table></figure><h5><span id="22配置键值">2.2配置键值</span></h5><p>然后在路径 /etc/zabbix/zabbix_agentd.d/ 下建立两个 python 脚本：</p><p><strong>docker_discovery.conf</strong>  （自动发现规则）</p><p><strong>docker_status.conf</strong> （获取状态的脚本）</p><p>注：自动发现规则主要是为了省事省力，试想你 docker 中有三个容器，名称分别是 nginx,node,php。那如果你一个个的去增加，工作效率极低，而是使用自动发现，通过脚本的编写来确定所有的容器名称。</p><p>docker_status.conf 文件中只要增加一行代码即可：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">UserParameter=docker_status[*],sudo /usr/bin/python /etc/zabbix/script/docker_monitor.py $1 $2</span><br></pre></td></tr></table></figure><p><strong>UserParameter :</strong> zabbix 增加自定义键值，此处不可更改</p><p><strong>docker_status[*] ：</strong>键值的名称，可以根据喜好来取名字，不过最好还是让人能一眼就看出你键值的意义。其中”[*]”代表任意值，是 shell 的语法。因为我们要监控特定容器的 CPU、负载、内存等使用的情况，最后的 $1 $2 的变量就是对此处赋值。</p><p><strong>sudo /usr/bin/python /etc/zabbix/script/docker_monitor.py ：</strong>指定了 python 的运行路径，sudo 运行（如果是 root 用户运行可去掉该项），还有我们 python 脚本的运行路径和s名称。此处为了整洁，我在 zabbix 目录下新建了 script 目录来存放这两个脚本。</p><p><strong>$1 $2 ：</strong>shell 脚本中的变量，$0 代表脚本名称，$1 $2 则是我们后面需要赋值给 docker_status[*] 的两个变量。容器名称和特定监控项（如 CPU 使用率，内存使用率等）</p><p>docker_discovery.conf 和上面的基本相同，不过是脚本不同：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">UserParameter=docker_discovery,python /etc/zabbix/script/docker_discovery.py</span><br></pre></td></tr></table></figure><h4><span id="3增加-python-脚本">3.增加 python 脚本</span></h4><p>按照2中的路径，在 /etc/zabbix/script/ 下建立： docker_discovery.py 和 docker_monitor.py</p><p>docker_discovery.py：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> simplejson <span class="keyword">as</span> json</span><br><span class="line">tname=os.popen(<span class="string">"""sudo docker ps | grep -v 'CONTAINER ID'|awk &#123;'print $NF'&#125;"""</span>)</span><br><span class="line">container_name=[]</span><br><span class="line"><span class="keyword">for</span> container <span class="keyword">in</span> tname.readlines():</span><br><span class="line">        rname=os.path.basename(container.strip())</span><br><span class="line">        container_name+=[&#123;<span class="string">'&#123;#CONTAINERNAME&#125;'</span>:rname&#125;]</span><br><span class="line"><span class="keyword">print</span> json.dumps(&#123;<span class="string">'data'</span>:container_name&#125;,sort_keys=<span class="literal">True</span>,indent=<span class="number">4</span>,separators=(<span class="string">','</span>,<span class="string">':'</span>))</span><br></pre></td></tr></table></figure><p>docker_monitor.py:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="keyword">import</span> docker</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> subprocess</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">check_container_stats</span><span class="params">(container_name,collect_item)</span>:</span></span><br><span class="line">        container_collect=docker_client.containers.get(container_name).stats(stream=<span class="literal">True</span>)</span><br><span class="line">        old_result=eval(container_collect.next())</span><br><span class="line">        new_result=eval(container_collect.next())</span><br><span class="line">        container_collect.close()</span><br><span class="line">        <span class="comment">#CPU使用百分比</span></span><br><span class="line">        <span class="keyword">if</span> collect_item == <span class="string">'cpu_percent'</span>:</span><br><span class="line">                cpu_total_usage=new_result[<span class="string">'cpu_stats'</span>][<span class="string">'cpu_usage'</span>][<span class="string">'total_usage'</span>] - old_result[<span class="string">'cpu_stats'</span>][<span class="string">'cpu_usage'</span>][<span class="string">'total_usage'</span>]</span><br><span class="line">                cpu_system_uasge=new_result[<span class="string">'cpu_stats'</span>][<span class="string">'system_cpu_usage'</span>] - old_result[<span class="string">'cpu_stats'</span>][<span class="string">'system_cpu_usage'</span>]</span><br><span class="line">                cpu_num=len(old_result[<span class="string">'cpu_stats'</span>][<span class="string">'cpu_usage'</span>][<span class="string">'percpu_usage'</span>])</span><br><span class="line">                result=round((float(cpu_total_usage)/float(cpu_system_uasge))*cpu_num*<span class="number">100.0</span>,<span class="number">2</span>)</span><br><span class="line">        <span class="comment">#内存使用量</span></span><br><span class="line">        <span class="keyword">elif</span> collect_item == <span class="string">'mem_usage'</span>:</span><br><span class="line">                result=new_result[<span class="string">'memory_stats'</span>][<span class="string">'usage'</span>]</span><br><span class="line"><span class="comment">#内存使用百分比</span></span><br><span class="line">        <span class="keyword">elif</span> collect_item == <span class="string">'mem_percent'</span>:</span><br><span class="line">                mem_usage=new_result[<span class="string">'memory_stats'</span>][<span class="string">'usage'</span>]</span><br><span class="line">                mem_limit=new_result[<span class="string">'memory_stats'</span>][<span class="string">'limit'</span>]</span><br><span class="line">                result=round(float(mem_usage)/float(mem_limit)*<span class="number">100.0</span>,<span class="number">2</span>)</span><br><span class="line">        <span class="keyword">return</span> result</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">        docker_client = docker.DockerClient(base_url=<span class="string">'unix://var/run/docker.sock'</span>, version=<span class="string">'1.27'</span>)</span><br><span class="line">        container_name=sys.argv[<span class="number">1</span>]</span><br><span class="line">        collect_item=sys.argv[<span class="number">2</span>]</span><br><span class="line">        <span class="keyword">print</span> check_container_stats(container_name,collect_item)</span><br></pre></td></tr></table></figure><p>python 版本是使用的是：Python 2.7.5</p><p>脚本的编写这里就不详细说了，如果有 python 基础，大部分的代码还是看得懂的。</p><p>建议直接复制上面两个脚本，并且记得下载脚本中所需的 python 包：<strong>docker、simplejson、subprocess</strong>等。并且增加脚本的可执行权限。否则会报错。</p><p>可以直接在终端执行”python /etc/zabbix/script/docker_discovery.py”检验代码是否有误，如下图：</p><p><img src="/2019/09/10/zabbix监控docker/docker_discovery.png" alt></p><p>可以看到我这里已经获取了三个容器，并且分别打印了他们的名称（就如同我们使用 docker ps 看到的一样）</p><p>docker_monitor.py 直接运行可不行，会报错：</p><p><img src="/2019/09/10/zabbix监控docker/docker_monitor1.png" alt></p><p>提示我们超出列表值，这是因为我们没有在后面接指定的”<strong>container_name</strong>“和”<strong>collect_item</strong>“。这也是”docker_status.conf”文件中为什么要在最后增加”$1 $2”的原因。</p><p>增加指定的两个变量后：</p><p><img src="/2019/09/10/zabbix监控docker/docker_monitor2.png" alt></p><p><strong>tb-nginx:</strong> 运行 docker_discovery.py获取到的容器名字</p><p><strong>cpu_percent:</strong>  docker_monitor.py中编写的”collect_item”值</p><p>可以看到返回1.45。即我们容器名为”tb-nginx“的 CPU 使用占比为：1.45%</p><h4><span id="4server端进行简单测试">4.server端进行简单测试</span></h4><p>以上的脚本都运行正常后，重启 zabbix-agent (不重启键值是不生效的)</p><p>然后在 zabbix-server 终端我们可以使用 zabbix 官方提供的 zabbix_get 进行测试（如果没有需要下载）</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">zabbix_get -s 192.168.40.10 -k docker_status[tb-nginx,mem_percent]</span><br></pre></td></tr></table></figure><p>192.168.40.10 ：就是你刚才增加键值的 agent 端，根据实际情况更改。</p><p>如果有正常返回值，那么就可以了，接下来配置 web 端。</p><h4><span id="5web界面增加监控模板">5.web界面增加监控模板</span></h4><p>打开 zabbix 的 web 界面，配置 –&gt; 模板 –&gt; 创建模板 </p><p><img src="/2019/09/10/zabbix监控docker/web1.png" alt></p><p>我这里已经添加好了，可以看到”已连接到”那里已经链接了几个模板。</p><p>名称、应用集、模板群组等这些都可根据个人喜好设定，方便管理和识别即可。</p><p>比较关键的是接下来”自动发现规则”这里。</p><h5><span id="51创建发现规则">5.1创建发现规则</span></h5><p><img src="/2019/09/10/zabbix监控docker/web2.png" alt></p><p><img src="/2019/09/10/zabbix监控docker/web3.png" alt></p><h5><span id="52添加监控项原形">5.2添加监控项原形</span></h5><p><img src="/2019/09/10/zabbix监控docker/web4.png" alt></p><p>两个监控项原形创建：</p><p><img src="/2019/09/10/zabbix监控docker/web5.png" alt></p><p><img src="/2019/09/10/zabbix监控docker/web6.png" alt></p><h4><span id="6为主机链接模板">6.为主机链接模板</span></h4><p>找到需要监控的主机，添加模板：</p><p><img src="/2019/09/10/zabbix监控docker/web7.png" alt></p><p>添加后点击更新。然后稍微等几分钟。点进监控项里查看，就可以看到我们自动发现的容器了。</p><p><img src="/2019/09/10/zabbix监控docker/web8.png" alt></p><p>有了监控项且没有报错，可以在 zabbix web 界面 –&gt;监测中 –&gt; 最新数据 中查看对应的值了。</p><p>然后接下来可以增加触发器、图形这些的。我这里图形是手动添加的，当然也可以自动添加，自动添加就是在增加 “docker自动发现模板”那里，再增加一个图形的模板。我这里需求的不太多，就手动添加了，效果图如下：</p><p><img src="/2019/09/10/zabbix监控docker/web10.png" alt></p>]]></content>
      
      
      <categories>
          
          <category> zabbix </category>
          
      </categories>
      
      
        <tags>
            
            <tag> zabbix </tag>
            
            <tag> docker </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>filebeat.yml配置详解</title>
      <link href="/2019/09/06/filebeat-yml%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/"/>
      <url>/2019/09/06/filebeat-yml%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/</url>
      
        <content type="html"><![CDATA[<p>filebeat.yml配置详解</p><a id="more"></a><!-- toc --><ul><li><a href="#1filebeat介绍">1.filebeat介绍</a></li><li><a href="#2示例文件及配置解析">2.示例文件及配置解析</a></li></ul><!-- tocstop --><h4><span id="1filebeat介绍">1.filebeat介绍</span></h4><p>filebeat 是 elastic beats 中的一个轻量型的采集器。beats 包含很多系列，如官网下图：</p><p><img src="/2019/09/06/filebeat-yml配置详解/beats.png" alt="beat系列"></p><p>基本从名字就可以看得出来其对应的功能。这里我们使用 filebeat 主要针对文件（也就是需要采集的log日志) 来进行采集。</p><p>filebeat 的原理是开启一个 prospectors(收割者)，对文件逐行进行采集。</p><h4><span id="2示例文件及配置解析">2.示例文件及配置解析</span></h4><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">filebeat.prospectors:</span><span class="comment">#采集 abc.com 下 nginx 的 access 日志 </span></span><br><span class="line"><span class="bullet">-</span> <span class="string">type</span> <span class="string">:</span> <span class="string">log</span></span><br><span class="line"><span class="attr">  enabled:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">  paths:</span></span><br><span class="line"><span class="bullet">     -</span> <span class="string">/data/server/wwwlog/nginx/abc.com.access.log</span></span><br><span class="line"><span class="attr">  tags:</span> <span class="string">["nginx_access"]</span></span><br><span class="line"><span class="attr">  tail_files:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">  scan_frequency:</span> <span class="number">30</span><span class="string">s</span></span><br><span class="line"><span class="attr">  fields:</span></span><br><span class="line"><span class="attr">    host:</span> <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span></span><br><span class="line"><span class="attr">    project:</span> <span class="string">abc.com</span></span><br></pre></td></tr></table></figure><table><thead><tr><th>参数选项</th><th>参数说明</th></tr></thead><tbody><tr><td>filebeat.prospectors</td><td>文件开头指定 filebeat 的采集方式，此处使用 prospectors</td></tr><tr><td>type : log</td><td>类型为：log</td></tr><tr><td>enabled: true</td><td>true 为开启，false 为关闭</td></tr><tr><td>paths:</td><td>指定路径</td></tr><tr><td>tags:</td><td>打标签，自定义名称，为后续在kibana查看时提供过滤与分类的效果</td></tr><tr><td>tail_files: true</td><td>开启此项，代表采集从文件最底部开始，选择 false 时 filebeat 会从文件头部开始采集</td></tr><tr><td>scan_frequency: 30s</td><td>对文件的扫描间隔（每30秒扫描一次文件是否改动，根据实际情况改动）</td></tr><tr><td>fields:</td><td>添加字段（用于 elasticsearch 过滤、分类，以及 kibana 中查看）</td></tr></tbody></table><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="bullet">-</span> <span class="string">type</span> <span class="string">:</span> <span class="string">log</span><span class="comment">#采集 abc.com 下 nginx 的 error 日志</span></span><br><span class="line"><span class="attr">  enabled:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">  paths:</span></span><br><span class="line"><span class="bullet">     -</span> <span class="string">/data/server/wwwlog/nginx/abc.com.error.log</span></span><br><span class="line"><span class="attr">  tags:</span> <span class="string">["nginx_error"]</span></span><br><span class="line"><span class="attr">  tail_files:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">  scan_frequency:</span> <span class="number">30</span><span class="string">s</span></span><br><span class="line"><span class="attr">  fields:</span></span><br><span class="line"><span class="attr">    host:</span> <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span></span><br><span class="line"><span class="attr">    project:</span> <span class="string">abc.com</span></span><br></pre></td></tr></table></figure><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="bullet">-</span> <span class="string">type</span> <span class="string">:</span> <span class="string">log</span><span class="comment">#采集 abc.com 下 nginx 的 cache 日志</span></span><br><span class="line"><span class="attr">  enabled:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">  paths:</span></span><br><span class="line"><span class="bullet">     -</span> <span class="string">/data/server/wwwcache/abc.com.cache/application.log</span></span><br><span class="line">  <span class="string">multiline.pattern:</span> <span class="string">'^[0-9]&#123;4&#125;/[0-9]&#123;2&#125;/[0-9]&#123;2&#125;'</span></span><br><span class="line">  <span class="string">multiline.negate:</span> <span class="literal">true</span></span><br><span class="line">  <span class="string">multiline.match:</span> <span class="string">after</span></span><br><span class="line"><span class="attr">  tags:</span> <span class="string">["wwwcache"]</span></span><br><span class="line"><span class="attr">  tail_files:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">  scan_frequency:</span> <span class="number">30</span><span class="string">s</span></span><br><span class="line"><span class="attr">  fields:</span></span><br><span class="line"><span class="attr">    host:</span> <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span></span><br><span class="line"><span class="attr">    project:</span> <span class="string">abc.com</span></span><br></pre></td></tr></table></figure><p>  multiline.pattern: ‘^[0-9]{4}/[0-9]{2}/[0-9]{2}’<br>  multiline.negate: true<br>  multiline.match: after</p><p>以上通过正规表达式，对日志多行进行合并。如下图效果(根据实际情况配置正规表达式，可对任意行进行合并保存在一个 message 中)：</p><p>cache 中日志不需要逐行采集，需要采集某一段</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span>2 /data/server/wwwroot/tui.tongbu.com/index.php(28): CApplication-&gt;run()</span><br><span class="line"><span class="meta">#</span>3 &#123;main&#125;</span><br><span class="line">REQUEST_URI=/apple-touch-icon-120x120-precomposed.png</span><br><span class="line">---</span><br><span class="line">2019/09/06 16:47:32 [error] [exception.CHttpException.404] CHttpException: Unable to resolve the request "apple-touch-icon-120x120.png". in /data/server/wwwroot/yii/framework/web/CWebApplication.php:286</span><br><span class="line">Stack trace:</span><br><span class="line"><span class="meta">#</span>0 /data/server/wwwroot/yii/framework/web/CWebApplication.php(141): CWebApplication-&gt;runController('apple-touch-ico...')</span><br><span class="line"><span class="meta">#</span>1 /data/server/wwwroot/yii/framework/base/CApplication.php(185): CWebApplication-&gt;processRequest()</span><br><span class="line"><span class="meta">#</span>2 /data/server/wwwroot/tui.tongbu.com/index.php(28): CApplication-&gt;run()</span><br><span class="line"><span class="meta">#</span>3 &#123;main&#125;</span><br><span class="line">REQUEST_URI=/apple-touch-icon-120x120.png</span><br><span class="line">---</span><br></pre></td></tr></table></figure><p>增加正规表达式后：</p><p><img src="/2019/09/06/filebeat-yml配置详解/wwwcache_kibana.png" alt="合并多行日志"></p>]]></content>
      
      
      <categories>
          
          <category> ELK </category>
          
      </categories>
      
      
        <tags>
            
            <tag> filebeat </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ELK+filebeat日志采集（搭建篇）</title>
      <link href="/2019/08/30/ElkDeploy/"/>
      <url>/2019/08/30/ElkDeploy/</url>
      
        <content type="html"><![CDATA[<p>ELK+filebeat日志采集（搭建篇）</p><a id="more"></a><!-- toc --><ul><li><a href="#1基本架构图">1.基本架构图</a></li><li><a href="#2此例版本号说明">2.此例版本号说明</a></li><li><a href="#3-java-环境配置">3. JAVA 环境配置</a></li><li><a href="#4rpm形式安装elk">4.RPM形式安装elk</a></li><li><a href="#5-安装-filebeat">5. 安装 filebeat</a></li><li><a href="#6配置文件证明连通性">6.配置文件证明连通性</a><ul><li><a href="#61配置-logstashyml-文件">6.1配置 logstash.yml 文件：</a></li><li><a href="#62配置elasticsearchyml">6.2配置elasticsearch.yml</a></li><li><a href="#63配置kibanayml">6.3配置kibana.yml</a></li></ul></li><li><a href="#7打开kibana添加索引验证">7.打开kibana添加索引验证</a></li></ul><!-- tocstop --><p><img src="/2019/08/30/ElkDeploy/elastic_top.png" alt></p><p>这里不进行配置文件配置更改的说明。全部使用默认配置文件，此篇主要旨在介绍正常安装及运行。</p><p><strong>每种程序的单独介绍可在以下查看（常用的一些配置和概念）：</strong></p><p><strong><a href>elasticsearch介绍及配置说明(待更新)</a></strong></p><p><strong><a href>logstash介绍配置说明(待更新)</a></strong></p><p><strong><a href>kibana介绍及配置说明(待更新)</a></strong></p><p><strong><a href="https://newpants.top/2019/09/06/filebeat-yml配置详解">filebeat介绍及配置说明</a></strong></p><p><a href="https://www.elastic.co/guide/index.html" target="_blank" rel="noopener">elastic官方文档地址</a>   #官方文档说明的都很详细</p><h3><span id="1基本架构图">1.基本架构图</span></h3><p><img src="/2019/08/30/ElkDeploy/Architecture_diagram.png" alt></p><p>elasticsearch： 一款基于 Lucene 的搜索服务器。可以理解为数据库，我们日后将要采集的日志都将储存在这里。</p><p>logstash： logstash 的主要功能是将数据按照我们的要求进行过滤和筛选。完成我们制定的工作发送给 elasticsearch 后以便我们查询。</p><p>kibana： 基于web的查看页面。已经开始提供越来越多的 api。以前的 elasticsearch 还需要 elasticsearch-head 或者直接服务器上面进行操作和查询。现 kibana 的控制台基本可以满足大部分需求。</p><p>filebeat： 采集工具。因为 logstash 非常的消耗系统资源，为了不影响业务服务器，使用 filebeat ，他非常轻量。基本不占用什么空间和系统资源。</p><p>大致流程：filebeat（采集）–&gt; logstash（过滤）–&gt; elasticsearch（储存）–&gt; kibana(查看)</p><h3><span id="2此例版本号说明">2.此例版本号说明</span></h3><table><thead><tr><th>软件</th><th>Java</th><th>Elasticsearch</th><th>Logstash</th><th>Kibana</th><th>Filebeat</th></tr></thead><tbody><tr><td>版本号</td><td>1.8.0_181</td><td>6.7.1</td><td>6.7.1</td><td>6.7.1</td><td>6.7.1</td></tr></tbody></table><p>因为采集量不大，且公司内部部分需求。所以此篇文章是在一台centos7服务器上搭建elasticsearch+logstash+kibana 。其他需要采集的机器上安装 filebeat 进行采集。</p><p>这里需要注意的是，elasticsearch 和 logstash 需要在 java 环境下运行。</p><p><strong>以下安装过程简单带过，网上已经有了很多，遇到问题可以简单进行百度分析。（官方建议最好保持elk+filebeat版本一致性，以避免不可预估的情况发生）</strong></p><h3><span id="3-java-环境配置">3. JAVA 环境配置</span></h3><p>此例使用压缩包形式安装，在<a href="https://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html" target="_blank" rel="noopener">orcale官网jdk下载</a>，按照需求选择需要下载的jdk版本，此例使用 jdk-8u201-linux-x64.tar.gz</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">tar -xvzf jdk-8u201-linux-x64.tar.gz     #解压</span><br><span class="line">mv jdk1.8.0_201/ /usr/jdk1.8.0_201       #移动解压包至/usr下</span><br><span class="line"></span><br><span class="line">vim /etc/profile     #编辑系统配置文件，添加 如下java 环境变量</span><br><span class="line">export JAVA_HOME=/usr/jdk1.8.0_201  #如果不生效，在jdk1.8.0_201加“/”，目录按照实际情况</span><br><span class="line">export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar</span><br><span class="line">export PATH=$PATH:$JAVA_HOME/bin</span><br><span class="line"></span><br><span class="line">source /etc/profile                       #重新加载环境变量</span><br><span class="line">java -version                              #验证</span><br></pre></td></tr></table></figure><h3><span id="4rpm形式安装elk">4.RPM形式安装elk</span></h3><p>在elastic官网：<a href="https://www.elastic.co/cn/" target="_blank" rel="noopener">elastic官网</a>，找到产品相应的下载页面。下载rpm包（当然也可以使用yum或者压缩包形式安装，个人认为rpm比较方便，关键在于可以统一版本）</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">rpm -ivh elasticsearch-6.7.1-x86_64.rpm</span><br><span class="line">rpm -ivh logstash-6.7.1.rpm</span><br><span class="line">rpm -ivh kibana-6.7.1-x86_64.rpm</span><br></pre></td></tr></table></figure><p>因资源有限且需求量不大，故本例三种程序都安装在一台 linux centos7 上。安装完成后，查看程序是否正常启动即可。启动顺序最好按照： </p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">systemctl start elasticsearch</span><br><span class="line">systemctl start logstash</span><br><span class="line">systemctl start kibana</span><br></pre></td></tr></table></figure><p>查看是否安装并启动成功</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">netstat -tunlp | grep 9200     #elasticsearch默认开放端口，有返回如下结果代表端口已启动</span><br><span class="line">tcp6     0      0  127.0.0.1:9200          :::*                LISTEN      12427/java</span><br><span class="line"></span><br><span class="line">netstat -tunlp | grep 9600#logstash默认开放端口，有返回如下结果代表端口已启动</span><br><span class="line">tcp6     0      0  127.0.0.1:9600          :::*                LISTEN      17905/java</span><br><span class="line"></span><br><span class="line">netstat -tunlp | grep 5601#kibana默认开放端口，有返回如下结果代表端口已启动</span><br><span class="line">tcp     0      0   127.0.0.1:5601          :::*                LISTEN      4666/node</span><br></pre></td></tr></table></figure><p>此时通过浏览器访问 127.0.0.1:9200 返回类似如下页面，证明 elasticsearch 安装并正常启动：</p><p><img src="/2019/08/30/ElkDeploy/elasticsearch_start.png" alt="4.elasticsearch_start.png"></p><p>此时通过浏览器访问 127.0.0.1:5601 即可看到 kibana 页面：</p><p><img src="/2019/08/30/ElkDeploy/kibana_start.png" alt="4.kibana_start.png"></p><p>logstash的验证相比前两种不太一样</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@study ~]# whereis logstash  #先查看logstash安装的默认位置</span><br><span class="line">logstash: /etc/logstash /usr/share/logstash</span><br><span class="line"></span><br><span class="line">#执行以下命令。说明：input和output是logstash的两个插件，stdin和stdout分别代表了标准输入和标准输出</span><br><span class="line">[root@study ~]# /usr/share/logstash/bin/logstash -e &apos;input &#123; stdin &#123; &#125; &#125; output &#123; stdout &#123; &#125;&#125;&apos;</span><br></pre></td></tr></table></figure><p>看到 {:port =&gt;9600}，我们在光标等待处随便输入点文字</p><p><img src="/2019/08/30/ElkDeploy/logstash-input.png" alt="logstash_input.png"></p><p>如果类似消息输出到屏幕则正常：</p><p><img src="/2019/08/30/ElkDeploy/logstash-output.png" alt></p><p>此时我们还没有用 filebeat 来收集日志，所以也没有生成对应的索引。故此时看到的都是空的。接来下就介绍在需要采集的机器上安装 filebeat 采集日志。</p><h3><span id="5-安装-filebeat">5. 安装 filebeat</span></h3><p>在目标采集机器上安装filebeat。因采集机器不同，分为 linux 和 windows 。</p><p>linux：</p><p>安装方式：RPM安装</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@study ~]#rpm -ivh filebeat-6.7.1-x86_64.rpm</span><br><span class="line">[root@study ~]#systemctl start filebeat</span><br></pre></td></tr></table></figure><p>对 filebeat.yml 进行简单的配置：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">filebeat.prospectors:  </span><br><span class="line"> - type : log</span><br><span class="line">   enabled: true  #选择true代表开启</span><br><span class="line">   paths:         #路径</span><br><span class="line">     - /data/*.log #所有.log结尾的日志</span><br><span class="line">   fields:#自定义字段，便于区分</span><br><span class="line">      host: 127.0.0.1</span><br><span class="line">   tail_files: true#从尾部开始采集，若选择false则会从头到尾把日志每行都读取</span><br><span class="line">   scan_frequency: 30s#扫描间隔</span><br><span class="line">   exclude_lines: [&quot;^#&quot;]#正则表达式：排除空行</span><br><span class="line">   tags: [&quot;nginx&quot;]#添加tags</span><br><span class="line">output.logstash:#输出插件到logstash</span><br><span class="line"> hosts: [&quot;127.0.0.1:5044&quot;]#hosts地址 本机为测试在本机上安装filebeat。按照实际情况填写</span><br></pre></td></tr></table></figure><p>对 filebeat.yml 文件进行测试：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@study ~]#cd 到filebeat的安装目录</span><br><span class="line">[root@study ~]#./filebeat test config#测试配置文件正确性</span><br><span class="line">[root@study ~]#./filebeat test output#测试配置文件输出的正确性(需要在开启logstash并且指定开放5044端口的前提下，后面会介绍logstash配置开放5044端口)</span><br><span class="line">如果存在异常会返回error。根据error进行调整。若全部正常，则重新启动filebeat</span><br><span class="line">[root@study ~]#systemctl restart filebeat</span><br></pre></td></tr></table></figure><p>windows:</p><p>安装方式：压缩包安装成系统服务</p><p>下载 filebeat-6.7.1-windows-x86_64.zip 解压到指定文件夹，配置文件基本于上述 linux 一样，”paths: “需要更改一下。其他的测试配置文件都相同。下面主要说下把 filebeat 安装成 windows 的服务启动项。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">1.将zip文件内容解压到C：\Program Files(或者其他路径，如果为其他路径要修改install-service-filebeat文件中的路径地址）</span><br><span class="line">2.将filebeat-&lt;version&gt;-windows目录重新命名为filebeat（必须为filebeat）</span><br><span class="line">3.以管理员身份打开PowerShell提示符</span><br><span class="line">4.在PowerShell下将Filebeat安装成Windows服务：</span><br><span class="line">cd ‘c:\Program Files\Filebeat’</span><br><span class="line">.\install-service-filebeat.ps1</span><br><span class="line">5.如果系统禁止脚本执行，则需要为当前会话设置执行策略以允许脚本执行，例如：</span><br><span class="line">PowerShell.exe -ExecutionPolicy UnRestricted -File .\install-service-filebeat.ps1</span><br></pre></td></tr></table></figure><p>这是在 windows 的服务中就可以看到名为 filebeat 的服务启动项了。启动即可。</p><h3><span id="6配置文件证明连通性">6.配置文件证明连通性</span></h3><p>上述 filebeat.yml 已经配置了输出文件到 logstash 的 5044 端口。5044端口是默认端口，此端口可随意更改，只要该端口可以通就可以。如果添加端口后无法进行通讯，修改防火墙策略增加端口放行，或直接关闭防火墙测试。</p><h4><span id="61配置-logstashyml-文件">6.1配置 logstash.yml 文件：</span></h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@study ~]#vim /etc/logstash/config/logstash.yml</span><br><span class="line"><span class="meta">#</span>修改或添加：</span><br><span class="line">http.host: "127.0.0.1"  #主机通讯地址，按实际情况而定</span><br><span class="line">http.port: 9600  #开放端口，默认端口，可更改</span><br><span class="line">path.config: /etc/logstash/conf.d/*.conf #指定配置文件路径</span><br></pre></td></tr></table></figure><p>然后我们在指定路径下配置一个名为 /etc/logstash/conf.d/test.conf 的文件如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">input&#123;    #input插件指定由beats输入，且开放端口号为：5044</span><br><span class="line"> beats&#123;</span><br><span class="line">   port =&gt; 5044</span><br><span class="line"> &#125;</span><br><span class="line">&#125;</span><br><span class="line">output &#123;</span><br><span class="line">        stdout &#123;</span><br><span class="line">                codec =&gt; rubydebug  #输出到当前屏幕，调试用。后面可以关掉</span><br><span class="line">        &#125;</span><br><span class="line">        elasticsearch&#123;#输出到 elasticsearch</span><br><span class="line">   hosts =&gt; ["127.0.0.1:9200"]#elasticsearch 的主机地址和端口号</span><br><span class="line">    index =&gt; "127.0.0.1-%&#123;+YYYY.MM&#125;"#自定义索引名称，如不指定，则默认 logstash*</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4><span id="62配置elasticsearchyml">6.2配置elasticsearch.yml</span></h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span>在elasticsearch.yml添加或修改如下内容</span><br><span class="line">network.host: 127.0.0.1#主机地址</span><br><span class="line">http.port: 9200#主机开放端口</span><br></pre></td></tr></table></figure><h4><span id="63配置kibanayml">6.3配置kibana.yml</span></h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">server.port: 5601    #kibana开放端口</span><br><span class="line">server.host: "127.0.0.1"#kibana主机地址</span><br><span class="line">elasticsearch.hosts: ["http://127.0.0.1:9200"]#kibana连接到的elasticsearch的主机地址及端口号</span><br></pre></td></tr></table></figure><h3><span id="7打开kibana添加索引验证">7.打开kibana添加索引验证</span></h3><p>如果一切顺利。重启这些服务。等待都完全启动后。在 filebeat 采集的路径日志中随便输入一些文字来验证。</p><p><strong>注：要使用 echo “xxx” &gt;&gt;  /data/*.log 的形式，而不是 vim 之后添加。因为filebeat是记录着文件的 PID 号。vim 打开保存后会找不到之前的文件 PID。故会重新采集指定路径的文件，造成每次都是从头开始读行文件。而 echo 不会改变文件的 PID 号。</strong></p><p> 如果在<strong>kibana-&gt;管理-&gt;创建索引模式</strong>中可以看到你指定的名为“127.0.0.1-*”的索引。就代表 elk+filebeat 全部运行成功了。</p><p><img src="/2019/08/30/ElkDeploy/kibana_index.png" alt="7.kibana_index.png"></p><p>(我这里没有截图，偷个懒，就用公司已经在用的索引作为图片说明了)</p>]]></content>
      
      
      <categories>
          
          <category> ELK </category>
          
      </categories>
      
      
        <tags>
            
            <tag> filebeat </tag>
            
            <tag> elasticsearch </tag>
            
            <tag> logstash </tag>
            
            <tag> kibana </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>new pants</title>
      <link href="/2019/08/28/new-pants/"/>
      <url>/2019/08/28/new-pants/</url>
      
        <content type="html"><![CDATA[<p>生命因你而火热</p>]]></content>
      
      
      <categories>
          
          <category> 测试 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pants </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
