<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>ansible批量添加用户及配置用户秘钥</title>
      <link href="/2019/09/12/ansible%E6%89%B9%E9%87%8F%E6%B7%BB%E5%8A%A0%E7%94%A8%E6%88%B7%E5%8F%8A%E9%85%8D%E7%BD%AE%E7%94%A8%E6%88%B7%E7%A7%98%E9%92%A5/"/>
      <url>/2019/09/12/ansible%E6%89%B9%E9%87%8F%E6%B7%BB%E5%8A%A0%E7%94%A8%E6%88%B7%E5%8F%8A%E9%85%8D%E7%BD%AE%E7%94%A8%E6%88%B7%E7%A7%98%E9%92%A5/</url>
      
        <content type="html"><![CDATA[<p>使用自动化运维工具 ansible 为多台服务器添加用户，并配置秘钥。</p><a id="more"></a><h4 id="1-ansible简介"><a href="#1-ansible简介" class="headerlink" title="1.ansible简介"></a>1.ansible简介</h4><p>ansible是一款基于python编写的自动化运维工具，多应用的场景是需要批量统一操作，类似：为多台服务器增加指定用户；更改多台服务器上某一配置文件；为多台服务器安装应用程序等等。</p><p>试想，如果是只有3台服务器，那么还好办，用xshell这类的远程工具，一台台远程过去操作就好。但是如果有30台，300台，光是想想这个数量就难免让人沮丧了。</p><p>其实市面上有很多款类似的开源软件。这里说下ansible的优缺点。</p><p>优点：</p><p>​            （1）python语言开发（意味着基本不需要搭建语言环境，开箱即用，因为大多，像red hat的centos系列装机都是自带python2.7版本的）</p><p>​            （2）基于ssh远程连接执行命令（也就意味着不需要在远程主机上安装任何代理端）</p><p>​            （3）使用YAML语法（学习简单，yaml配置文件格式清晰）</p><p>​            （4）内置模块（模块后面的配置会接触到。这里记住模块是<strong>幂等性</strong>的就可以了。幂等性举个例子就是：你在一台机器上创建用户“user01”，如果“user01”不存在，则创建他，如果“user01”存在，ansible就不会做任何事情。所以在同一台机器上执行同一个ansible playbook是安全的）</p><p>缺点：</p><p>​            （1）无web界面（其实是有<a href="https://www.ansible.com/products/tower" target="_blank" rel="noopener">ansible tower</a>可以使用的。但是据说是商业版才有的，暂时没有深入了解）</p><p>​            （2）因内置模块的特殊性，即使是简单任务也是要花一些时间来编写playbook的（其实熟悉了以后很快，重点还是前期的学习过程）</p><p>​            （3）速度中等（因为不是多通道执行任务，一个任务执行成功返回结果后才执行下一个任务）</p><p>注：上面有提到playbook，这里简单说下。直接使用ansible+命令是可以对目标主机进行操作的。但是如果命令很多，比如要先增加user01，然后为他分配组，为他增加ssh秘钥。一条一条输入显然不现实。而playbook就相当于ansible的剧本，将所有的步骤写在playbook中一次性去执行。</p><h4 id="2-ansible安装及基本文件配置"><a href="#2-ansible安装及基本文件配置" class="headerlink" title="2.ansible安装及基本文件配置"></a>2.ansible安装及基本文件配置</h4><p>ansible的安装很简单，可以通过yum方式安装。这里可以参考官网文档：<a href="https://docs.ansible.com/" target="_blank" rel="noopener">docs.ansible.com</a></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@padim ~]#yum install ansible</span><br></pre></td></tr></table></figure><p>还可以通过github下载安装等等方式。</p><p>使用yum方式安装后，默认安装目录是在<strong>/etc/ansible/</strong>下。</p><h5 id="2-1-hosts文件配置"><a href="#2-1-hosts文件配置" class="headerlink" title="2.1 hosts文件配置"></a>2.1 hosts文件配置</h5><p>这里的hosts不是linux主机上的hosts文件。是指ansible安装目录下的hosts文件，这个hosts文件就是来规定你连接的主机ip，或者主机群组的。默认位置在下面要说到的 ansible.cfg 中指定。我这里的位置是：/etc/ansible/playbooks/hosts</p><p>下面举个hosts文件的例子：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[nginx]</span><br><span class="line">192.168.40.10</span><br><span class="line">192.168.40.11</span><br><span class="line">[mysql]</span><br><span class="line">192.168.40.20</span><br><span class="line">192.168.40.21</span><br><span class="line">[all]</span><br><span class="line">192.168.40.10</span><br><span class="line">192.168.40.11</span><br><span class="line">192.168.40.20</span><br><span class="line">192.168.40.21</span><br></pre></td></tr></table></figure><h5 id="2-2-ansible-cfg文件配置"><a href="#2-2-ansible-cfg文件配置" class="headerlink" title="2.2 ansible.cfg文件配置"></a>2.2 ansible.cfg文件配置</h5><p>首先配置ansible.cfg文件，相当于整个程序的默认启动配置文件。下面是我的配置：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[defaults]</span><br><span class="line">inventory       =/etc/ansible/playbooks/hosts</span><br><span class="line">remote_user     =root</span><br><span class="line">private_key_file=/root/.ssh/my_private</span><br><span class="line">host_key_checking=False</span><br></pre></td></tr></table></figure><p>如果不在这里配置的话，等要写playbook时，是需要再配置的。所以我们这里进行默认的统一配置，有非常多可以增加的项目。这里只说明，如何使用本地的私钥来连接目标服务器上的公钥。（几台服务器上的公钥都是统一的，相当于一把钥匙开好几个锁）</p><p>inventory：    指定hosts文件的路径</p><p>remote_user：    远程连接使用的用户名，此处为root</p><p>private_key_file：    私钥文件路径</p><p>host_key_checking：    首次连接会提示输入yes来确认连接主机。这里选择False来关闭这个提示。</p><h4 id="3-编写playbook"><a href="#3-编写playbook" class="headerlink" title="3.编写playbook"></a>3.编写playbook</h4><p>playbook就是ansible的剧本，也是使用ansible中最重要的一环。我们把所有要进行操作的步骤，统一放在yaml文件中，让ansible去执行。</p><p>yaml文件格式编写时要注意缩进，因为yaml文件对缩进的要求是非常严格的。刚刚入门编写yaml可能会被缩进逼疯，经常调试半天还是有错误。不过只要多编写几个，熟悉了套路，yaml文件的优势就慢慢体现出来。主要是体现在易于阅读和更改。对后期维护等操作非常的有益。</p><p>下面直接贴出我的adduser.yaml配置文件，然后对文件一一进行解读：</p><h5 id="3-1-adduser-yaml"><a href="#3-1-adduser-yaml" class="headerlink" title="3.1 adduser.yaml"></a>3.1 adduser.yaml</h5><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">- name:</span> <span class="string">增加指定用户并添加秘钥</span> <span class="string">清理自动生成的秘钥</span> </span><br><span class="line">  <span class="comment">#指定远程命令的主机组</span></span><br><span class="line"><span class="attr">  hosts:</span> <span class="string">all</span> </span><br><span class="line">  <span class="comment">#动作</span></span><br><span class="line"><span class="attr">  tasks:</span> </span><br><span class="line"><span class="attr">    - name:</span> <span class="string">增加用户user01</span></span><br><span class="line">      <span class="comment">#使用模块user</span></span><br><span class="line"><span class="attr">      user:</span> </span><br><span class="line">         <span class="comment">#指定增加用户名为：</span></span><br><span class="line"><span class="attr">         name:</span> <span class="string">user01</span> </span><br><span class="line">         <span class="comment">#增加用户说明</span></span><br><span class="line"><span class="attr">         comment:</span> <span class="string">developer</span> </span><br><span class="line">         <span class="comment">#用户所属组</span></span><br><span class="line"><span class="attr">         group:</span> <span class="string">dev</span> </span><br><span class="line">         <span class="comment">#登陆所使用的shell路径</span></span><br><span class="line"><span class="attr">         shell:</span> <span class="string">/bin/bash</span> </span><br><span class="line">         <span class="comment">#是否在.ssh/路径下生成id_rsa及id_rsa.pub</span></span><br><span class="line"><span class="attr">         generate_ssh_key:</span> <span class="literal">yes</span> </span><br><span class="line">         <span class="comment">#指定生成的路径和名称，公钥自动以.pub结尾</span></span><br><span class="line"><span class="attr">         ssh_key_file:</span> <span class="string">.ssh/id_rsa</span> </span><br><span class="line">         <span class="comment">#默认值present，表示用户需要存在</span></span><br><span class="line"><span class="attr">         state:</span> <span class="string">present</span> </span><br><span class="line"><span class="attr">    - name:</span> <span class="string">复制本机192.168.50.50指定路径文件到目标服务器上</span></span><br><span class="line">      <span class="comment">#使用copy模块</span></span><br><span class="line"><span class="attr">      copy:</span> </span><br><span class="line">         <span class="comment">#源路径，本机文件路径</span></span><br><span class="line"><span class="attr">         src:</span> <span class="string">/home/padim/.ssh/authorized_keys</span> </span><br><span class="line">         <span class="comment">#目标主机路径</span></span><br><span class="line"><span class="attr">         dest:</span> <span class="string">/home/user01/.ssh/authorized_keys</span> </span><br><span class="line">         <span class="comment">#文件所有人</span></span><br><span class="line"><span class="attr">         owner:</span> <span class="string">user01</span> </span><br><span class="line">         <span class="comment">#文件所有组</span></span><br><span class="line"><span class="attr">         group:</span> <span class="string">dev</span> </span><br><span class="line">         <span class="comment">#文件权限</span></span><br><span class="line"><span class="attr">         mode:</span> <span class="string">'0600'</span> </span><br><span class="line"><span class="attr">    - name:</span> <span class="string">清理自动生成的id_rsa文件</span> </span><br><span class="line">      <span class="comment">#使用file模块</span></span><br><span class="line"><span class="attr">      file:</span> </span><br><span class="line">         <span class="comment">#指定路径，删除多个文件时使用，&#123;&#123;item&#125;&#125;为变量，不可变</span></span><br><span class="line"><span class="attr">         path:</span> <span class="string">'/home/user01/.ssh/<span class="template-variable">&#123;&#123; item &#125;&#125;</span>'</span> </span><br><span class="line">         <span class="comment">#状态，删除</span></span><br><span class="line"><span class="attr">         state:</span> <span class="string">absent</span> </span><br><span class="line">         <span class="comment">#定义变量的多个值</span></span><br><span class="line"><span class="attr">      with_items:</span></span><br><span class="line"><span class="bullet">         -</span> <span class="string">id_rsa</span></span><br><span class="line"><span class="bullet">         -</span> <span class="string">id_rsa.pub</span></span><br></pre></td></tr></table></figure><p>以上文件基本都有注释了，这里说明几个地方：</p><p><strong>name</strong>：类似整个文件的说明，随意填写，清楚表达即可。</p><p><strong>tasks</strong>：步骤。每一个tasks为一步，比如上面就是在一步里面完成创建user01。如果要再删除user01，可以在下面再新建一个tasks用来删除。</p><p><strong>tasks中的name</strong>：一样是说明性语句，可随意填写。执行playbook时这项说明语句会打印在屏幕上，告诉你playbook的进展情况。</p><hr><p>编辑好playbook后直接检查并运行该文件就可以了，命令如下：</p><p>检查(使用check参数)：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@padim ~]#ansible-playbook --check adduser.yaml</span><br></pre></td></tr></table></figure><p>无报错后运行：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@padim ~]#ansible-playbook adduser.yaml</span><br></pre></td></tr></table></figure><h5 id="3-2-deluser-yaml"><a href="#3-2-deluser-yaml" class="headerlink" title="3.2 deluser.yaml"></a>3.2 deluser.yaml</h5><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#删除用户</span></span><br><span class="line"><span class="attr">- name:</span> <span class="string">删除用户user01</span></span><br><span class="line">  <span class="comment">#指定执行的主机组</span></span><br><span class="line"><span class="attr">  hosts:</span> <span class="string">all</span></span><br><span class="line"><span class="attr">  tasks:</span></span><br><span class="line"><span class="attr">    - name:</span> <span class="string">删除用户user01</span></span><br><span class="line">      <span class="comment">#使用user模块</span></span><br><span class="line"><span class="attr">      user:</span>  </span><br><span class="line"><span class="attr">        name:</span> <span class="string">user01</span></span><br><span class="line">        <span class="comment">#absent参数代表删除</span></span><br><span class="line"><span class="attr">        state:</span> <span class="string">absent</span></span><br><span class="line">        <span class="comment">#删除家目录</span></span><br><span class="line"><span class="attr">        remove:</span> <span class="literal">yes</span></span><br></pre></td></tr></table></figure><h5 id="3-3关于模块"><a href="#3-3关于模块" class="headerlink" title="3.3关于模块"></a>3.3关于模块</h5><p>ansible的官方文档编写的已经是非常的详细了。而且每个功能或者说是模块的使用。官方都会在下面给出一个例子来详细说明，只要耐心的对例子进行阅读，很快就能明白模块的使用方法。下面给出几个链接供学习和参考：</p><p><a href="https://docs.ansible.com/ansible/latest/modules/list_of_all_modules.html" target="_blank" rel="noopener">ansible官方所有模块列表</a></p><p><a href="https://docs.ansible.com/ansible/latest/modules/user_module.html#user-module" target="_blank" rel="noopener">user模块</a></p><p><a href="https://docs.ansible.com/ansible/latest/modules/list_of_files_modules.html" target="_blank" rel="noopener">文件模块</a></p><p><a href="https://docs.ansible.com/ansible/latest/modules/shell_module.html#shell-module" target="_blank" rel="noopener">shell模块</a></p><p><a href="https://docs.ansible.com/ansible/latest/modules/user_module.html#user-module" target="_blank" rel="noopener">模块索引</a></p><p><a href="https://docs.ansible.com/ansible/latest/modules/copy_module.html#copy-module" target="_blank" rel="noopener">copy模块</a></p><p>因为本文旨在说明如果使用 ansible 批量批量添加用户及配置用户秘钥。所以以上列出一些相关的模块链接。如果有其他需求，对单独模块进行学习即可。</p>]]></content>
      
      
      <categories>
          
          <category> ansible </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ansible </tag>
            
            <tag> 自动化运维 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>zabbix监控docker</title>
      <link href="/2019/09/10/zabbix%E7%9B%91%E6%8E%A7docker/"/>
      <url>/2019/09/10/zabbix%E7%9B%91%E6%8E%A7docker/</url>
      
        <content type="html"><![CDATA[<p>使用 zabbix 对 docker 运行容器使用的 CPU 和内存情况等进行监控</p><a id="more"></a><p>官网有提供了一些监控 docker 信息的模板。具体可以通过点击 zabbix 主页的 share 进入官网网址后搜索下载，并按步骤进行安装即可（如下图）</p><p><img src="/2019/09/10/zabbix监控docker/zabbix_share1.png" alt></p><p>搜索框里直接搜索docker即可。还有各种各样的其他模板共使用。</p><p><img src="/2019/09/10/zabbix监控docker/zabbix_share2.png" alt></p><h4 id="1-zabbix监控原理"><a href="#1-zabbix监控原理" class="headerlink" title="1.zabbix监控原理"></a>1.zabbix监控原理</h4><p>本文使用自建的 python 脚本对 docker 进行监控。zabbix 监控大致原理可以分为：</p><p>增加键值 –&gt; 采集数据 –&gt;  agent 端传递键值给server端 –&gt; web 界面增加模板 –&gt; 为主机添加模板 –&gt; 添加触发器/图形等</p><h4 id="2-增加键值"><a href="#2-增加键值" class="headerlink" title="2.增加键值"></a>2.增加键值</h4><p>那第一步我们就是要来采集数据了。</p><p>采集数据有多种方式，可以是 shell 脚本、python 脚本、又或者是程序自带的信息界面</p><p>如：</p><p>redis 中： redis-cli -h 127.0.0.1 -p 端口号 -a 密码 </p><p>nginx 配置时增加’–with-http_stub_status_module’模块，配置 nginx.conf 后在地址 “<a href="http://127.0.0.1/status&quot;" target="_blank" rel="noopener">http://127.0.0.1/status&quot;</a> 中查看，诸如此类这样的命令，截取其中想要的信息保存到一个文件内读取。</p><p>注：脚本是放在 agent 端，增加键值等也是在 agent 端增加。</p><h5 id="2-1查看agent端配置"><a href="#2-1查看agent端配置" class="headerlink" title="2.1查看agent端配置"></a>2.1查看agent端配置</h5><p>首先找到 zabbix_agentd.conf 配置文件，在配置文件中搜索包含”Include”的行。如我的配置文件是：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Include=/etc/zabbix/zabbix_agentd.d/</span><br></pre></td></tr></table></figure><h5 id="2-2配置键值"><a href="#2-2配置键值" class="headerlink" title="2.2配置键值"></a>2.2配置键值</h5><p>然后在路径 /etc/zabbix/zabbix_agentd.d/ 下建立两个 python 脚本：</p><p><strong>docker_discovery.conf</strong>  （自动发现规则）</p><p><strong>docker_status.conf</strong> （获取状态的脚本）</p><p>注：自动发现规则主要是为了省事省力，试想你 docker 中有三个容器，名称分别是 nginx,node,php。那如果你一个个的去增加，工作效率极低，而是使用自动发现，通过脚本的编写来确定所有的容器名称。</p><p>docker_status.conf 文件中只要增加一行代码即可：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">UserParameter=docker_status[*],sudo /usr/bin/python /etc/zabbix/script/docker_monitor.py $1 $2</span><br></pre></td></tr></table></figure><p><strong>UserParameter :</strong> zabbix 增加自定义键值，此处不可更改</p><p><strong>docker_status[*] ：</strong>键值的名称，可以根据喜好来取名字，不过最好还是让人能一眼就看出你键值的意义。其中”[*]”代表任意值，是 shell 的语法。因为我们要监控特定容器的 CPU、负载、内存等使用的情况，最后的 $1 $2 的变量就是对此处赋值。</p><p><strong>sudo /usr/bin/python /etc/zabbix/script/docker_monitor.py ：</strong>指定了 python 的运行路径，sudo 运行（如果是 root 用户运行可去掉该项），还有我们 python 脚本的运行路径和s名称。此处为了整洁，我在 zabbix 目录下新建了 script 目录来存放这两个脚本。</p><p><strong>$1 $2 ：</strong>shell 脚本中的变量，$0 代表脚本名称，$1 $2 则是我们后面需要赋值给 docker_status[*] 的两个变量。容器名称和特定监控项（如 CPU 使用率，内存使用率等）</p><p>docker_discovery.conf 和上面的基本相同，不过是脚本不同：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">UserParameter=docker_discovery,python /etc/zabbix/script/docker_discovery.py</span><br></pre></td></tr></table></figure><h4 id="3-增加-python-脚本"><a href="#3-增加-python-脚本" class="headerlink" title="3.增加 python 脚本"></a>3.增加 python 脚本</h4><p>按照2中的路径，在 /etc/zabbix/script/ 下建立： docker_discovery.py 和 docker_monitor.py</p><p>docker_discovery.py：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> simplejson <span class="keyword">as</span> json</span><br><span class="line">tname=os.popen(<span class="string">"""sudo docker ps | grep -v 'CONTAINER ID'|awk &#123;'print $NF'&#125;"""</span>)</span><br><span class="line">container_name=[]</span><br><span class="line"><span class="keyword">for</span> container <span class="keyword">in</span> tname.readlines():</span><br><span class="line">        rname=os.path.basename(container.strip())</span><br><span class="line">        container_name+=[&#123;<span class="string">'&#123;#CONTAINERNAME&#125;'</span>:rname&#125;]</span><br><span class="line"><span class="keyword">print</span> json.dumps(&#123;<span class="string">'data'</span>:container_name&#125;,sort_keys=<span class="literal">True</span>,indent=<span class="number">4</span>,separators=(<span class="string">','</span>,<span class="string">':'</span>))</span><br></pre></td></tr></table></figure><p>docker_monitor.py:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="keyword">import</span> docker</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> subprocess</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">check_container_stats</span><span class="params">(container_name,collect_item)</span>:</span></span><br><span class="line">        container_collect=docker_client.containers.get(container_name).stats(stream=<span class="literal">True</span>)</span><br><span class="line">        old_result=eval(container_collect.next())</span><br><span class="line">        new_result=eval(container_collect.next())</span><br><span class="line">        container_collect.close()</span><br><span class="line">        <span class="comment">#CPU使用百分比</span></span><br><span class="line">        <span class="keyword">if</span> collect_item == <span class="string">'cpu_percent'</span>:</span><br><span class="line">                cpu_total_usage=new_result[<span class="string">'cpu_stats'</span>][<span class="string">'cpu_usage'</span>][<span class="string">'total_usage'</span>] - old_result[<span class="string">'cpu_stats'</span>][<span class="string">'cpu_usage'</span>][<span class="string">'total_usage'</span>]</span><br><span class="line">                cpu_system_uasge=new_result[<span class="string">'cpu_stats'</span>][<span class="string">'system_cpu_usage'</span>] - old_result[<span class="string">'cpu_stats'</span>][<span class="string">'system_cpu_usage'</span>]</span><br><span class="line">                cpu_num=len(old_result[<span class="string">'cpu_stats'</span>][<span class="string">'cpu_usage'</span>][<span class="string">'percpu_usage'</span>])</span><br><span class="line">                result=round((float(cpu_total_usage)/float(cpu_system_uasge))*cpu_num*<span class="number">100.0</span>,<span class="number">2</span>)</span><br><span class="line">        <span class="comment">#内存使用量</span></span><br><span class="line">        <span class="keyword">elif</span> collect_item == <span class="string">'mem_usage'</span>:</span><br><span class="line">                result=new_result[<span class="string">'memory_stats'</span>][<span class="string">'usage'</span>]</span><br><span class="line"><span class="comment">#内存使用百分比</span></span><br><span class="line">        <span class="keyword">elif</span> collect_item == <span class="string">'mem_percent'</span>:</span><br><span class="line">                mem_usage=new_result[<span class="string">'memory_stats'</span>][<span class="string">'usage'</span>]</span><br><span class="line">                mem_limit=new_result[<span class="string">'memory_stats'</span>][<span class="string">'limit'</span>]</span><br><span class="line">                result=round(float(mem_usage)/float(mem_limit)*<span class="number">100.0</span>,<span class="number">2</span>)</span><br><span class="line">        <span class="keyword">return</span> result</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">        docker_client = docker.DockerClient(base_url=<span class="string">'unix://var/run/docker.sock'</span>, version=<span class="string">'1.27'</span>)</span><br><span class="line">        container_name=sys.argv[<span class="number">1</span>]</span><br><span class="line">        collect_item=sys.argv[<span class="number">2</span>]</span><br><span class="line">        <span class="keyword">print</span> check_container_stats(container_name,collect_item)</span><br></pre></td></tr></table></figure><p>python 版本是使用的是：Python 2.7.5</p><p>脚本的编写这里就不详细说了，如果有 python 基础，大部分的代码还是看得懂的。</p><p>建议直接复制上面两个脚本，并且记得下载脚本中所需的 python 包：<strong>docker、simplejson、subprocess</strong>等。并且增加脚本的可执行权限。否则会报错。</p><p>可以直接在终端执行”python /etc/zabbix/script/docker_discovery.py”检验代码是否有误，如下图：</p><p><img src="/2019/09/10/zabbix监控docker/docker_discovery.png" alt></p><p>可以看到我这里已经获取了三个容器，并且分别打印了他们的名称（就如同我们使用 docker ps 看到的一样）</p><p>docker_monitor.py 直接运行可不行，会报错：</p><p><img src="/2019/09/10/zabbix监控docker/docker_monitor1.png" alt></p><p>提示我们超出列表值，这是因为我们没有在后面接指定的”<strong>container_name</strong>“和”<strong>collect_item</strong>“。这也是”docker_status.conf”文件中为什么要在最后增加”$1 $2”的原因。</p><p>增加指定的两个变量后：</p><p><img src="/2019/09/10/zabbix监控docker/docker_monitor2.png" alt></p><p><strong>tb-nginx:</strong> 运行 docker_discovery.py获取到的容器名字</p><p><strong>cpu_percent:</strong>  docker_monitor.py中编写的”collect_item”值</p><p>可以看到返回1.45。即我们容器名为”tb-nginx“的 CPU 使用占比为：1.45%</p><h4 id="4-server端进行简单测试"><a href="#4-server端进行简单测试" class="headerlink" title="4.server端进行简单测试"></a>4.server端进行简单测试</h4><p>以上的脚本都运行正常后，重启 zabbix-agent (不重启键值是不生效的)</p><p>然后在 zabbix-server 终端我们可以使用 zabbix 官方提供的 zabbix_get 进行测试（如果没有需要下载）</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">zabbix_get -s 192.168.40.10 -k docker_status[tb-nginx,mem_percent]</span><br></pre></td></tr></table></figure><p>192.168.40.10 ：就是你刚才增加键值的 agent 端，根据实际情况更改。</p><p>如果有正常返回值，那么就可以了，接下来配置 web 端。</p><h4 id="5-web界面增加监控模板"><a href="#5-web界面增加监控模板" class="headerlink" title="5.web界面增加监控模板"></a>5.web界面增加监控模板</h4><p>打开 zabbix 的 web 界面，配置 –&gt; 模板 –&gt; 创建模板 </p><p><img src="/2019/09/10/zabbix监控docker/web1.png" alt></p><p>我这里已经添加好了，可以看到”已连接到”那里已经链接了几个模板。</p><p>名称、应用集、模板群组等这些都可根据个人喜好设定，方便管理和识别即可。</p><p>比较关键的是接下来”自动发现规则”这里。</p><h5 id="5-1创建发现规则"><a href="#5-1创建发现规则" class="headerlink" title="5.1创建发现规则"></a>5.1创建发现规则</h5><p><img src="/2019/09/10/zabbix监控docker/web2.png" alt></p><p><img src="/2019/09/10/zabbix监控docker/web3.png" alt></p><h5 id="5-2添加监控项原形"><a href="#5-2添加监控项原形" class="headerlink" title="5.2添加监控项原形"></a>5.2添加监控项原形</h5><p><img src="/2019/09/10/zabbix监控docker/web4.png" alt></p><p>两个监控项原形创建：</p><p><img src="/2019/09/10/zabbix监控docker/web5.png" alt></p><p><img src="/2019/09/10/zabbix监控docker/web6.png" alt></p><h4 id="6-为主机链接模板"><a href="#6-为主机链接模板" class="headerlink" title="6.为主机链接模板"></a>6.为主机链接模板</h4><p>找到需要监控的主机，添加模板：</p><p><img src="/2019/09/10/zabbix监控docker/web7.png" alt></p><p>添加后点击更新。然后稍微等几分钟。点进监控项里查看，就可以看到我们自动发现的容器了。</p><p><img src="/2019/09/10/zabbix监控docker/web8.png" alt></p><p>有了监控项且没有报错，可以在 zabbix web 界面 –&gt;监测中 –&gt; 最新数据 中查看对应的值了。</p><p>然后接下来可以增加触发器、图形这些的。我这里图形是手动添加的，当然也可以自动添加，自动添加就是在增加 “docker自动发现模板”那里，再增加一个图形的模板。我这里需求的不太多，就手动添加了，效果图如下：</p><p><img src="/2019/09/10/zabbix监控docker/web10.png" alt></p>]]></content>
      
      
      <categories>
          
          <category> zabbix </category>
          
      </categories>
      
      
        <tags>
            
            <tag> zabbix </tag>
            
            <tag> docker </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>filebeat.yml配置详解</title>
      <link href="/2019/09/06/filebeat-yml%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/"/>
      <url>/2019/09/06/filebeat-yml%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/</url>
      
        <content type="html"><![CDATA[<p>filebeat.yml配置详解</p><a id="more"></a><h4 id="1-filebeat介绍"><a href="#1-filebeat介绍" class="headerlink" title="1.filebeat介绍"></a>1.filebeat介绍</h4><p>filebeat 是 elastic beats 中的一个轻量型的采集器。beats 包含很多系列，如官网下图：</p><p><img src="/2019/09/06/filebeat-yml配置详解/beats.png" alt="beat系列"></p><p>基本从名字就可以看得出来其对应的功能。这里我们使用 filebeat 主要针对文件（也就是需要采集的log日志) 来进行采集。</p><p>filebeat 的原理是开启一个 prospectors(收割者)，对文件逐行进行采集。</p><h4 id="2-示例文件及配置解析"><a href="#2-示例文件及配置解析" class="headerlink" title="2.示例文件及配置解析"></a>2.示例文件及配置解析</h4><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">filebeat.prospectors:</span><span class="comment">#采集 abc.com 下 nginx 的 access 日志 </span></span><br><span class="line"><span class="bullet">-</span> <span class="string">type</span> <span class="string">:</span> <span class="string">log</span></span><br><span class="line"><span class="attr">  enabled:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">  paths:</span></span><br><span class="line"><span class="bullet">     -</span> <span class="string">/data/server/wwwlog/nginx/abc.com.access.log</span></span><br><span class="line"><span class="attr">  tags:</span> <span class="string">["nginx_access"]</span></span><br><span class="line"><span class="attr">  tail_files:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">  scan_frequency:</span> <span class="number">30</span><span class="string">s</span></span><br><span class="line"><span class="attr">  fields:</span></span><br><span class="line"><span class="attr">    host:</span> <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span></span><br><span class="line"><span class="attr">    project:</span> <span class="string">abc.com</span></span><br></pre></td></tr></table></figure><p>filebeat.prospectors:        文件开头指定 filebeat 的采集方式，此处使用 prospectors</p><p>type : log                             类型为：log</p><p>enabled: true                     true 为开启，false 为关闭</p><p>paths:                                 指定路径</p><p>tags:                                    打标签，自定义名称，为后续在kibana查看时提供过滤与分类的效果</p><p>tail_files: true                     开启此项，代表采集从文件最底部开始，选择 false 时 filebeat 会从文件头部开始采集</p><p>scan_frequency: 30s         对文件的扫描间隔（每30秒扫描一次文件是否改动）</p><p>fields:                                  添加字段（用于 elasticsearch 过滤、分类，以及 kibana 中查看）</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="bullet">-</span> <span class="string">type</span> <span class="string">:</span> <span class="string">log</span><span class="comment">#采集 abc.com 下 nginx 的 error 日志</span></span><br><span class="line"><span class="attr">  enabled:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">  paths:</span></span><br><span class="line"><span class="bullet">     -</span> <span class="string">/data/server/wwwlog/nginx/abc.com.error.log</span></span><br><span class="line"><span class="attr">  tags:</span> <span class="string">["nginx_error"]</span></span><br><span class="line"><span class="attr">  tail_files:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">  scan_frequency:</span> <span class="number">30</span><span class="string">s</span></span><br><span class="line"><span class="attr">  fields:</span></span><br><span class="line"><span class="attr">    host:</span> <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span></span><br><span class="line"><span class="attr">    project:</span> <span class="string">abc.com</span></span><br></pre></td></tr></table></figure><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="bullet">-</span> <span class="string">type</span> <span class="string">:</span> <span class="string">log</span><span class="comment">#采集 abc.com 下 nginx 的 cache 日志</span></span><br><span class="line"><span class="attr">  enabled:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">  paths:</span></span><br><span class="line"><span class="bullet">     -</span> <span class="string">/data/server/wwwcache/abc.com.cache/application.log</span></span><br><span class="line">  <span class="string">multiline.pattern:</span> <span class="string">'^[0-9]&#123;4&#125;/[0-9]&#123;2&#125;/[0-9]&#123;2&#125;'</span></span><br><span class="line">  <span class="string">multiline.negate:</span> <span class="literal">true</span></span><br><span class="line">  <span class="string">multiline.match:</span> <span class="string">after</span></span><br><span class="line"><span class="attr">  tags:</span> <span class="string">["wwwcache"]</span></span><br><span class="line"><span class="attr">  tail_files:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">  scan_frequency:</span> <span class="number">30</span><span class="string">s</span></span><br><span class="line"><span class="attr">  fields:</span></span><br><span class="line"><span class="attr">    host:</span> <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span></span><br><span class="line"><span class="attr">    project:</span> <span class="string">abc.com</span></span><br></pre></td></tr></table></figure><p>  multiline.pattern: ‘^[0-9]{4}/[0-9]{2}/[0-9]{2}’<br>  multiline.negate: true<br>  multiline.match: after</p><p>以上通过正规表达式，对日志多行进行合并。如下图效果(根据实际情况配置正规表达式，可对任意行进行合并保存在一个 message 中)：</p><p>cache 中日志不需要逐行采集，需要采集某一段</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span>2 /data/server/wwwroot/tui.tongbu.com/index.php(28): CApplication-&gt;run()</span><br><span class="line"><span class="meta">#</span>3 &#123;main&#125;</span><br><span class="line">REQUEST_URI=/apple-touch-icon-120x120-precomposed.png</span><br><span class="line">---</span><br><span class="line">2019/09/06 16:47:32 [error] [exception.CHttpException.404] CHttpException: Unable to resolve the request "apple-touch-icon-120x120.png". in /data/server/wwwroot/yii/framework/web/CWebApplication.php:286</span><br><span class="line">Stack trace:</span><br><span class="line"><span class="meta">#</span>0 /data/server/wwwroot/yii/framework/web/CWebApplication.php(141): CWebApplication-&gt;runController('apple-touch-ico...')</span><br><span class="line"><span class="meta">#</span>1 /data/server/wwwroot/yii/framework/base/CApplication.php(185): CWebApplication-&gt;processRequest()</span><br><span class="line"><span class="meta">#</span>2 /data/server/wwwroot/tui.tongbu.com/index.php(28): CApplication-&gt;run()</span><br><span class="line"><span class="meta">#</span>3 &#123;main&#125;</span><br><span class="line">REQUEST_URI=/apple-touch-icon-120x120.png</span><br><span class="line">---</span><br></pre></td></tr></table></figure><p>增加正规表达式后：</p><p><img src="/2019/09/06/filebeat-yml配置详解/wwwcache_kibana.png" alt="合并多行日志"></p>]]></content>
      
      
      <categories>
          
          <category> ELK </category>
          
      </categories>
      
      
        <tags>
            
            <tag> filebeat </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ELK+filebeat日志采集（搭建篇）</title>
      <link href="/2019/08/30/ElkDeploy/"/>
      <url>/2019/08/30/ElkDeploy/</url>
      
        <content type="html"><![CDATA[<p>ELK+filebeat日志采集（搭建篇）</p><a id="more"></a><p><img src="/2019/08/30/ElkDeploy/elastic_top.png" alt></p><p>这里不进行配置文件配置更改的说明。全部使用默认配置文件，此篇主要旨在介绍正常安装及运行。</p><p><strong>每种程序的单独介绍可在以下查看（常用的一些配置和概念）：</strong></p><p><strong><a href>elasticsearch介绍及配置说明(待更新)</a></strong></p><p><strong><a href>logstash介绍配置说明(待更新)</a></strong></p><p><strong><a href>kibana介绍及配置说明(待更新)</a></strong></p><p><strong><a href="https://newpants.top/2019/09/06/filebeat-yml配置详解">filebeat介绍及配置说明</a></strong></p><p><a href="https://www.elastic.co/guide/index.html" target="_blank" rel="noopener">elastic官方文档地址</a>   #官方文档说明的都很详细</p><h3 id="1-基本架构图"><a href="#1-基本架构图" class="headerlink" title="1.基本架构图"></a>1.基本架构图</h3><p><img src="/2019/08/30/ElkDeploy/Architecture_diagram.png" alt></p><p>elasticsearch： 一款基于 Lucene 的搜索服务器。可以理解为数据库，我们日后将要采集的日志都将储存在这里。</p><p>logstash： logstash 的主要功能是将数据按照我们的要求进行过滤和筛选。完成我们制定的工作发送给 elasticsearch 后以便我们查询。</p><p>kibana： 基于web的查看页面。已经开始提供越来越多的 api。以前的 elasticsearch 还需要 elasticsearch-head 或者直接服务器上面进行操作和查询。现 kibana 的控制台基本可以满足大部分需求。</p><p>filebeat： 采集工具。因为 logstash 非常的消耗系统资源，为了不影响业务服务器，使用 filebeat ，他非常轻量。基本不占用什么空间和系统资源。</p><p>大致流程：filebeat（采集）–&gt; logstash（过滤）–&gt; elasticsearch（储存）–&gt; kibana(查看)</p><h3 id="2-此例版本号说明"><a href="#2-此例版本号说明" class="headerlink" title="2.此例版本号说明"></a>2.此例版本号说明</h3><table><thead><tr><th>软件</th><th>Java</th><th>Elasticsearch</th><th>Logstash</th><th>Kibana</th><th>Filebeat</th></tr></thead><tbody><tr><td>版本号</td><td>1.8.0_181</td><td>6.7.1</td><td>6.7.1</td><td>6.7.1</td><td>6.7.1</td></tr></tbody></table><p>因为采集量不大，且公司内部部分需求。所以此篇文章是在一台centos7服务器上搭建elasticsearch+logstash+kibana 。其他需要采集的机器上安装 filebeat 进行采集。</p><p>这里需要注意的是，elasticsearch 和 logstash 需要在 java 环境下运行。</p><p><strong>以下安装过程简单带过，网上已经有了很多，遇到问题可以简单进行百度分析。（官方建议最好保持elk+filebeat版本一致性，以避免不可预估的情况发生）</strong></p><h3 id="3-JAVA-环境配置"><a href="#3-JAVA-环境配置" class="headerlink" title="3. JAVA 环境配置"></a>3. JAVA 环境配置</h3><p>此例使用压缩包形式安装，在<a href="https://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html" target="_blank" rel="noopener">orcale官网jdk下载</a>，按照需求选择需要下载的jdk版本，此例使用 jdk-8u201-linux-x64.tar.gz</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">tar -xvzf jdk-8u201-linux-x64.tar.gz     #解压</span><br><span class="line">mv jdk1.8.0_201/ /usr/jdk1.8.0_201       #移动解压包至/usr下</span><br><span class="line"></span><br><span class="line">vim /etc/profile     #编辑系统配置文件，添加 如下java 环境变量</span><br><span class="line">export JAVA_HOME=/usr/jdk1.8.0_201  #如果不生效，在jdk1.8.0_201加“/”，目录按照实际情况</span><br><span class="line">export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar</span><br><span class="line">export PATH=$PATH:$JAVA_HOME/bin</span><br><span class="line"></span><br><span class="line">source /etc/profile                       #重新加载环境变量</span><br><span class="line">java -version                              #验证</span><br></pre></td></tr></table></figure><h3 id="4-RPM形式安装elk"><a href="#4-RPM形式安装elk" class="headerlink" title="4.RPM形式安装elk"></a>4.RPM形式安装elk</h3><p>在elastic官网：<a href="https://www.elastic.co/cn/" target="_blank" rel="noopener">elastic官网</a>，找到产品相应的下载页面。下载rpm包（当然也可以使用yum或者压缩包形式安装，个人认为rpm比较方便，关键在于可以统一版本）</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">rpm -ivh elasticsearch-6.7.1-x86_64.rpm</span><br><span class="line">rpm -ivh logstash-6.7.1.rpm</span><br><span class="line">rpm -ivh kibana-6.7.1-x86_64.rpm</span><br></pre></td></tr></table></figure><p>因资源有限且需求量不大，故本例三种程序都安装在一台 linux centos7 上。安装完成后，查看程序是否正常启动即可。启动顺序最好按照： </p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">systemctl start elasticsearch</span><br><span class="line">systemctl start logstash</span><br><span class="line">systemctl start kibana</span><br></pre></td></tr></table></figure><p>查看是否安装并启动成功</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">netstat -tunlp | grep 9200     #elasticsearch默认开放端口，有返回如下结果代表端口已启动</span><br><span class="line">tcp6     0      0  127.0.0.1:9200          :::*                LISTEN      12427/java</span><br><span class="line"></span><br><span class="line">netstat -tunlp | grep 9600#logstash默认开放端口，有返回如下结果代表端口已启动</span><br><span class="line">tcp6     0      0  127.0.0.1:9600          :::*                LISTEN      17905/java</span><br><span class="line"></span><br><span class="line">netstat -tunlp | grep 5601#kibana默认开放端口，有返回如下结果代表端口已启动</span><br><span class="line">tcp     0      0   127.0.0.1:5601          :::*                LISTEN      4666/node</span><br></pre></td></tr></table></figure><p>此时通过浏览器访问 127.0.0.1:9200 返回类似如下页面，证明 elasticsearch 安装并正常启动：</p><p><img src="/2019/08/30/ElkDeploy/elasticsearch_start.png" alt="4.elasticsearch_start.png"></p><p>此时通过浏览器访问 127.0.0.1:5601 即可看到 kibana 页面：</p><p><img src="/2019/08/30/ElkDeploy/kibana_start.png" alt="4.kibana_start.png"></p><p>logstash的验证相比前两种不太一样</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@study ~]# whereis logstash  #先查看logstash安装的默认位置</span><br><span class="line">logstash: /etc/logstash /usr/share/logstash</span><br><span class="line"></span><br><span class="line">#执行以下命令。说明：input和output是logstash的两个插件，stdin和stdout分别代表了标准输入和标准输出</span><br><span class="line">[root@study ~]# /usr/share/logstash/bin/logstash -e &apos;input &#123; stdin &#123; &#125; &#125; output &#123; stdout &#123; &#125;&#125;&apos;</span><br></pre></td></tr></table></figure><p>看到 {:port =&gt;9600}，我们在光标等待处随便输入点文字</p><p><img src="/2019/08/30/ElkDeploy/logstash-input.png" alt="logstash_input.png"></p><p>如果类似消息输出到屏幕则正常：</p><p><img src="/2019/08/30/ElkDeploy/logstash-output.png" alt></p><p>此时我们还没有用 filebeat 来收集日志，所以也没有生成对应的索引。故此时看到的都是空的。接来下就介绍在需要采集的机器上安装 filebeat 采集日志。</p><h3 id="5-安装-filebeat"><a href="#5-安装-filebeat" class="headerlink" title="5. 安装 filebeat"></a>5. 安装 filebeat</h3><p>在目标采集机器上安装filebeat。因采集机器不同，分为 linux 和 windows 。</p><p>linux：</p><p>安装方式：RPM安装</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@study ~]#rpm -ivh filebeat-6.7.1-x86_64.rpm</span><br><span class="line">[root@study ~]#systemctl start filebeat</span><br></pre></td></tr></table></figure><p>对 filebeat.yml 进行简单的配置：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">filebeat.prospectors:  </span><br><span class="line"> - type : log</span><br><span class="line">   enabled: true  #选择true代表开启</span><br><span class="line">   paths:         #路径</span><br><span class="line">     - /data/*.log #所有.log结尾的日志</span><br><span class="line">   fields:#自定义字段，便于区分</span><br><span class="line">      host: 127.0.0.1</span><br><span class="line">   tail_files: true#从尾部开始采集，若选择false则会从头到尾把日志每行都读取</span><br><span class="line">   scan_frequency: 30s#扫描间隔</span><br><span class="line">   exclude_lines: [&quot;^#&quot;]#正则表达式：排除空行</span><br><span class="line">   tags: [&quot;nginx&quot;]#添加tags</span><br><span class="line">output.logstash:#输出插件到logstash</span><br><span class="line"> hosts: [&quot;127.0.0.1:5044&quot;]#hosts地址 本机为测试在本机上安装filebeat。按照实际情况填写</span><br></pre></td></tr></table></figure><p>对 filebeat.yml 文件进行测试：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@study ~]#cd 到filebeat的安装目录</span><br><span class="line">[root@study ~]#./filebeat test config#测试配置文件正确性</span><br><span class="line">[root@study ~]#./filebeat test output#测试配置文件输出的正确性(需要在开启logstash并且指定开放5044端口的前提下，后面会介绍logstash配置开放5044端口)</span><br><span class="line">如果存在异常会返回error。根据error进行调整。若全部正常，则重新启动filebeat</span><br><span class="line">[root@study ~]#systemctl restart filebeat</span><br></pre></td></tr></table></figure><p>windows:</p><p>安装方式：压缩包安装成系统服务</p><p>下载 filebeat-6.7.1-windows-x86_64.zip 解压到指定文件夹，配置文件基本于上述 linux 一样，”paths: “需要更改一下。其他的测试配置文件都相同。下面主要说下把 filebeat 安装成 windows 的服务启动项。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">1.将zip文件内容解压到C：\Program Files(或者其他路径，如果为其他路径要修改install-service-filebeat文件中的路径地址）</span><br><span class="line">2.将filebeat-&lt;version&gt;-windows目录重新命名为filebeat（必须为filebeat）</span><br><span class="line">3.以管理员身份打开PowerShell提示符</span><br><span class="line">4.在PowerShell下将Filebeat安装成Windows服务：</span><br><span class="line">cd ‘c:\Program Files\Filebeat’</span><br><span class="line">.\install-service-filebeat.ps1</span><br><span class="line">5.如果系统禁止脚本执行，则需要为当前会话设置执行策略以允许脚本执行，例如：</span><br><span class="line">PowerShell.exe -ExecutionPolicy UnRestricted -File .\install-service-filebeat.ps1</span><br></pre></td></tr></table></figure><p>这是在 windows 的服务中就可以看到名为 filebeat 的服务启动项了。启动即可。</p><h3 id="6-配置文件证明连通性"><a href="#6-配置文件证明连通性" class="headerlink" title="6.配置文件证明连通性"></a>6.配置文件证明连通性</h3><p>上述 filebeat.yml 已经配置了输出文件到 logstash 的 5044 端口。5044端口是默认端口，此端口可随意更改，只要该端口可以通就可以。如果添加端口后无法进行通讯，修改防火墙策略增加端口放行，或直接关闭防火墙测试。</p><h4 id="6-1配置-logstash-yml-文件："><a href="#6-1配置-logstash-yml-文件：" class="headerlink" title="6.1配置 logstash.yml 文件："></a>6.1配置 logstash.yml 文件：</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@study ~]#vim /etc/logstash/config/logstash.yml</span><br><span class="line"><span class="meta">#</span>修改或添加：</span><br><span class="line">http.host: "127.0.0.1"  #主机通讯地址，按实际情况而定</span><br><span class="line">http.port: 9600  #开放端口，默认端口，可更改</span><br><span class="line">path.config: /etc/logstash/conf.d/*.conf #指定配置文件路径</span><br></pre></td></tr></table></figure><p>然后我们在指定路径下配置一个名为 /etc/logstash/conf.d/test.conf 的文件如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">input&#123;    #input插件指定由beats输入，且开放端口号为：5044</span><br><span class="line"> beats&#123;</span><br><span class="line">   port =&gt; 5044</span><br><span class="line"> &#125;</span><br><span class="line">&#125;</span><br><span class="line">output &#123;</span><br><span class="line">        stdout &#123;</span><br><span class="line">                codec =&gt; rubydebug  #输出到当前屏幕，调试用。后面可以关掉</span><br><span class="line">        &#125;</span><br><span class="line">        elasticsearch&#123;#输出到 elasticsearch</span><br><span class="line">   hosts =&gt; ["127.0.0.1:9200"]#elasticsearch 的主机地址和端口号</span><br><span class="line">    index =&gt; "127.0.0.1-%&#123;+YYYY.MM&#125;"#自定义索引名称，如不指定，则默认 logstash*</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="6-2配置elasticsearch-yml"><a href="#6-2配置elasticsearch-yml" class="headerlink" title="6.2配置elasticsearch.yml"></a>6.2配置elasticsearch.yml</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span>在elasticsearch.yml添加或修改如下内容</span><br><span class="line">network.host: 127.0.0.1#主机地址</span><br><span class="line">http.port: 9200#主机开放端口</span><br></pre></td></tr></table></figure><h4 id="6-3配置kibana-yml"><a href="#6-3配置kibana-yml" class="headerlink" title="6.3配置kibana.yml"></a>6.3配置kibana.yml</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">server.port: 5601    #kibana开放端口</span><br><span class="line">server.host: "127.0.0.1"#kibana主机地址</span><br><span class="line">elasticsearch.hosts: ["http://127.0.0.1:9200"]#kibana连接到的elasticsearch的主机地址及端口号</span><br></pre></td></tr></table></figure><h3 id="7-打开kibana添加索引验证"><a href="#7-打开kibana添加索引验证" class="headerlink" title="7.打开kibana添加索引验证"></a>7.打开kibana添加索引验证</h3><p>如果一切顺利。重启这些服务。等待都完全启动后。在 filebeat 采集的路径日志中随便输入一些文字来验证。</p><p><strong>注：要使用 echo “xxx” &gt;&gt;  /data/*.log 的形式，而不是 vim 之后添加。因为filebeat是记录着文件的 PID 号。vim 打开保存后会找不到之前的文件 PID。故会重新采集指定路径的文件，造成每次都是从头开始读行文件。而 echo 不会改变文件的 PID 号。</strong></p><p> 如果在<strong>kibana-&gt;管理-&gt;创建索引模式</strong>中可以看到你指定的名为“127.0.0.1-*”的索引。就代表 elk+filebeat 全部运行成功了。</p><p><img src="/2019/08/30/ElkDeploy/kibana_index.png" alt="7.kibana_index.png"></p><p>(我这里没有截图，偷个懒，就用公司已经在用的索引作为图片说明了)</p>]]></content>
      
      
      <categories>
          
          <category> ELK </category>
          
      </categories>
      
      
        <tags>
            
            <tag> filebeat </tag>
            
            <tag> elasticsearch </tag>
            
            <tag> logstash </tag>
            
            <tag> kibana </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>new pants</title>
      <link href="/2019/08/28/new-pants/"/>
      <url>/2019/08/28/new-pants/</url>
      
        <content type="html"><![CDATA[<div id="hbe-security">  <div class="hbe-input-container">  <input type="password" class="hbe-form-control" id="pass" placeholder="抱歉，此文暂时不对外开放." />    <label for="pass">抱歉，此文暂时不对外开放.</label>    <div class="bottom-line"></div>  </div></div><div id="decryptionError" style="display:none;">Incorrect Password!</div><div id="noContentError" style="display:none;">No content to display!</div><div id="encrypt-blog" style="display:none">U2FsdGVkX1+35Rf3oqxLpjk0B7OxuX496b1g3lUAtWnVHnBzHoedc0ZWAa+TcZTHm0rr9mHBXRreqVtRdlahfNzklbBGRcosqNNlMC9/ZY0=</div><script src="/lib/crypto-js.js"></script><script src="/lib/blog-encrypt.js"></script><link href="/css/blog-encrypt.css" rel="stylesheet" type="text/css">]]></content>
      
      
      <categories>
          
          <category> other </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pants </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
