<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>NewPants</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://newpants.top/"/>
  <updated>2019-09-25T10:46:15.310Z</updated>
  <id>http://newpants.top/</id>
  
  <author>
    <name>未完成</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>利用性能分析工具sar、iotop对linux服务器高负载问题排查</title>
    <link href="http://newpants.top/2019/09/25/%E5%88%A9%E7%94%A8%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E5%B7%A5%E5%85%B7sar%E3%80%81iotop%E5%AF%B9linux%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%AB%98%E8%B4%9F%E8%BD%BD%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5/"/>
    <id>http://newpants.top/2019/09/25/利用性能分析工具sar、iotop对linux服务器高负载问题排查/</id>
    <published>2019-09-25T08:03:38.000Z</published>
    <updated>2019-09-25T10:46:15.310Z</updated>
    
    <content type="html"><![CDATA[<p>工作中我们有时候会遇到一些服务器性能上的问题。比如：内存不足、io等待时间过长、cpu使用率高等等等等。其实原本这些东西在我们服务器上线之前就应该经过压力测验了，所以不管是云服务器还是实体机，最开始的配置其实还是可以满足实际业务需求的。</p><a id="more"></a><p>但是随着机器年限的提升，为了节约成本或者一些新的需求，又或者是长时间运行，一些问题还是会暴露出来。</p><p>这几天工作中同事经常会和我说一台linux的服务器cpu负载偶尔会变得很高。</p><p>这里说下这台服务器的配置：</p><table><thead><tr><th>说明</th><th>详细</th></tr></thead><tbody><tr><td>系统</td><td>centos7</td></tr><tr><td>性质</td><td>腾讯云主机</td></tr><tr><td>内存</td><td>4G</td></tr><tr><td>物理CPU个数</td><td>1</td></tr><tr><td>CPU核数</td><td>2</td></tr><tr><td>逻辑CPU个数（即物理CPU个数×核数）</td><td>2</td></tr></tbody></table><p>因为是用作web网站的，基本不太需要很大的资源，这样配置的主机已经是够了的。</p><p>我们先从zabbix报警的图形中看一下cpu负载的状况：</p><p><img src="/2019/09/25/利用性能分析工具sar、iotop对linux服务器高负载问题排查/cpu_load.png" alt></p><p>从上图可以看出，1分钟的平均负载已经达到了5，5分钟的平均负载则达到了2.0多，15分钟的负载就相对正常。如果这样看还好，只是短暂的负载飙升。这个值的正常大小主要取决于你的CPU逻辑个数。即，不超过2以上系统就基本没啥问题正常运行。一旦超过这个最大值以后，其实你的系统会变得非常的卡，就好比我们用windows时，鼠标直接都没办法移动的这种情况。这种情况下，web服务器基本属于宕机状态，是没办法为客户提供服务的。虽说偶尔才会出现，而且每次的影响也就是十几个连接超时。但我们遇到问题，还是要先排查一下，排查的过程中还是可以学习到非常多的知识的。</p><p>虽然linux自带的top命令一样可以查看关于各类报告的数值，但是比较局限，一是不能按时间戳查看（比如想看昨天的，或者统计数据），二是也无法对数据进行细化查看（查看到底是哪个进程，或者占用比例）。</p><p>所以我们使用以下两种软件来达到我们的目的：sar和iotop</p><h4 id="1-sar的使用"><a href="#1-sar的使用" class="headerlink" title="1.sar的使用"></a>1.sar的使用</h4><p>sar，全称：”System Activity Reporter” ，直译就是：系统活动情况报告。例如：文件读写情况报告、CPU效率报告、内存使用情况报告、磁盘I/O报告等。</p><p>安装我们使用yum方式安装，保证镜像源可用后直接输入</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@padim ~]#yum -y install sysstat</span><br></pre></td></tr></table></figure><p>开箱即用，先输入”sar –help”查看一下是否安装正常，并且查看可用的参数，如下图：</p><p><img src="/2019/09/25/利用性能分析工具sar、iotop对linux服务器高负载问题排查/sar_help.png" alt></p><p>以下列出一些常用的参数详解：</p><table><thead><tr><th>参数选项</th><th>参数说明</th></tr></thead><tbody><tr><td>-A</td><td>所有报告的总和</td></tr><tr><td>-u</td><td>输出<a href="http://lovesoo.org/tag/cpu" target="_blank" rel="noopener">CPU</a>使用情况的统计信息</td></tr><tr><td>-v</td><td>输出inode、文件和其他内核表的统计信息</td></tr><tr><td>-d</td><td>输出每一个块设备的活动信息</td></tr><tr><td>-r</td><td>输出<a href="http://lovesoo.org/tag/内存" target="_blank" rel="noopener">内存</a>和交换空间的统计信息</td></tr><tr><td>-b</td><td>显示<a href="http://lovesoo.org/tag/io" target="_blank" rel="noopener">I/O</a>和传送速率的统计信息</td></tr><tr><td>-a</td><td>文件读写情况</td></tr><tr><td>-c</td><td>输出进程统计信息，每秒创建的进程数</td></tr><tr><td>-R</td><td>输出内存页面的统计信息</td></tr><tr><td>-y</td><td>终端设备活动情况</td></tr><tr><td>-w</td><td>输出系统交换活动信息</td></tr></tbody></table><p>因为我们想看CPU相关的信息，直接输入：”sar -u”，找到我们监控对应的上午08:30分左右，如下图：</p><p><img src="/2019/09/25/利用性能分析工具sar、iotop对linux服务器高负载问题排查/sar_u.png" alt></p><p>太好了，果然08:30跟其他的凡夫俗子不一样啊。很突出的彰显着自己的王霸之气。可以看到%iowait比其他的高出非常多。已经达到了百分之10+。</p><p>说实话我对iowait理解也不是特别透彻，比较浅显的理解就是，系统在做io，进程在等到io完成。所以此时进程是不工作的，如果iowait值很大，那么进程的等待时间就越长，所以进程等待这么长的时间，换谁也坐不住了，生命就这样流逝啊。</p><p>知道了可能是iowait的问题后，那么可以查看是哪些进程在做IO导致系统在等待。</p><h5 id="1-1-iostat"><a href="#1-1-iostat" class="headerlink" title="1.1 iostat"></a>1.1 iostat</h5><p>sysstat包下还有一个iostat的软件，iostat是专门来查看io相关信息的软件，有如下几个参数：</p><table><thead><tr><th>参数选项</th><th>参数说明</th></tr></thead><tbody><tr><td>-c</td><td>仅显示CPU使用情况</td></tr><tr><td>-d</td><td>仅显示设备利用率</td></tr><tr><td>-k</td><td>显示状态以千字节每秒为单位，而不适用块每秒</td></tr><tr><td>-m</td><td>显示状态以兆字节每秒为单位</td></tr><tr><td>-p</td><td>仅显示块设备和所有被使用的其他分区的状态</td></tr><tr><td>-t</td><td>显示每个报告产生时的时间</td></tr><tr><td>-V</td><td>显示版号并退出</td></tr><tr><td>-x</td><td>显示扩展状态</td></tr></tbody></table><p>我们使用一个”-t”的参数看下效果，如下图：</p><p><img src="/2019/09/25/利用性能分析工具sar、iotop对linux服务器高负载问题排查/iostat_t.png" alt></p><p>各属性说明：</p><table><thead><tr><th>属性</th><th>属性说明</th><th>备注</th></tr></thead><tbody><tr><td>%user</td><td>CPU处在用户模式下的时间百分比</td><td></td></tr><tr><td>%nice</td><td>CPU处于带NICE值的用户模式下的时间百分比</td><td></td></tr><tr><td>%system</td><td>CPU处于系统模式下的时间百分比</td><td></td></tr><tr><td>%iowait</td><td>CPU等待输入输出完成时间的百分比</td><td>如果%iowait值过高，表示硬盘存在I/O瓶颈</td></tr><tr><td>%steal</td><td>管理程序维护另一个虚拟处理器时，虚拟CPU的无意识等待时间百分比</td><td></td></tr><tr><td>%idle</td><td>CPU空闲时间百分比</td><td><strong>1）</strong>如果%idle值持续低于10，表明CPU处理能力相对较低，系统中最需要解决的资源是CPU。<strong>2）</strong>如果%idle值高，表示CPU较空闲。<strong>3）</strong>如果%idle值高但系统响应慢时，可能是CPU等待分配内存，应加大内存容量</td></tr><tr><td>tps</td><td>该设备每秒的传输次数</td><td></td></tr><tr><td>kB_read/s</td><td>每秒从设备读取的数据量</td><td></td></tr><tr><td>kB_wrtn/s</td><td>每秒从设备写入的数据量</td><td></td></tr><tr><td>kB_read</td><td>读取的数据总量</td><td></td></tr><tr><td>kB_wrtn</td><td>写入的数据总量</td><td></td></tr></tbody></table><p>如果你对top很熟悉，那么上面的输出内容基本也是看得懂的。基本可以看出，是vda这块盘的读写量很大。但是不能细化到是哪个进程。这时候就要用到下面所说的”iotop”了。</p><h4 id="2-iotop"><a href="#2-iotop" class="headerlink" title="2.iotop"></a>2.iotop</h4><p>iotop和top名字很像，也是可以动态监视并查看系统状态的工具，是用python来编写的。</p><p>安装iotop我们也是使用yum方式安装：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@padim ~]#yum -y install iotop</span><br></pre></td></tr></table></figure><p>iotop参数说明：</p><table><thead><tr><th>参数选项</th><th>参数说明</th></tr></thead><tbody><tr><td>–version</td><td>表示显示版本号</td></tr><tr><td>-h</td><td>–help 表示显示帮助信息</td></tr><tr><td>-o，–only</td><td>表示显示进程或者线程实际上正在做的I/O，而不是全部的，可以随时切换按o</td></tr><tr><td>-b，–batch</td><td>表示运行在非交互式的模式</td></tr><tr><td>-n，NUM, –iter=NUM</td><td>表示在非交互式模式下，设置显示的次数</td></tr><tr><td>-d，SEC, –delay=SEC</td><td>表示设置显示的间隔秒数</td></tr><tr><td>-p，PID, –pid=PID</td><td>表示显示指定PID的信息</td></tr><tr><td>-u，USER, –user=USER</td><td>表示显示指定用户的进程信息</td></tr><tr><td>-P，–processes</td><td>表示只显示进程信息</td></tr><tr><td>-a，–accumulated</td><td>表示显示从iotop启动后每个线程完成了的IO总数</td></tr><tr><td>-k，–kilobytes</td><td>表示以千字节显示</td></tr><tr><td>-t，–time</td><td>表示在每一行前添加一个当前的时间</td></tr></tbody></table><p>我们输入”iotop -oPa”来查看当前服务器上运行的程序的I/O情况：</p><p><img src="/2019/09/25/利用性能分析工具sar、iotop对linux服务器高负载问题排查/iotop.png" alt></p><p>可以通过键盘左右键选则，选中想要排序的项目对其进行排序查看。这里我选中磁盘的写操作排序。</p><p>可以看到第一行是一个名为”systemd-journald”的命令。该命令是linux系统自带的系统服务。第二行是www用户运行的一个node脚本。</p><p>因为我们之前使用过命令iostat查看过%user和%system的情况。%user占用的比例是比%system高的。所以非常有可能的是当时占用cpu资源的是user用户执行的程序，如下图（之前iostat查看到的信息）：</p><p><img src="/2019/09/25/利用性能分析工具sar、iotop对linux服务器高负载问题排查/iostat_t2.png" alt></p><p>所以到这里我们猜测，可能是node这个脚本，存在着较大的读写操作，导致服务器iowait变长，从而增加了CPU的负载值。</p><p>那其实到底是不是…还需要来看看这个js脚本。这时候需要呼叫开发小哥了。然后其他的进程也去网上百度一下，搜搜看哪里是不是需要优化的地方。改完以后再去观察监控，看是不是还会出现之前的问题。</p><p>不过说到底不管是不是，我们至少学会了如何使用sar和iotop去查找问题的根源。在这方面自己也是还算个新手，如果有不对的地方，希望大家指出。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;工作中我们有时候会遇到一些服务器性能上的问题。比如：内存不足、io等待时间过长、cpu使用率高等等等等。其实原本这些东西在我们服务器上线之前就应该经过压力测验了，所以不管是云服务器还是实体机，最开始的配置其实还是可以满足实际业务需求的。&lt;/p&gt;
    
    </summary>
    
      <category term="linux" scheme="http://newpants.top/categories/linux/"/>
    
    
      <category term="sar" scheme="http://newpants.top/tags/sar/"/>
    
      <category term="iotop" scheme="http://newpants.top/tags/iotop/"/>
    
  </entry>
  
  <entry>
    <title>还能欢笑如此吗</title>
    <link href="http://newpants.top/2019/09/21/%E8%BF%98%E8%83%BD%E6%AC%A2%E7%AC%91%E5%A6%82%E6%AD%A4%E5%90%97/"/>
    <id>http://newpants.top/2019/09/21/还能欢笑如此吗/</id>
    <published>2019-09-21T14:14:30.000Z</published>
    <updated>2019-09-25T07:37:22.020Z</updated>
    
    <content type="html"><![CDATA[<div id="hbe-security">  <div class="hbe-input-container">  <input type="password" class="hbe-form-control" id="pass" placeholder="抱歉，此文暂时不对外开放." />    <label for="pass">抱歉，此文暂时不对外开放.</label>    <div class="bottom-line"></div>  </div></div><div id="decryptionError" style="display:none;">Incorrect Password!</div><div id="noContentError" style="display:none;">No content to display!</div><div id="encrypt-blog" style="display:none">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</div><script src="/lib/crypto-js.js"></script><script src="/lib/blog-encrypt.js"></script><link href="/css/blog-encrypt.css" rel="stylesheet" type="text/css">]]></content>
    
    <summary type="html">
    
      抱歉，此文暂时不对外开放.&lt;/br&gt;
    
    </summary>
    
    
      <category term="Ref:rain" scheme="http://newpants.top/tags/Ref-rain/"/>
    
  </entry>
  
  <entry>
    <title>多端更新hexo博客</title>
    <link href="http://newpants.top/2019/09/21/%E5%A4%9A%E7%AB%AF%E6%9B%B4%E6%96%B0hexo%E5%8D%9A%E5%AE%A2/"/>
    <id>http://newpants.top/2019/09/21/多端更新hexo博客/</id>
    <published>2019-09-21T03:49:11.000Z</published>
    <updated>2019-09-25T07:37:22.020Z</updated>
    
    <content type="html"><![CDATA[<p>在公司的电脑上部署了hexo，想要家里也可以更新。就想着把整个文件夹上传到github或者coding上面，再clone下来更新。其中还是遇到蛮多坑的。主要还是hexo框架的问题。还有git这个工具其实单独拿出来就可以写好几篇教程，本文对git部分稍微介绍，只列出此过程中使用到的git命令。</p><a id="more"></a><h4 id="1-把本地hexo代码上传到github"><a href="#1-把本地hexo代码上传到github" class="headerlink" title="1.把本地hexo代码上传到github"></a>1.把本地hexo代码上传到github</h4><p>首先先把本地正常运行的hexo框架上传到github上面去。（原本想上传到coding，但是不知道coding抽什么风，直接不通。难怪有时候访问网站时都超时（网站访问的源是coding的仓库），国内这个做的还是稍微差点）</p><p>这里有几个需要注意的地方：</p><p>1）git文件夹的问题</p><p>2）上传的文件夹中需要剔除的部分，通过.gitignore文件</p><p>3）已经下载过的第三方插件问题（在最后面clone到本地时再说）</p><p>那么接下来一个个来说。</p><h5 id="1-1-git文件夹的删除"><a href="#1-1-git文件夹的删除" class="headerlink" title="1.1 .git文件夹的删除"></a>1.1 .git文件夹的删除</h5><p><img src="/2019/09/21/多端更新hexo博客/git.png" alt></p><p>如上图，git是不支持嵌套的，这就意味着，假如我在A文件夹中初始化了本地仓库git，想要上传A仓库中所有的文件夹包括其中的B文件夹，但是B文件夹我们看到也是存在git仓库的。所以这时候我们去上传文件夹时，B文件夹中的内容是不能被上传的。</p><p>所以我们使用hexo时，像themes中我们下载的next主题是从github上面下载来的，所以里面会自带一个.git文件夹。所以我们要把所有的.git文件夹删除才行。</p><p><strong><img src="/2019/09/21/多端更新hexo博客/delgit.png" alt></strong></p><p>我们平时使用hexo部署时，上传到github或者coding的文件夹里面只是包含我们使用hexo编译生成的静态页面，其中是没有我们的主题、配置文件、插件等等的文件的。我们可以看一下仓库里面的文件夹：</p><p><img src="/2019/09/21/多端更新hexo博客/gitdir.png" alt></p><p>我们本地所有的文件：</p><p><img src="/2019/09/21/多端更新hexo博客/hexodir.png" alt></p><p>其实我们上传到仓库的代码仅仅是上图中.deploy_git中的部署文件，点开就可以看到。public是hexo引擎编译生成的静态页面文件。</p><h5 id="1-2上传需要的文件夹"><a href="#1-2上传需要的文件夹" class="headerlink" title="1.2上传需要的文件夹"></a>1.2上传需要的文件夹</h5><p>我们可以在文件夹中找到一个名为”.gitignore”的文件，此文件是为了在git push过程中过滤掉不需要的文件，下面贴出我的这个文件的内容：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">.DS_Store</span><br><span class="line">Thumbs.db</span><br><span class="line">db.json</span><br><span class="line">*.log</span><br><span class="line">node_modules/</span><br><span class="line">public/</span><br><span class="line">.deploy*/</span><br><span class="line">/.deploy_git</span><br><span class="line">/public</span><br></pre></td></tr></table></figure><p>我这里除了一些默认的文件以外，还在末尾加上了：/.deploy_git和/public。这是为了不包含这两个文件夹。这两个文件夹我们是不需要的。</p><p>然后就可以初始化本地文件夹：git init 。文件夹中出现.git文件夹即可。</p><h6 id="1-2-1添加远程仓库"><a href="#1-2-1添加远程仓库" class="headerlink" title="1.2.1添加远程仓库"></a>1.2.1添加远程仓库</h6><p>在github新建一个仓库，设为私有，名字随意，清晰就好。</p><p>打开git bash：</p><p>1)测试连通性：ssh -T <a href="mailto:git@github.com" target="_blank" rel="noopener">git@github.com</a></p><p><img src="/2019/09/21/多端更新hexo博客/ssh_test.png" alt></p><p>2)添加远程仓库</p><p><img src="/2019/09/21/多端更新hexo博客/ssh2.png" alt></p><p>git remote add <em>仓库名 git地址</em></p><p>git remote -v :查看已经添加的远程仓库地址</p><h6 id="1-2-2上传文件夹到仓库"><a href="#1-2-2上传文件夹到仓库" class="headerlink" title="1.2.2上传文件夹到仓库"></a>1.2.2上传文件夹到仓库</h6><p>1) git add .    #注意后面的 “.” ，代表当前文件夹中所有文件。</p><p>2)git commit -m “说明”   #提交到本地仓库，说明随意。</p><p>3)git push -u <em>仓库名 分支</em>    #推送到远程仓库地址，仓库名要对应你上面添加的远程仓库名，分支默认是master，你也可以推送到其他分支，根据实际情况而定。</p><p><img src="/2019/09/21/多端更新hexo博客/ssh3.png" alt></p><p> 我已经推送过一次了，所以这里就简单演示一下。如果你第一次推送，会打印非常多的信息，只要没报错就万事大吉了。我的远程库名字为”github”，这里要看你自己的远程库起的名字是什么，对应替换就可以了。</p><p>这时候我们打开github的仓库进行查看，就可以看到我们推送上来所有我们需要在另外一台电脑使用的文件夹了。</p><p><img src="/2019/09/21/多端更新hexo博客/gitdir2.png" alt></p><h4 id="2-clone仓库代码到新机器上继续使用"><a href="#2-clone仓库代码到新机器上继续使用" class="headerlink" title="2.clone仓库代码到新机器上继续使用"></a>2.clone仓库代码到新机器上继续使用</h4><p>如果你是自己部署搭建的hexo环境的话，那么接下来问题就不大了。同样的遵循以下几个步骤：</p><p>1)新机添加ssh秘钥，github或coding上面添加公钥</p><p>2)测试连通性确保链接正常</p><p>3)新机下载安装   <a href="https://nodejs.org/en/" target="_blank" rel="noopener">node官网下载地址</a>        #cmd中使用 node -v 检验是否安装成功</p><p>4)新机下载安装   <a href="https://gitforwindows.org/" target="_blank" rel="noopener">git windows版本官网下载地址</a>  #同样cmd中 git –version检测。或者在菜单栏中能看到新安装的git bash就可以了</p><p> 5)安装hexo框架（切换到你要保存的目录右键选择”Git Bash here”）：npm install hexo –save</p><p> <img src="/2019/09/21/多端更新hexo博客/gitbash.png" alt></p><p>6)克隆远程仓库代码到本地</p><p><img src="/2019/09/21/多端更新hexo博客/gitclone.png" alt></p><p>看到我们需要的都在这里了：</p><p><img src="/2019/09/21/多端更新hexo博客/gitclone2.png" alt></p><p>我们先尝试 hexo g 看看编译会不会出错，果然出错了，一开始还算顺利，但是到后面提示我们有个文件找不到：</p><p><img src="/2019/09/21/多端更新hexo博客/error1.png" alt></p><p>这里的”calendar.swing”是因为我的博客中有使用了一些网上写好的插件，如提交日历插件、加载动画插件、官方提供的动态背景插件等等。</p><p>我们顺着路径去找：/themes/next/source/lib</p><p>发现路径下竟然是空的，因为之前是安装官方的文档，把几个插件下载在这个文件夹中，不知道为什么git过程中这几个文件夹没有上传上去。原本这几个文件夹中因为是git clone下来的，所以是带有”.git”文件夹，但是我删除后，再上传，这几个文件夹还是空的。</p><p>不过不是很重要，这几个文件很小，我们直接从公司的电脑复制这几个文件夹到我们家里的电脑相对应的路径中就可以了。</p><p><img src="/2019/09/21/多端更新hexo博客/error2.png" alt></p><p>然后再次编译：</p><p><img src="/2019/09/21/多端更新hexo博客/error3.png" alt></p><p>没有错误了。大功告成，再在本地”hexo s”启动一下试试，访问本地”localhost:4000”:</p><p><img src="/2019/09/21/多端更新hexo博客/end.png" alt></p><p>一切正常。终于可以在家更新博客了。不容易啊。因为其他配置都是原先那台电脑的，所以也不用更改任何东西。一样的”hexo d”部署就可以了。</p><p>不过想要实现电脑和家中的所有配置文件，文章等等都是同步的，那么还是需要借助git仓库，每次更新完文章，或者更改配置后，都要去git push和git pull保持多端同步的状态。</p><p>更多git使用教程后续：</p><p><a href>git使用教程(待更新)</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在公司的电脑上部署了hexo，想要家里也可以更新。就想着把整个文件夹上传到github或者coding上面，再clone下来更新。其中还是遇到蛮多坑的。主要还是hexo框架的问题。还有git这个工具其实单独拿出来就可以写好几篇教程，本文对git部分稍微介绍，只列出此过程中使用到的git命令。&lt;/p&gt;
    
    </summary>
    
      <category term="hexo" scheme="http://newpants.top/categories/hexo/"/>
    
    
      <category term="hexo" scheme="http://newpants.top/tags/hexo/"/>
    
      <category term="git" scheme="http://newpants.top/tags/git/"/>
    
  </entry>
  
  <entry>
    <title>ansible批量添加用户及配置用户秘钥</title>
    <link href="http://newpants.top/2019/09/12/ansible%E6%89%B9%E9%87%8F%E6%B7%BB%E5%8A%A0%E7%94%A8%E6%88%B7%E5%8F%8A%E9%85%8D%E7%BD%AE%E7%94%A8%E6%88%B7%E7%A7%98%E9%92%A5/"/>
    <id>http://newpants.top/2019/09/12/ansible批量添加用户及配置用户秘钥/</id>
    <published>2019-09-12T08:38:33.000Z</published>
    <updated>2019-09-25T10:17:46.947Z</updated>
    
    <content type="html"><![CDATA[<p>使用自动化运维工具 ansible 为多台服务器添加用户，并配置秘钥。</p><a id="more"></a><h4 id="1-ansible简介"><a href="#1-ansible简介" class="headerlink" title="1.ansible简介"></a>1.ansible简介</h4><p>ansible是一款基于python编写的自动化运维工具，多应用的场景是需要批量统一操作，类似：为多台服务器增加指定用户；更改多台服务器上某一配置文件；为多台服务器安装应用程序等等。</p><p>试想，如果是只有3台服务器，那么还好办，用xshell这类的远程工具，一台台远程过去操作就好。但是如果有30台，300台，光是想想这个数量就难免让人沮丧了。</p><p>其实市面上有很多款类似的开源软件。这里说下ansible的优缺点。</p><p>优点：</p><p>​            （1）python语言开发（意味着基本不需要搭建语言环境，开箱即用，因为大多，像red hat的centos系列装机都是自带python2.7版本的）</p><p>​            （2）基于ssh远程连接执行命令（也就意味着不需要在远程主机上安装任何代理端）</p><p>​            （3）使用YAML语法（学习简单，yaml配置文件格式清晰）</p><p>​            （4）内置模块（模块后面的配置会接触到。这里记住模块是<strong>幂等性</strong>的就可以了。幂等性举个例子就是：你在一台机器上创建用户“user01”，如果“user01”不存在，则创建他，如果“user01”存在，ansible就不会做任何事情。所以在同一台机器上执行同一个ansible playbook是安全的）</p><p>缺点：</p><p>​            （1）无web界面（其实是有<a href="https://www.ansible.com/products/tower" target="_blank" rel="noopener">ansible tower</a>可以使用的。但是据说是商业版才有的，暂时没有深入了解）</p><p>​            （2）因内置模块的特殊性，即使是简单任务也是要花一些时间来编写playbook的（其实熟悉了以后很快，重点还是前期的学习过程）</p><p>​            （3）速度中等（因为不是多通道执行任务，一个任务执行成功返回结果后才执行下一个任务）</p><p>注：上面有提到playbook，这里简单说下。直接使用ansible+命令是可以对目标主机进行操作的。但是如果命令很多，比如要先增加user01，然后为他分配组，为他增加ssh秘钥。一条一条输入显然不现实。而playbook就相当于ansible的剧本，将所有的步骤写在playbook中一次性去执行。</p><h4 id="2-ansible安装及基本文件配置"><a href="#2-ansible安装及基本文件配置" class="headerlink" title="2.ansible安装及基本文件配置"></a>2.ansible安装及基本文件配置</h4><p>ansible的安装很简单，可以通过yum方式安装。这里可以参考官网文档：<a href="https://docs.ansible.com/" target="_blank" rel="noopener">docs.ansible.com</a></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@padim ~]#yum install ansible</span><br></pre></td></tr></table></figure><p>还可以通过github下载安装等等方式。</p><p>使用yum方式安装后，默认安装目录是在<strong>/etc/ansible/</strong>下。</p><h5 id="2-1-hosts文件配置"><a href="#2-1-hosts文件配置" class="headerlink" title="2.1 hosts文件配置"></a>2.1 hosts文件配置</h5><p>这里的hosts不是linux主机上的hosts文件。是指ansible安装目录下的hosts文件，这个hosts文件就是来规定你连接的主机ip，或者主机群组的。默认位置在下面要说到的 ansible.cfg 中指定。我这里的位置是：/etc/ansible/playbooks/hosts</p><p>下面举个hosts文件的例子：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[nginx]</span><br><span class="line">192.168.40.10</span><br><span class="line">192.168.40.11</span><br><span class="line">[mysql]</span><br><span class="line">192.168.40.20</span><br><span class="line">192.168.40.21</span><br><span class="line">[all]</span><br><span class="line">192.168.40.10</span><br><span class="line">192.168.40.11</span><br><span class="line">192.168.40.20</span><br><span class="line">192.168.40.21</span><br></pre></td></tr></table></figure><h5 id="2-2-ansible-cfg文件配置"><a href="#2-2-ansible-cfg文件配置" class="headerlink" title="2.2 ansible.cfg文件配置"></a>2.2 ansible.cfg文件配置</h5><p>首先配置ansible.cfg文件，相当于整个程序的默认启动配置文件。下面是我的配置：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[defaults]</span><br><span class="line">inventory       =/etc/ansible/playbooks/hosts</span><br><span class="line">remote_user     =root</span><br><span class="line">private_key_file=/root/.ssh/my_private</span><br><span class="line">host_key_checking=False</span><br></pre></td></tr></table></figure><p>如果不在这里配置的话，等要写playbook时，是需要再配置的。所以我们这里进行默认的统一配置，有非常多可以增加的项目。这里只说明，如何使用本地的私钥来连接目标服务器上的公钥。（几台服务器上的公钥都是统一的，相当于一把钥匙开好几个锁）</p><table><thead><tr><th>参数选项</th><th>参数说明</th></tr></thead><tbody><tr><td>inventory</td><td>指定hosts文件的路径</td></tr><tr><td>remote_user</td><td>远程连接使用的用户名，此处为root</td></tr><tr><td>private_key_file</td><td>私钥文件路径</td></tr><tr><td>host_key_checking</td><td>首次连接会提示输入yes来确认连接主机。这里选择False来关闭这个提示。</td></tr></tbody></table><h4 id="3-编写playbook"><a href="#3-编写playbook" class="headerlink" title="3.编写playbook"></a>3.编写playbook</h4><p>playbook就是ansible的剧本，也是使用ansible中最重要的一环。我们把所有要进行操作的步骤，统一放在yaml文件中，让ansible去执行。</p><p>yaml文件格式编写时要注意缩进，因为yaml文件对缩进的要求是非常严格的。刚刚入门编写yaml可能会被缩进逼疯，经常调试半天还是有错误。不过只要多编写几个，熟悉了套路，yaml文件的优势就慢慢体现出来。主要是体现在易于阅读和更改。对后期维护等操作非常的有益。</p><p>下面直接贴出我的adduser.yaml配置文件，然后对文件一一进行解读：</p><h5 id="3-1-adduser-yaml"><a href="#3-1-adduser-yaml" class="headerlink" title="3.1 adduser.yaml"></a>3.1 adduser.yaml</h5><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">- name:</span> <span class="string">增加指定用户并添加秘钥</span> <span class="string">清理自动生成的秘钥</span> </span><br><span class="line">  <span class="comment">#指定远程命令的主机组</span></span><br><span class="line"><span class="attr">  hosts:</span> <span class="string">all</span> </span><br><span class="line">  <span class="comment">#动作</span></span><br><span class="line"><span class="attr">  tasks:</span> </span><br><span class="line"><span class="attr">    - name:</span> <span class="string">增加用户user01</span></span><br><span class="line">      <span class="comment">#使用模块user</span></span><br><span class="line"><span class="attr">      user:</span> </span><br><span class="line">         <span class="comment">#指定增加用户名为：</span></span><br><span class="line"><span class="attr">         name:</span> <span class="string">user01</span> </span><br><span class="line">         <span class="comment">#增加用户说明</span></span><br><span class="line"><span class="attr">         comment:</span> <span class="string">developer</span> </span><br><span class="line">         <span class="comment">#用户所属组</span></span><br><span class="line"><span class="attr">         group:</span> <span class="string">dev</span> </span><br><span class="line">         <span class="comment">#登陆所使用的shell路径</span></span><br><span class="line"><span class="attr">         shell:</span> <span class="string">/bin/bash</span> </span><br><span class="line">         <span class="comment">#是否在.ssh/路径下生成id_rsa及id_rsa.pub</span></span><br><span class="line"><span class="attr">         generate_ssh_key:</span> <span class="literal">yes</span> </span><br><span class="line">         <span class="comment">#指定生成的路径和名称，公钥自动以.pub结尾</span></span><br><span class="line"><span class="attr">         ssh_key_file:</span> <span class="string">.ssh/id_rsa</span> </span><br><span class="line">         <span class="comment">#默认值present，表示用户需要存在</span></span><br><span class="line"><span class="attr">         state:</span> <span class="string">present</span> </span><br><span class="line"><span class="attr">    - name:</span> <span class="string">复制本机192.168.50.50指定路径文件到目标服务器上</span></span><br><span class="line">      <span class="comment">#使用copy模块</span></span><br><span class="line"><span class="attr">      copy:</span> </span><br><span class="line">         <span class="comment">#源路径，本机文件路径</span></span><br><span class="line"><span class="attr">         src:</span> <span class="string">/home/padim/.ssh/authorized_keys</span> </span><br><span class="line">         <span class="comment">#目标主机路径</span></span><br><span class="line"><span class="attr">         dest:</span> <span class="string">/home/user01/.ssh/authorized_keys</span> </span><br><span class="line">         <span class="comment">#文件所有人</span></span><br><span class="line"><span class="attr">         owner:</span> <span class="string">user01</span> </span><br><span class="line">         <span class="comment">#文件所有组</span></span><br><span class="line"><span class="attr">         group:</span> <span class="string">dev</span> </span><br><span class="line">         <span class="comment">#文件权限</span></span><br><span class="line"><span class="attr">         mode:</span> <span class="string">'0600'</span> </span><br><span class="line"><span class="attr">    - name:</span> <span class="string">清理自动生成的id_rsa文件</span> </span><br><span class="line">      <span class="comment">#使用file模块</span></span><br><span class="line"><span class="attr">      file:</span> </span><br><span class="line">         <span class="comment">#指定路径，删除多个文件时使用，&#123;&#123;item&#125;&#125;为变量，不可变</span></span><br><span class="line"><span class="attr">         path:</span> <span class="string">'/home/user01/.ssh/<span class="template-variable">&#123;&#123; item &#125;&#125;</span>'</span> </span><br><span class="line">         <span class="comment">#状态，删除</span></span><br><span class="line"><span class="attr">         state:</span> <span class="string">absent</span> </span><br><span class="line">         <span class="comment">#定义变量的多个值</span></span><br><span class="line"><span class="attr">      with_items:</span></span><br><span class="line"><span class="bullet">         -</span> <span class="string">id_rsa</span></span><br><span class="line"><span class="bullet">         -</span> <span class="string">id_rsa.pub</span></span><br></pre></td></tr></table></figure><p>以上文件基本都有注释了，这里说明几个地方：</p><table><thead><tr><th>参数名称</th><th>参数说明</th></tr></thead><tbody><tr><td><strong>name</strong></td><td>类似整个文件的说明，随意填写，清楚表达即可。</td></tr><tr><td><strong>tasks</strong></td><td>步骤。每一个tasks为一步，比如上面就是在一步里面完成创建user01。如果要再删除user01，可以在下面再新建一个tasks用来删除。</td></tr><tr><td><strong>tasks中的name</strong></td><td>一样是说明性语句，可随意填写。执行playbook时这项说明语句会打印在屏幕上，告诉你playbook的进展情况。</td></tr></tbody></table><p>编辑好playbook后直接检查并运行该文件就可以了，命令如下：</p><p>检查(使用check参数)：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@padim ~]#ansible-playbook --check adduser.yaml</span><br></pre></td></tr></table></figure><p>无报错后运行：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@padim ~]#ansible-playbook adduser.yaml</span><br></pre></td></tr></table></figure><h5 id="3-2-deluser-yaml"><a href="#3-2-deluser-yaml" class="headerlink" title="3.2 deluser.yaml"></a>3.2 deluser.yaml</h5><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#删除用户</span></span><br><span class="line"><span class="attr">- name:</span> <span class="string">删除用户user01</span></span><br><span class="line">  <span class="comment">#指定执行的主机组</span></span><br><span class="line"><span class="attr">  hosts:</span> <span class="string">all</span></span><br><span class="line"><span class="attr">  tasks:</span></span><br><span class="line"><span class="attr">    - name:</span> <span class="string">删除用户user01</span></span><br><span class="line">      <span class="comment">#使用user模块</span></span><br><span class="line"><span class="attr">      user:</span>  </span><br><span class="line"><span class="attr">        name:</span> <span class="string">user01</span></span><br><span class="line">        <span class="comment">#absent参数代表删除</span></span><br><span class="line"><span class="attr">        state:</span> <span class="string">absent</span></span><br><span class="line">        <span class="comment">#删除家目录</span></span><br><span class="line"><span class="attr">        remove:</span> <span class="literal">yes</span></span><br></pre></td></tr></table></figure><h5 id="3-3关于模块"><a href="#3-3关于模块" class="headerlink" title="3.3关于模块"></a>3.3关于模块</h5><p>ansible的官方文档编写的已经是非常的详细了。而且每个功能或者说是模块的使用。官方都会在下面给出一个例子来详细说明，只要耐心的对例子进行阅读，很快就能明白模块的使用方法。下面给出几个链接供学习和参考：</p><p><a href="https://docs.ansible.com/ansible/latest/modules/list_of_all_modules.html" target="_blank" rel="noopener">ansible官方所有模块列表</a></p><p><a href="https://docs.ansible.com/ansible/latest/modules/user_module.html#user-module" target="_blank" rel="noopener">user模块</a></p><p><a href="https://docs.ansible.com/ansible/latest/modules/list_of_files_modules.html" target="_blank" rel="noopener">文件模块</a></p><p><a href="https://docs.ansible.com/ansible/latest/modules/shell_module.html#shell-module" target="_blank" rel="noopener">shell模块</a></p><p><a href="https://docs.ansible.com/ansible/latest/modules/user_module.html#user-module" target="_blank" rel="noopener">模块索引</a></p><p><a href="https://docs.ansible.com/ansible/latest/modules/copy_module.html#copy-module" target="_blank" rel="noopener">copy模块</a></p><p>因为本文旨在说明如果使用 ansible 批量批量添加用户及配置用户秘钥。所以以上列出一些相关的模块链接。如果有其他需求，对单独模块进行学习即可。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;使用自动化运维工具 ansible 为多台服务器添加用户，并配置秘钥。&lt;/p&gt;
    
    </summary>
    
      <category term="ansible" scheme="http://newpants.top/categories/ansible/"/>
    
    
      <category term="ansible" scheme="http://newpants.top/tags/ansible/"/>
    
      <category term="自动化运维" scheme="http://newpants.top/tags/%E8%87%AA%E5%8A%A8%E5%8C%96%E8%BF%90%E7%BB%B4/"/>
    
  </entry>
  
  <entry>
    <title>zabbix监控docker</title>
    <link href="http://newpants.top/2019/09/10/zabbix%E7%9B%91%E6%8E%A7docker/"/>
    <id>http://newpants.top/2019/09/10/zabbix监控docker/</id>
    <published>2019-09-10T05:53:56.000Z</published>
    <updated>2019-09-12T02:39:44.337Z</updated>
    
    <content type="html"><![CDATA[<p>使用 zabbix 对 docker 运行容器使用的 CPU 和内存情况等进行监控</p><a id="more"></a><p>官网有提供了一些监控 docker 信息的模板。具体可以通过点击 zabbix 主页的 share 进入官网网址后搜索下载，并按步骤进行安装即可（如下图）</p><p><img src="/2019/09/10/zabbix监控docker/zabbix_share1.png" alt></p><p>搜索框里直接搜索docker即可。还有各种各样的其他模板共使用。</p><p><img src="/2019/09/10/zabbix监控docker/zabbix_share2.png" alt></p><h4 id="1-zabbix监控原理"><a href="#1-zabbix监控原理" class="headerlink" title="1.zabbix监控原理"></a>1.zabbix监控原理</h4><p>本文使用自建的 python 脚本对 docker 进行监控。zabbix 监控大致原理可以分为：</p><p>增加键值 –&gt; 采集数据 –&gt;  agent 端传递键值给server端 –&gt; web 界面增加模板 –&gt; 为主机添加模板 –&gt; 添加触发器/图形等</p><h4 id="2-增加键值"><a href="#2-增加键值" class="headerlink" title="2.增加键值"></a>2.增加键值</h4><p>那第一步我们就是要来采集数据了。</p><p>采集数据有多种方式，可以是 shell 脚本、python 脚本、又或者是程序自带的信息界面</p><p>如：</p><p>redis 中： redis-cli -h 127.0.0.1 -p 端口号 -a 密码 </p><p>nginx 配置时增加’–with-http_stub_status_module’模块，配置 nginx.conf 后在地址 “<a href="http://127.0.0.1/status&quot;" target="_blank" rel="noopener">http://127.0.0.1/status&quot;</a> 中查看，诸如此类这样的命令，截取其中想要的信息保存到一个文件内读取。</p><p>注：脚本是放在 agent 端，增加键值等也是在 agent 端增加。</p><h5 id="2-1查看agent端配置"><a href="#2-1查看agent端配置" class="headerlink" title="2.1查看agent端配置"></a>2.1查看agent端配置</h5><p>首先找到 zabbix_agentd.conf 配置文件，在配置文件中搜索包含”Include”的行。如我的配置文件是：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Include=/etc/zabbix/zabbix_agentd.d/</span><br></pre></td></tr></table></figure><h5 id="2-2配置键值"><a href="#2-2配置键值" class="headerlink" title="2.2配置键值"></a>2.2配置键值</h5><p>然后在路径 /etc/zabbix/zabbix_agentd.d/ 下建立两个 python 脚本：</p><p><strong>docker_discovery.conf</strong>  （自动发现规则）</p><p><strong>docker_status.conf</strong> （获取状态的脚本）</p><p>注：自动发现规则主要是为了省事省力，试想你 docker 中有三个容器，名称分别是 nginx,node,php。那如果你一个个的去增加，工作效率极低，而是使用自动发现，通过脚本的编写来确定所有的容器名称。</p><p>docker_status.conf 文件中只要增加一行代码即可：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">UserParameter=docker_status[*],sudo /usr/bin/python /etc/zabbix/script/docker_monitor.py $1 $2</span><br></pre></td></tr></table></figure><p><strong>UserParameter :</strong> zabbix 增加自定义键值，此处不可更改</p><p><strong>docker_status[*] ：</strong>键值的名称，可以根据喜好来取名字，不过最好还是让人能一眼就看出你键值的意义。其中”[*]”代表任意值，是 shell 的语法。因为我们要监控特定容器的 CPU、负载、内存等使用的情况，最后的 $1 $2 的变量就是对此处赋值。</p><p><strong>sudo /usr/bin/python /etc/zabbix/script/docker_monitor.py ：</strong>指定了 python 的运行路径，sudo 运行（如果是 root 用户运行可去掉该项），还有我们 python 脚本的运行路径和s名称。此处为了整洁，我在 zabbix 目录下新建了 script 目录来存放这两个脚本。</p><p><strong>$1 $2 ：</strong>shell 脚本中的变量，$0 代表脚本名称，$1 $2 则是我们后面需要赋值给 docker_status[*] 的两个变量。容器名称和特定监控项（如 CPU 使用率，内存使用率等）</p><p>docker_discovery.conf 和上面的基本相同，不过是脚本不同：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">UserParameter=docker_discovery,python /etc/zabbix/script/docker_discovery.py</span><br></pre></td></tr></table></figure><h4 id="3-增加-python-脚本"><a href="#3-增加-python-脚本" class="headerlink" title="3.增加 python 脚本"></a>3.增加 python 脚本</h4><p>按照2中的路径，在 /etc/zabbix/script/ 下建立： docker_discovery.py 和 docker_monitor.py</p><p>docker_discovery.py：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> simplejson <span class="keyword">as</span> json</span><br><span class="line">tname=os.popen(<span class="string">"""sudo docker ps | grep -v 'CONTAINER ID'|awk &#123;'print $NF'&#125;"""</span>)</span><br><span class="line">container_name=[]</span><br><span class="line"><span class="keyword">for</span> container <span class="keyword">in</span> tname.readlines():</span><br><span class="line">        rname=os.path.basename(container.strip())</span><br><span class="line">        container_name+=[&#123;<span class="string">'&#123;#CONTAINERNAME&#125;'</span>:rname&#125;]</span><br><span class="line"><span class="keyword">print</span> json.dumps(&#123;<span class="string">'data'</span>:container_name&#125;,sort_keys=<span class="literal">True</span>,indent=<span class="number">4</span>,separators=(<span class="string">','</span>,<span class="string">':'</span>))</span><br></pre></td></tr></table></figure><p>docker_monitor.py:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="keyword">import</span> docker</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> subprocess</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">check_container_stats</span><span class="params">(container_name,collect_item)</span>:</span></span><br><span class="line">        container_collect=docker_client.containers.get(container_name).stats(stream=<span class="literal">True</span>)</span><br><span class="line">        old_result=eval(container_collect.next())</span><br><span class="line">        new_result=eval(container_collect.next())</span><br><span class="line">        container_collect.close()</span><br><span class="line">        <span class="comment">#CPU使用百分比</span></span><br><span class="line">        <span class="keyword">if</span> collect_item == <span class="string">'cpu_percent'</span>:</span><br><span class="line">                cpu_total_usage=new_result[<span class="string">'cpu_stats'</span>][<span class="string">'cpu_usage'</span>][<span class="string">'total_usage'</span>] - old_result[<span class="string">'cpu_stats'</span>][<span class="string">'cpu_usage'</span>][<span class="string">'total_usage'</span>]</span><br><span class="line">                cpu_system_uasge=new_result[<span class="string">'cpu_stats'</span>][<span class="string">'system_cpu_usage'</span>] - old_result[<span class="string">'cpu_stats'</span>][<span class="string">'system_cpu_usage'</span>]</span><br><span class="line">                cpu_num=len(old_result[<span class="string">'cpu_stats'</span>][<span class="string">'cpu_usage'</span>][<span class="string">'percpu_usage'</span>])</span><br><span class="line">                result=round((float(cpu_total_usage)/float(cpu_system_uasge))*cpu_num*<span class="number">100.0</span>,<span class="number">2</span>)</span><br><span class="line">        <span class="comment">#内存使用量</span></span><br><span class="line">        <span class="keyword">elif</span> collect_item == <span class="string">'mem_usage'</span>:</span><br><span class="line">                result=new_result[<span class="string">'memory_stats'</span>][<span class="string">'usage'</span>]</span><br><span class="line"><span class="comment">#内存使用百分比</span></span><br><span class="line">        <span class="keyword">elif</span> collect_item == <span class="string">'mem_percent'</span>:</span><br><span class="line">                mem_usage=new_result[<span class="string">'memory_stats'</span>][<span class="string">'usage'</span>]</span><br><span class="line">                mem_limit=new_result[<span class="string">'memory_stats'</span>][<span class="string">'limit'</span>]</span><br><span class="line">                result=round(float(mem_usage)/float(mem_limit)*<span class="number">100.0</span>,<span class="number">2</span>)</span><br><span class="line">        <span class="keyword">return</span> result</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">        docker_client = docker.DockerClient(base_url=<span class="string">'unix://var/run/docker.sock'</span>, version=<span class="string">'1.27'</span>)</span><br><span class="line">        container_name=sys.argv[<span class="number">1</span>]</span><br><span class="line">        collect_item=sys.argv[<span class="number">2</span>]</span><br><span class="line">        <span class="keyword">print</span> check_container_stats(container_name,collect_item)</span><br></pre></td></tr></table></figure><p>python 版本是使用的是：Python 2.7.5</p><p>脚本的编写这里就不详细说了，如果有 python 基础，大部分的代码还是看得懂的。</p><p>建议直接复制上面两个脚本，并且记得下载脚本中所需的 python 包：<strong>docker、simplejson、subprocess</strong>等。并且增加脚本的可执行权限。否则会报错。</p><p>可以直接在终端执行”python /etc/zabbix/script/docker_discovery.py”检验代码是否有误，如下图：</p><p><img src="/2019/09/10/zabbix监控docker/docker_discovery.png" alt></p><p>可以看到我这里已经获取了三个容器，并且分别打印了他们的名称（就如同我们使用 docker ps 看到的一样）</p><p>docker_monitor.py 直接运行可不行，会报错：</p><p><img src="/2019/09/10/zabbix监控docker/docker_monitor1.png" alt></p><p>提示我们超出列表值，这是因为我们没有在后面接指定的”<strong>container_name</strong>“和”<strong>collect_item</strong>“。这也是”docker_status.conf”文件中为什么要在最后增加”$1 $2”的原因。</p><p>增加指定的两个变量后：</p><p><img src="/2019/09/10/zabbix监控docker/docker_monitor2.png" alt></p><p><strong>tb-nginx:</strong> 运行 docker_discovery.py获取到的容器名字</p><p><strong>cpu_percent:</strong>  docker_monitor.py中编写的”collect_item”值</p><p>可以看到返回1.45。即我们容器名为”tb-nginx“的 CPU 使用占比为：1.45%</p><h4 id="4-server端进行简单测试"><a href="#4-server端进行简单测试" class="headerlink" title="4.server端进行简单测试"></a>4.server端进行简单测试</h4><p>以上的脚本都运行正常后，重启 zabbix-agent (不重启键值是不生效的)</p><p>然后在 zabbix-server 终端我们可以使用 zabbix 官方提供的 zabbix_get 进行测试（如果没有需要下载）</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">zabbix_get -s 192.168.40.10 -k docker_status[tb-nginx,mem_percent]</span><br></pre></td></tr></table></figure><p>192.168.40.10 ：就是你刚才增加键值的 agent 端，根据实际情况更改。</p><p>如果有正常返回值，那么就可以了，接下来配置 web 端。</p><h4 id="5-web界面增加监控模板"><a href="#5-web界面增加监控模板" class="headerlink" title="5.web界面增加监控模板"></a>5.web界面增加监控模板</h4><p>打开 zabbix 的 web 界面，配置 –&gt; 模板 –&gt; 创建模板 </p><p><img src="/2019/09/10/zabbix监控docker/web1.png" alt></p><p>我这里已经添加好了，可以看到”已连接到”那里已经链接了几个模板。</p><p>名称、应用集、模板群组等这些都可根据个人喜好设定，方便管理和识别即可。</p><p>比较关键的是接下来”自动发现规则”这里。</p><h5 id="5-1创建发现规则"><a href="#5-1创建发现规则" class="headerlink" title="5.1创建发现规则"></a>5.1创建发现规则</h5><p><img src="/2019/09/10/zabbix监控docker/web2.png" alt></p><p><img src="/2019/09/10/zabbix监控docker/web3.png" alt></p><h5 id="5-2添加监控项原形"><a href="#5-2添加监控项原形" class="headerlink" title="5.2添加监控项原形"></a>5.2添加监控项原形</h5><p><img src="/2019/09/10/zabbix监控docker/web4.png" alt></p><p>两个监控项原形创建：</p><p><img src="/2019/09/10/zabbix监控docker/web5.png" alt></p><p><img src="/2019/09/10/zabbix监控docker/web6.png" alt></p><h4 id="6-为主机链接模板"><a href="#6-为主机链接模板" class="headerlink" title="6.为主机链接模板"></a>6.为主机链接模板</h4><p>找到需要监控的主机，添加模板：</p><p><img src="/2019/09/10/zabbix监控docker/web7.png" alt></p><p>添加后点击更新。然后稍微等几分钟。点进监控项里查看，就可以看到我们自动发现的容器了。</p><p><img src="/2019/09/10/zabbix监控docker/web8.png" alt></p><p>有了监控项且没有报错，可以在 zabbix web 界面 –&gt;监测中 –&gt; 最新数据 中查看对应的值了。</p><p>然后接下来可以增加触发器、图形这些的。我这里图形是手动添加的，当然也可以自动添加，自动添加就是在增加 “docker自动发现模板”那里，再增加一个图形的模板。我这里需求的不太多，就手动添加了，效果图如下：</p><p><img src="/2019/09/10/zabbix监控docker/web10.png" alt></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;使用 zabbix 对 docker 运行容器使用的 CPU 和内存情况等进行监控&lt;/p&gt;
    
    </summary>
    
      <category term="zabbix" scheme="http://newpants.top/categories/zabbix/"/>
    
    
      <category term="zabbix" scheme="http://newpants.top/tags/zabbix/"/>
    
      <category term="docker" scheme="http://newpants.top/tags/docker/"/>
    
  </entry>
  
  <entry>
    <title>filebeat.yml配置详解</title>
    <link href="http://newpants.top/2019/09/06/filebeat-yml%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/"/>
    <id>http://newpants.top/2019/09/06/filebeat-yml配置详解/</id>
    <published>2019-09-06T08:16:36.000Z</published>
    <updated>2019-09-25T10:18:38.585Z</updated>
    
    <content type="html"><![CDATA[<p>filebeat.yml配置详解</p><a id="more"></a><h4 id="1-filebeat介绍"><a href="#1-filebeat介绍" class="headerlink" title="1.filebeat介绍"></a>1.filebeat介绍</h4><p>filebeat 是 elastic beats 中的一个轻量型的采集器。beats 包含很多系列，如官网下图：</p><p><img src="/2019/09/06/filebeat-yml配置详解/beats.png" alt="beat系列"></p><p>基本从名字就可以看得出来其对应的功能。这里我们使用 filebeat 主要针对文件（也就是需要采集的log日志) 来进行采集。</p><p>filebeat 的原理是开启一个 prospectors(收割者)，对文件逐行进行采集。</p><h4 id="2-示例文件及配置解析"><a href="#2-示例文件及配置解析" class="headerlink" title="2.示例文件及配置解析"></a>2.示例文件及配置解析</h4><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">filebeat.prospectors:</span><span class="comment">#采集 abc.com 下 nginx 的 access 日志 </span></span><br><span class="line"><span class="bullet">-</span> <span class="string">type</span> <span class="string">:</span> <span class="string">log</span></span><br><span class="line"><span class="attr">  enabled:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">  paths:</span></span><br><span class="line"><span class="bullet">     -</span> <span class="string">/data/server/wwwlog/nginx/abc.com.access.log</span></span><br><span class="line"><span class="attr">  tags:</span> <span class="string">["nginx_access"]</span></span><br><span class="line"><span class="attr">  tail_files:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">  scan_frequency:</span> <span class="number">30</span><span class="string">s</span></span><br><span class="line"><span class="attr">  fields:</span></span><br><span class="line"><span class="attr">    host:</span> <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span></span><br><span class="line"><span class="attr">    project:</span> <span class="string">abc.com</span></span><br></pre></td></tr></table></figure><table><thead><tr><th>参数选项</th><th>参数说明</th></tr></thead><tbody><tr><td>filebeat.prospectors</td><td>文件开头指定 filebeat 的采集方式，此处使用 prospectors</td></tr><tr><td>type : log</td><td>类型为：log</td></tr><tr><td>enabled: true</td><td>true 为开启，false 为关闭</td></tr><tr><td>paths:</td><td>指定路径</td></tr><tr><td>tags:</td><td>打标签，自定义名称，为后续在kibana查看时提供过滤与分类的效果</td></tr><tr><td>tail_files: true</td><td>开启此项，代表采集从文件最底部开始，选择 false 时 filebeat 会从文件头部开始采集</td></tr><tr><td>scan_frequency: 30s</td><td>对文件的扫描间隔（每30秒扫描一次文件是否改动，根据实际情况改动）</td></tr><tr><td>fields:</td><td>添加字段（用于 elasticsearch 过滤、分类，以及 kibana 中查看）</td></tr></tbody></table><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="bullet">-</span> <span class="string">type</span> <span class="string">:</span> <span class="string">log</span><span class="comment">#采集 abc.com 下 nginx 的 error 日志</span></span><br><span class="line"><span class="attr">  enabled:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">  paths:</span></span><br><span class="line"><span class="bullet">     -</span> <span class="string">/data/server/wwwlog/nginx/abc.com.error.log</span></span><br><span class="line"><span class="attr">  tags:</span> <span class="string">["nginx_error"]</span></span><br><span class="line"><span class="attr">  tail_files:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">  scan_frequency:</span> <span class="number">30</span><span class="string">s</span></span><br><span class="line"><span class="attr">  fields:</span></span><br><span class="line"><span class="attr">    host:</span> <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span></span><br><span class="line"><span class="attr">    project:</span> <span class="string">abc.com</span></span><br></pre></td></tr></table></figure><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="bullet">-</span> <span class="string">type</span> <span class="string">:</span> <span class="string">log</span><span class="comment">#采集 abc.com 下 nginx 的 cache 日志</span></span><br><span class="line"><span class="attr">  enabled:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">  paths:</span></span><br><span class="line"><span class="bullet">     -</span> <span class="string">/data/server/wwwcache/abc.com.cache/application.log</span></span><br><span class="line">  <span class="string">multiline.pattern:</span> <span class="string">'^[0-9]&#123;4&#125;/[0-9]&#123;2&#125;/[0-9]&#123;2&#125;'</span></span><br><span class="line">  <span class="string">multiline.negate:</span> <span class="literal">true</span></span><br><span class="line">  <span class="string">multiline.match:</span> <span class="string">after</span></span><br><span class="line"><span class="attr">  tags:</span> <span class="string">["wwwcache"]</span></span><br><span class="line"><span class="attr">  tail_files:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">  scan_frequency:</span> <span class="number">30</span><span class="string">s</span></span><br><span class="line"><span class="attr">  fields:</span></span><br><span class="line"><span class="attr">    host:</span> <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span></span><br><span class="line"><span class="attr">    project:</span> <span class="string">abc.com</span></span><br></pre></td></tr></table></figure><p>  multiline.pattern: ‘^[0-9]{4}/[0-9]{2}/[0-9]{2}’<br>  multiline.negate: true<br>  multiline.match: after</p><p>以上通过正规表达式，对日志多行进行合并。如下图效果(根据实际情况配置正规表达式，可对任意行进行合并保存在一个 message 中)：</p><p>cache 中日志不需要逐行采集，需要采集某一段</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span>2 /data/server/wwwroot/tui.tongbu.com/index.php(28): CApplication-&gt;run()</span><br><span class="line"><span class="meta">#</span>3 &#123;main&#125;</span><br><span class="line">REQUEST_URI=/apple-touch-icon-120x120-precomposed.png</span><br><span class="line">---</span><br><span class="line">2019/09/06 16:47:32 [error] [exception.CHttpException.404] CHttpException: Unable to resolve the request "apple-touch-icon-120x120.png". in /data/server/wwwroot/yii/framework/web/CWebApplication.php:286</span><br><span class="line">Stack trace:</span><br><span class="line"><span class="meta">#</span>0 /data/server/wwwroot/yii/framework/web/CWebApplication.php(141): CWebApplication-&gt;runController('apple-touch-ico...')</span><br><span class="line"><span class="meta">#</span>1 /data/server/wwwroot/yii/framework/base/CApplication.php(185): CWebApplication-&gt;processRequest()</span><br><span class="line"><span class="meta">#</span>2 /data/server/wwwroot/tui.tongbu.com/index.php(28): CApplication-&gt;run()</span><br><span class="line"><span class="meta">#</span>3 &#123;main&#125;</span><br><span class="line">REQUEST_URI=/apple-touch-icon-120x120.png</span><br><span class="line">---</span><br></pre></td></tr></table></figure><p>增加正规表达式后：</p><p><img src="/2019/09/06/filebeat-yml配置详解/wwwcache_kibana.png" alt="合并多行日志"></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;filebeat.yml配置详解&lt;/p&gt;
    
    </summary>
    
      <category term="ELK" scheme="http://newpants.top/categories/ELK/"/>
    
    
      <category term="filebeat" scheme="http://newpants.top/tags/filebeat/"/>
    
  </entry>
  
  <entry>
    <title>ELK+filebeat日志采集（搭建篇）</title>
    <link href="http://newpants.top/2019/08/30/ElkDeploy/"/>
    <id>http://newpants.top/2019/08/30/ElkDeploy/</id>
    <published>2019-08-30T03:14:03.000Z</published>
    <updated>2019-09-12T09:09:28.868Z</updated>
    
    <content type="html"><![CDATA[<p>ELK+filebeat日志采集（搭建篇）</p><a id="more"></a><p><img src="/2019/08/30/ElkDeploy/elastic_top.png" alt></p><p>这里不进行配置文件配置更改的说明。全部使用默认配置文件，此篇主要旨在介绍正常安装及运行。</p><p><strong>每种程序的单独介绍可在以下查看（常用的一些配置和概念）：</strong></p><p><strong><a href>elasticsearch介绍及配置说明(待更新)</a></strong></p><p><strong><a href>logstash介绍配置说明(待更新)</a></strong></p><p><strong><a href>kibana介绍及配置说明(待更新)</a></strong></p><p><strong><a href="https://newpants.top/2019/09/06/filebeat-yml配置详解">filebeat介绍及配置说明</a></strong></p><p><a href="https://www.elastic.co/guide/index.html" target="_blank" rel="noopener">elastic官方文档地址</a>   #官方文档说明的都很详细</p><h3 id="1-基本架构图"><a href="#1-基本架构图" class="headerlink" title="1.基本架构图"></a>1.基本架构图</h3><p><img src="/2019/08/30/ElkDeploy/Architecture_diagram.png" alt></p><p>elasticsearch： 一款基于 Lucene 的搜索服务器。可以理解为数据库，我们日后将要采集的日志都将储存在这里。</p><p>logstash： logstash 的主要功能是将数据按照我们的要求进行过滤和筛选。完成我们制定的工作发送给 elasticsearch 后以便我们查询。</p><p>kibana： 基于web的查看页面。已经开始提供越来越多的 api。以前的 elasticsearch 还需要 elasticsearch-head 或者直接服务器上面进行操作和查询。现 kibana 的控制台基本可以满足大部分需求。</p><p>filebeat： 采集工具。因为 logstash 非常的消耗系统资源，为了不影响业务服务器，使用 filebeat ，他非常轻量。基本不占用什么空间和系统资源。</p><p>大致流程：filebeat（采集）–&gt; logstash（过滤）–&gt; elasticsearch（储存）–&gt; kibana(查看)</p><h3 id="2-此例版本号说明"><a href="#2-此例版本号说明" class="headerlink" title="2.此例版本号说明"></a>2.此例版本号说明</h3><table><thead><tr><th>软件</th><th>Java</th><th>Elasticsearch</th><th>Logstash</th><th>Kibana</th><th>Filebeat</th></tr></thead><tbody><tr><td>版本号</td><td>1.8.0_181</td><td>6.7.1</td><td>6.7.1</td><td>6.7.1</td><td>6.7.1</td></tr></tbody></table><p>因为采集量不大，且公司内部部分需求。所以此篇文章是在一台centos7服务器上搭建elasticsearch+logstash+kibana 。其他需要采集的机器上安装 filebeat 进行采集。</p><p>这里需要注意的是，elasticsearch 和 logstash 需要在 java 环境下运行。</p><p><strong>以下安装过程简单带过，网上已经有了很多，遇到问题可以简单进行百度分析。（官方建议最好保持elk+filebeat版本一致性，以避免不可预估的情况发生）</strong></p><h3 id="3-JAVA-环境配置"><a href="#3-JAVA-环境配置" class="headerlink" title="3. JAVA 环境配置"></a>3. JAVA 环境配置</h3><p>此例使用压缩包形式安装，在<a href="https://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html" target="_blank" rel="noopener">orcale官网jdk下载</a>，按照需求选择需要下载的jdk版本，此例使用 jdk-8u201-linux-x64.tar.gz</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">tar -xvzf jdk-8u201-linux-x64.tar.gz     #解压</span><br><span class="line">mv jdk1.8.0_201/ /usr/jdk1.8.0_201       #移动解压包至/usr下</span><br><span class="line"></span><br><span class="line">vim /etc/profile     #编辑系统配置文件，添加 如下java 环境变量</span><br><span class="line">export JAVA_HOME=/usr/jdk1.8.0_201  #如果不生效，在jdk1.8.0_201加“/”，目录按照实际情况</span><br><span class="line">export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar</span><br><span class="line">export PATH=$PATH:$JAVA_HOME/bin</span><br><span class="line"></span><br><span class="line">source /etc/profile                       #重新加载环境变量</span><br><span class="line">java -version                              #验证</span><br></pre></td></tr></table></figure><h3 id="4-RPM形式安装elk"><a href="#4-RPM形式安装elk" class="headerlink" title="4.RPM形式安装elk"></a>4.RPM形式安装elk</h3><p>在elastic官网：<a href="https://www.elastic.co/cn/" target="_blank" rel="noopener">elastic官网</a>，找到产品相应的下载页面。下载rpm包（当然也可以使用yum或者压缩包形式安装，个人认为rpm比较方便，关键在于可以统一版本）</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">rpm -ivh elasticsearch-6.7.1-x86_64.rpm</span><br><span class="line">rpm -ivh logstash-6.7.1.rpm</span><br><span class="line">rpm -ivh kibana-6.7.1-x86_64.rpm</span><br></pre></td></tr></table></figure><p>因资源有限且需求量不大，故本例三种程序都安装在一台 linux centos7 上。安装完成后，查看程序是否正常启动即可。启动顺序最好按照： </p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">systemctl start elasticsearch</span><br><span class="line">systemctl start logstash</span><br><span class="line">systemctl start kibana</span><br></pre></td></tr></table></figure><p>查看是否安装并启动成功</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">netstat -tunlp | grep 9200     #elasticsearch默认开放端口，有返回如下结果代表端口已启动</span><br><span class="line">tcp6     0      0  127.0.0.1:9200          :::*                LISTEN      12427/java</span><br><span class="line"></span><br><span class="line">netstat -tunlp | grep 9600#logstash默认开放端口，有返回如下结果代表端口已启动</span><br><span class="line">tcp6     0      0  127.0.0.1:9600          :::*                LISTEN      17905/java</span><br><span class="line"></span><br><span class="line">netstat -tunlp | grep 5601#kibana默认开放端口，有返回如下结果代表端口已启动</span><br><span class="line">tcp     0      0   127.0.0.1:5601          :::*                LISTEN      4666/node</span><br></pre></td></tr></table></figure><p>此时通过浏览器访问 127.0.0.1:9200 返回类似如下页面，证明 elasticsearch 安装并正常启动：</p><p><img src="/2019/08/30/ElkDeploy/elasticsearch_start.png" alt="4.elasticsearch_start.png"></p><p>此时通过浏览器访问 127.0.0.1:5601 即可看到 kibana 页面：</p><p><img src="/2019/08/30/ElkDeploy/kibana_start.png" alt="4.kibana_start.png"></p><p>logstash的验证相比前两种不太一样</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@study ~]# whereis logstash  #先查看logstash安装的默认位置</span><br><span class="line">logstash: /etc/logstash /usr/share/logstash</span><br><span class="line"></span><br><span class="line">#执行以下命令。说明：input和output是logstash的两个插件，stdin和stdout分别代表了标准输入和标准输出</span><br><span class="line">[root@study ~]# /usr/share/logstash/bin/logstash -e &apos;input &#123; stdin &#123; &#125; &#125; output &#123; stdout &#123; &#125;&#125;&apos;</span><br></pre></td></tr></table></figure><p>看到 {:port =&gt;9600}，我们在光标等待处随便输入点文字</p><p><img src="/2019/08/30/ElkDeploy/logstash-input.png" alt="logstash_input.png"></p><p>如果类似消息输出到屏幕则正常：</p><p><img src="/2019/08/30/ElkDeploy/logstash-output.png" alt></p><p>此时我们还没有用 filebeat 来收集日志，所以也没有生成对应的索引。故此时看到的都是空的。接来下就介绍在需要采集的机器上安装 filebeat 采集日志。</p><h3 id="5-安装-filebeat"><a href="#5-安装-filebeat" class="headerlink" title="5. 安装 filebeat"></a>5. 安装 filebeat</h3><p>在目标采集机器上安装filebeat。因采集机器不同，分为 linux 和 windows 。</p><p>linux：</p><p>安装方式：RPM安装</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@study ~]#rpm -ivh filebeat-6.7.1-x86_64.rpm</span><br><span class="line">[root@study ~]#systemctl start filebeat</span><br></pre></td></tr></table></figure><p>对 filebeat.yml 进行简单的配置：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">filebeat.prospectors:  </span><br><span class="line"> - type : log</span><br><span class="line">   enabled: true  #选择true代表开启</span><br><span class="line">   paths:         #路径</span><br><span class="line">     - /data/*.log #所有.log结尾的日志</span><br><span class="line">   fields:#自定义字段，便于区分</span><br><span class="line">      host: 127.0.0.1</span><br><span class="line">   tail_files: true#从尾部开始采集，若选择false则会从头到尾把日志每行都读取</span><br><span class="line">   scan_frequency: 30s#扫描间隔</span><br><span class="line">   exclude_lines: [&quot;^#&quot;]#正则表达式：排除空行</span><br><span class="line">   tags: [&quot;nginx&quot;]#添加tags</span><br><span class="line">output.logstash:#输出插件到logstash</span><br><span class="line"> hosts: [&quot;127.0.0.1:5044&quot;]#hosts地址 本机为测试在本机上安装filebeat。按照实际情况填写</span><br></pre></td></tr></table></figure><p>对 filebeat.yml 文件进行测试：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@study ~]#cd 到filebeat的安装目录</span><br><span class="line">[root@study ~]#./filebeat test config#测试配置文件正确性</span><br><span class="line">[root@study ~]#./filebeat test output#测试配置文件输出的正确性(需要在开启logstash并且指定开放5044端口的前提下，后面会介绍logstash配置开放5044端口)</span><br><span class="line">如果存在异常会返回error。根据error进行调整。若全部正常，则重新启动filebeat</span><br><span class="line">[root@study ~]#systemctl restart filebeat</span><br></pre></td></tr></table></figure><p>windows:</p><p>安装方式：压缩包安装成系统服务</p><p>下载 filebeat-6.7.1-windows-x86_64.zip 解压到指定文件夹，配置文件基本于上述 linux 一样，”paths: “需要更改一下。其他的测试配置文件都相同。下面主要说下把 filebeat 安装成 windows 的服务启动项。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">1.将zip文件内容解压到C：\Program Files(或者其他路径，如果为其他路径要修改install-service-filebeat文件中的路径地址）</span><br><span class="line">2.将filebeat-&lt;version&gt;-windows目录重新命名为filebeat（必须为filebeat）</span><br><span class="line">3.以管理员身份打开PowerShell提示符</span><br><span class="line">4.在PowerShell下将Filebeat安装成Windows服务：</span><br><span class="line">cd ‘c:\Program Files\Filebeat’</span><br><span class="line">.\install-service-filebeat.ps1</span><br><span class="line">5.如果系统禁止脚本执行，则需要为当前会话设置执行策略以允许脚本执行，例如：</span><br><span class="line">PowerShell.exe -ExecutionPolicy UnRestricted -File .\install-service-filebeat.ps1</span><br></pre></td></tr></table></figure><p>这是在 windows 的服务中就可以看到名为 filebeat 的服务启动项了。启动即可。</p><h3 id="6-配置文件证明连通性"><a href="#6-配置文件证明连通性" class="headerlink" title="6.配置文件证明连通性"></a>6.配置文件证明连通性</h3><p>上述 filebeat.yml 已经配置了输出文件到 logstash 的 5044 端口。5044端口是默认端口，此端口可随意更改，只要该端口可以通就可以。如果添加端口后无法进行通讯，修改防火墙策略增加端口放行，或直接关闭防火墙测试。</p><h4 id="6-1配置-logstash-yml-文件："><a href="#6-1配置-logstash-yml-文件：" class="headerlink" title="6.1配置 logstash.yml 文件："></a>6.1配置 logstash.yml 文件：</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@study ~]#vim /etc/logstash/config/logstash.yml</span><br><span class="line"><span class="meta">#</span>修改或添加：</span><br><span class="line">http.host: "127.0.0.1"  #主机通讯地址，按实际情况而定</span><br><span class="line">http.port: 9600  #开放端口，默认端口，可更改</span><br><span class="line">path.config: /etc/logstash/conf.d/*.conf #指定配置文件路径</span><br></pre></td></tr></table></figure><p>然后我们在指定路径下配置一个名为 /etc/logstash/conf.d/test.conf 的文件如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">input&#123;    #input插件指定由beats输入，且开放端口号为：5044</span><br><span class="line"> beats&#123;</span><br><span class="line">   port =&gt; 5044</span><br><span class="line"> &#125;</span><br><span class="line">&#125;</span><br><span class="line">output &#123;</span><br><span class="line">        stdout &#123;</span><br><span class="line">                codec =&gt; rubydebug  #输出到当前屏幕，调试用。后面可以关掉</span><br><span class="line">        &#125;</span><br><span class="line">        elasticsearch&#123;#输出到 elasticsearch</span><br><span class="line">   hosts =&gt; ["127.0.0.1:9200"]#elasticsearch 的主机地址和端口号</span><br><span class="line">    index =&gt; "127.0.0.1-%&#123;+YYYY.MM&#125;"#自定义索引名称，如不指定，则默认 logstash*</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="6-2配置elasticsearch-yml"><a href="#6-2配置elasticsearch-yml" class="headerlink" title="6.2配置elasticsearch.yml"></a>6.2配置elasticsearch.yml</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span>在elasticsearch.yml添加或修改如下内容</span><br><span class="line">network.host: 127.0.0.1#主机地址</span><br><span class="line">http.port: 9200#主机开放端口</span><br></pre></td></tr></table></figure><h4 id="6-3配置kibana-yml"><a href="#6-3配置kibana-yml" class="headerlink" title="6.3配置kibana.yml"></a>6.3配置kibana.yml</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">server.port: 5601    #kibana开放端口</span><br><span class="line">server.host: "127.0.0.1"#kibana主机地址</span><br><span class="line">elasticsearch.hosts: ["http://127.0.0.1:9200"]#kibana连接到的elasticsearch的主机地址及端口号</span><br></pre></td></tr></table></figure><h3 id="7-打开kibana添加索引验证"><a href="#7-打开kibana添加索引验证" class="headerlink" title="7.打开kibana添加索引验证"></a>7.打开kibana添加索引验证</h3><p>如果一切顺利。重启这些服务。等待都完全启动后。在 filebeat 采集的路径日志中随便输入一些文字来验证。</p><p><strong>注：要使用 echo “xxx” &gt;&gt;  /data/*.log 的形式，而不是 vim 之后添加。因为filebeat是记录着文件的 PID 号。vim 打开保存后会找不到之前的文件 PID。故会重新采集指定路径的文件，造成每次都是从头开始读行文件。而 echo 不会改变文件的 PID 号。</strong></p><p> 如果在<strong>kibana-&gt;管理-&gt;创建索引模式</strong>中可以看到你指定的名为“127.0.0.1-*”的索引。就代表 elk+filebeat 全部运行成功了。</p><p><img src="/2019/08/30/ElkDeploy/kibana_index.png" alt="7.kibana_index.png"></p><p>(我这里没有截图，偷个懒，就用公司已经在用的索引作为图片说明了)</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;ELK+filebeat日志采集（搭建篇）&lt;/p&gt;
    
    </summary>
    
      <category term="ELK" scheme="http://newpants.top/categories/ELK/"/>
    
    
      <category term="filebeat" scheme="http://newpants.top/tags/filebeat/"/>
    
      <category term="elasticsearch" scheme="http://newpants.top/tags/elasticsearch/"/>
    
      <category term="logstash" scheme="http://newpants.top/tags/logstash/"/>
    
      <category term="kibana" scheme="http://newpants.top/tags/kibana/"/>
    
  </entry>
  
  <entry>
    <title>new pants</title>
    <link href="http://newpants.top/2019/08/28/new-pants/"/>
    <id>http://newpants.top/2019/08/28/new-pants/</id>
    <published>2019-08-28T08:39:41.000Z</published>
    <updated>2019-09-25T07:48:30.132Z</updated>
    
    <content type="html"><![CDATA[<p>生命因你而火热</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;生命因你而火热&lt;/p&gt;

      
    
    </summary>
    
      <category term="测试" scheme="http://newpants.top/categories/%E6%B5%8B%E8%AF%95/"/>
    
    
      <category term="pants" scheme="http://newpants.top/tags/pants/"/>
    
  </entry>
  
</feed>
