<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>NewPants</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://newpants.top/"/>
  <updated>2019-09-11T03:33:40.519Z</updated>
  <id>http://newpants.top/</id>
  
  <author>
    <name>未完成</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>zabbix监控docker</title>
    <link href="http://newpants.top/2019/09/10/zabbix%E7%9B%91%E6%8E%A7docker/"/>
    <id>http://newpants.top/2019/09/10/zabbix监控docker/</id>
    <published>2019-09-10T05:53:56.000Z</published>
    <updated>2019-09-11T03:33:40.519Z</updated>
    
    <content type="html"><![CDATA[<p>使用 zabbix 对 docker 运行容器使用的 CPU 和内存情况等进行监控</p><a id="more"></a><p>官网有提供了一些监控 docker 信息的模板。具体可以通过点击 zabbix 主页的 share 进入官网网址后搜索下载，并按步骤进行安装即可（如下图）</p><p><img src="/2019/09/10/zabbix监控docker/zabbix_share1.png" alt></p><p>搜索框里直接搜索docker即可。还有各种各样的其他模板共使用。</p><p><img src="/2019/09/10/zabbix监控docker/zabbix_share2.png" alt></p><h4 id="1-zabbix监控原理"><a href="#1-zabbix监控原理" class="headerlink" title="1.zabbix监控原理"></a>1.zabbix监控原理</h4><p>本文使用自建的 python 脚本对 docker 进行监控。zabbix 监控大致原理可以分为：</p><p>增加键值 –&gt; 采集数据 –&gt;  agent 端传递键值给server端 –&gt; web 界面增加模板 –&gt; 为主机添加模板 –&gt; 添加触发器/图形等</p><h4 id="2-增加键值"><a href="#2-增加键值" class="headerlink" title="2.增加键值"></a>2.增加键值</h4><p>那第一步我们就是要来采集数据了。</p><p>采集数据有多种方式，可以是 shell 脚本、python 脚本、又或者是程序自带的信息界面</p><p>如：</p><p>redis 中： redis-cli -h 127.0.0.1 -p 端口号 -a 密码 </p><p>nginx 配置时增加’–with-http_stub_status_module’模块，配置 nginx.conf 后在地址 “<a href="http://127.0.0.1/status&quot;" target="_blank" rel="noopener">http://127.0.0.1/status&quot;</a> 中查看，诸如此类这样的命令，截取其中想要的信息保存到一个文件内读取。</p><p>注：脚本是放在 agent 端，增加键值等也是在 agent 端增加。</p><h5 id="2-1查看agent端配置"><a href="#2-1查看agent端配置" class="headerlink" title="2.1查看agent端配置"></a>2.1查看agent端配置</h5><p>首先找到 zabbix_agentd.conf 配置文件，在配置文件中搜索包含”Include”的行。如我的配置文件是：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Include=/etc/zabbix/zabbix_agentd.d/</span><br></pre></td></tr></table></figure><h5 id="2-2配置键值"><a href="#2-2配置键值" class="headerlink" title="2.2配置键值"></a>2.2配置键值</h5><p>然后在路径 /etc/zabbix/zabbix_agentd.d/ 下建立两个 python 脚本：</p><p><strong>docker_discovery.conf</strong>  （自动发现规则）</p><p><strong>docker_status.conf</strong> （获取状态的脚本）</p><p>注：自动发现规则主要是为了省事省力，试想你 docker 中有三个容器，名称分别是 nginx,node,php。那如果你一个个的去增加，工作效率极低，而是使用自动发现，通过脚本的编写来确定所有的容器名称。</p><p>docker_status.conf 文件中只要增加一行代码即可：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">UserParameter=docker_status[*],sudo /usr/bin/python /etc/zabbix/script/docker_monitor.py $1 $2</span><br></pre></td></tr></table></figure><p><strong>UserParameter :</strong> zabbix 增加自定义键值，此处不可更改</p><p><strong>docker_status[*] ：</strong>键值的名称，可以根据喜好来取名字，不过最好还是让人能一眼就看出你键值的意义。其中”[*]”代表任意值，是 shell 的语法。因为我们要监控特定容器的 CPU、负载、内存等使用的情况，最后的 $1 $2 的变量就是对此处赋值。</p><p><strong>sudo /usr/bin/python /etc/zabbix/script/docker_monitor.py ：</strong>指定了 python 的运行路径，sudo 运行（如果是 root 用户运行可去掉该项），还有我们 python 脚本的运行路径和s名称。此处为了整洁，我在 zabbix 目录下新建了 script 目录来存放这两个脚本。</p><p><strong>$1 $2 ：</strong>shell 脚本中的变量，$0 代表脚本名称，$1 $2 则是我们后面需要赋值给 docker_status[*] 的两个变量。容器名称和特定监控项（如 CPU 使用率，内存使用率等）</p><p>docker_discovery.conf 和上面的基本相同，不过是脚本不同：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">UserParameter=docker_discovery,python /etc/zabbix/script/docker_discovery.py</span><br></pre></td></tr></table></figure><h4 id="3-增加-python-脚本"><a href="#3-增加-python-脚本" class="headerlink" title="3.增加 python 脚本"></a>3.增加 python 脚本</h4><p>按照2中的路径，在 /etc/zabbix/script/ 下建立： docker_discovery.py 和 docker_monitor.py</p><p>docker_discovery.py：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> simplejson <span class="keyword">as</span> json</span><br><span class="line">tname=os.popen(<span class="string">"""sudo docker ps | grep -v 'CONTAINER ID'|awk &#123;'print $NF'&#125;"""</span>)</span><br><span class="line">container_name=[]</span><br><span class="line"><span class="keyword">for</span> container <span class="keyword">in</span> tname.readlines():</span><br><span class="line">        rname=os.path.basename(container.strip())</span><br><span class="line">        container_name+=[&#123;<span class="string">'&#123;#CONTAINERNAME&#125;'</span>:rname&#125;]</span><br><span class="line"><span class="keyword">print</span> json.dumps(&#123;<span class="string">'data'</span>:container_name&#125;,sort_keys=<span class="literal">True</span>,indent=<span class="number">4</span>,separators=(<span class="string">','</span>,<span class="string">':'</span>))</span><br></pre></td></tr></table></figure><p>docker_monitor.py:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="keyword">import</span> docker</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> subprocess</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">check_container_stats</span><span class="params">(container_name,collect_item)</span>:</span></span><br><span class="line">        container_collect=docker_client.containers.get(container_name).stats(stream=<span class="literal">True</span>)</span><br><span class="line">        old_result=eval(container_collect.next())</span><br><span class="line">        new_result=eval(container_collect.next())</span><br><span class="line">        container_collect.close()</span><br><span class="line">        <span class="comment">#CPU使用百分比</span></span><br><span class="line">        <span class="keyword">if</span> collect_item == <span class="string">'cpu_percent'</span>:</span><br><span class="line">                cpu_total_usage=new_result[<span class="string">'cpu_stats'</span>][<span class="string">'cpu_usage'</span>][<span class="string">'total_usage'</span>] - old_result[<span class="string">'cpu_stats'</span>][<span class="string">'cpu_usage'</span>][<span class="string">'total_usage'</span>]</span><br><span class="line">                cpu_system_uasge=new_result[<span class="string">'cpu_stats'</span>][<span class="string">'system_cpu_usage'</span>] - old_result[<span class="string">'cpu_stats'</span>][<span class="string">'system_cpu_usage'</span>]</span><br><span class="line">                cpu_num=len(old_result[<span class="string">'cpu_stats'</span>][<span class="string">'cpu_usage'</span>][<span class="string">'percpu_usage'</span>])</span><br><span class="line">                result=round((float(cpu_total_usage)/float(cpu_system_uasge))*cpu_num*<span class="number">100.0</span>,<span class="number">2</span>)</span><br><span class="line">        <span class="comment">#内存使用量</span></span><br><span class="line">        <span class="keyword">elif</span> collect_item == <span class="string">'mem_usage'</span>:</span><br><span class="line">                result=new_result[<span class="string">'memory_stats'</span>][<span class="string">'usage'</span>]</span><br><span class="line"><span class="comment">#内存使用百分比</span></span><br><span class="line">        <span class="keyword">elif</span> collect_item == <span class="string">'mem_percent'</span>:</span><br><span class="line">                mem_usage=new_result[<span class="string">'memory_stats'</span>][<span class="string">'usage'</span>]</span><br><span class="line">                mem_limit=new_result[<span class="string">'memory_stats'</span>][<span class="string">'limit'</span>]</span><br><span class="line">                result=round(float(mem_usage)/float(mem_limit)*<span class="number">100.0</span>,<span class="number">2</span>)</span><br><span class="line">        <span class="keyword">return</span> result</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">        docker_client = docker.DockerClient(base_url=<span class="string">'unix://var/run/docker.sock'</span>, version=<span class="string">'1.27'</span>)</span><br><span class="line">        container_name=sys.argv[<span class="number">1</span>]</span><br><span class="line">        collect_item=sys.argv[<span class="number">2</span>]</span><br><span class="line">        <span class="keyword">print</span> check_container_stats(container_name,collect_item)</span><br></pre></td></tr></table></figure><p>python 版本是使用的是：Python 2.7.5</p><p>脚本的编写这里就不详细说了，如果有 python 基础，大部分的代码还是看得懂的。</p><p>建议直接复制上面两个脚本，并且记得下载脚本中所需的 python 包：<strong>docker、simplejson、subprocess</strong>等。并且增加脚本的可执行权限。否则会报错。</p><p>可以直接在终端执行  “python /etc/zabbix/script/docker_discovery.py “检验代码是否有误，如下图：</p><p><img src="/2019/09/10/zabbix监控docker/docker_discovery.png" alt></p><p>可以看到我这里已经获取了三个容器，并且分别打印了他们的名称（就如同我们使用 docker ps 看到的一样）</p><p>docker_monitor.py 直接运行可不行，会报错：</p><p><img src="/2019/09/10/zabbix监控docker/docker_monitor1.png" alt></p><p>提示我们超出列表值，这是因为我们没有在后面接指定的”<strong>container_name</strong>“和”<strong>collect_item</strong>“。这也是”docker_status.conf”文件中为什么要在最后增加” $1 $2”的原因。</p><p>增加指定的两个变量后：</p><p><img src="/2019/09/10/zabbix监控docker/docker_monitor2.png" alt></p><p><strong>tb-nginx:</strong> 运行 docker_discovery.py 获取到的容器名字</p><p><strong>cpu_percent:</strong>  docker_monitor.py 中编写的”collect_item”值</p><p>可以看到返回1.45。即我们容器名为”tb-nginx“的 CPU 使用占比为：1.45%</p><h4 id="4-server端进行简单测试"><a href="#4-server端进行简单测试" class="headerlink" title="4.server端进行简单测试"></a>4.server端进行简单测试</h4><p>以上的脚本都运行正常后，重启 zabbix-agent (不重启键值是不生效的)</p><p>然后在 zabbix-server 终端我们可以使用 zabbix 官方提供的 zabbix_get 进行测试（如果没有需要下载）</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">zabbix_get -s 192.168.40.10 -k docker_status[tb-nginx,mem_percent]</span><br></pre></td></tr></table></figure><p>192.168.40.10 ：就是你刚才增加键值的 agent 端，根据实际情况更改。</p><p>如果有正常返回值，那么就可以了，接下来配置 web 端。</p><h4 id="5-web界面增加监控模板"><a href="#5-web界面增加监控模板" class="headerlink" title="5.web界面增加监控模板"></a>5.web界面增加监控模板</h4><p>打开 zabbix 的 web 界面，配置 –&gt; 模板 –&gt; 创建模板 </p><p><img src="/2019/09/10/zabbix监控docker/web1.png" alt></p><p>我这里已经添加好了，可以看到”已连接到”那里已经链接了几个模板。</p><p>名称、应用集、模板群组等这些都可根据个人喜好设定，方便管理和识别即可。</p><p>比较关键的是接下来”自动发现规则”这里。</p><h5 id="5-1创建发现规则"><a href="#5-1创建发现规则" class="headerlink" title="5.1创建发现规则"></a>5.1创建发现规则</h5><p><img src="/2019/09/10/zabbix监控docker/web2.png" alt></p><p><img src="/2019/09/10/zabbix监控docker/web3.png" alt></p><h5 id="5-2添加监控项原形"><a href="#5-2添加监控项原形" class="headerlink" title="5.2添加监控项原形"></a>5.2添加监控项原形</h5><p><img src="/2019/09/10/zabbix监控docker/web4.png" alt></p><p>两个监控项原形创建：</p><p><img src="/2019/09/10/zabbix监控docker/web5.png" alt></p><p><img src="/2019/09/10/zabbix监控docker/web6.png" alt></p><h4 id="6-为主机链接模板"><a href="#6-为主机链接模板" class="headerlink" title="6.为主机链接模板"></a>6.为主机链接模板</h4><p>找到需要监控的主机，添加模板：</p><p><img src="/2019/09/10/zabbix监控docker/web7.png" alt></p><p>添加后点击更新。然后稍微等几分钟。点进监控项里查看，就可以看到我们自动发现的容器了。</p><p><img src="/2019/09/10/zabbix监控docker/web8.png" alt></p><p>有了监控项且没有报错，可以在 zabbix web 界面 –&gt;监测中 –&gt; 最新数据 中查看对应的值了。</p><p>然后接下来可以增加触发器、图形这些的。我这里图形是手动添加的，当然也可以自动添加，自动添加就是在增加 “docker自动发现模板”那里，再增加一个图形的模板。我这里需求的不太多，就手动添加了，效果图如下：</p><p><img src="/2019/09/10/zabbix监控docker/web10.png" alt></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;使用 zabbix 对 docker 运行容器使用的 CPU 和内存情况等进行监控&lt;/p&gt;
    
    </summary>
    
      <category term="运维监控" scheme="http://newpants.top/categories/%E8%BF%90%E7%BB%B4%E7%9B%91%E6%8E%A7/"/>
    
    
      <category term="zabbix" scheme="http://newpants.top/tags/zabbix/"/>
    
      <category term="docker" scheme="http://newpants.top/tags/docker/"/>
    
  </entry>
  
  <entry>
    <title>filebeat.yml配置详解</title>
    <link href="http://newpants.top/2019/09/06/filebeat-yml%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/"/>
    <id>http://newpants.top/2019/09/06/filebeat-yml配置详解/</id>
    <published>2019-09-06T08:16:36.000Z</published>
    <updated>2019-09-11T03:34:00.889Z</updated>
    
    <content type="html"><![CDATA[<p>filebeat.yml配置详解</p><a id="more"></a><h4 id="1-filebeat介绍"><a href="#1-filebeat介绍" class="headerlink" title="1.filebeat介绍"></a>1.filebeat介绍</h4><p>filebeat 是 elastic beats 中的一个轻量型的采集器。beats 包含很多系列，如官网下图：</p><p><img src="/2019/09/06/filebeat-yml配置详解/beats.png" alt="beat系列"></p><p>基本从名字就可以看得出来其对应的功能。这里我们使用 filebeat 主要针对文件（也就是需要采集的log日志) 来进行采集。</p><p>filebeat 的原理是开启一个 prospectors(收割者)，对文件逐行进行采集。</p><h4 id="2-示例文件及配置解析"><a href="#2-示例文件及配置解析" class="headerlink" title="2.示例文件及配置解析"></a>2.示例文件及配置解析</h4><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">filebeat.prospectors:</span><span class="comment">#采集 abc.com 下 nginx 的 access 日志 </span></span><br><span class="line"><span class="bullet">-</span> <span class="string">type</span> <span class="string">:</span> <span class="string">log</span></span><br><span class="line"><span class="attr">  enabled:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">  paths:</span></span><br><span class="line"><span class="bullet">     -</span> <span class="string">/data/server/wwwlog/nginx/abc.com.access.log</span></span><br><span class="line"><span class="attr">  tags:</span> <span class="string">["nginx_access"]</span></span><br><span class="line"><span class="attr">  tail_files:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">  scan_frequency:</span> <span class="number">30</span><span class="string">s</span></span><br><span class="line"><span class="attr">  fields:</span></span><br><span class="line"><span class="attr">    host:</span> <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span></span><br><span class="line"><span class="attr">    project:</span> <span class="string">abc.com</span></span><br></pre></td></tr></table></figure><p>filebeat.prospectors:        文件开头指定 filebeat 的采集方式，此处使用 prospectors</p><p>type : log                             类型为：log</p><p>enabled: true                     true 为开启，false 为关闭</p><p>paths:                                 指定路径</p><p>tags:                                    打标签，自定义名称，为后续在kibana查看时提供过滤与分类的效果</p><p>tail_files: true                     开启此项，代表采集从文件最底部开始，选择 false 时 filebeat 会从文件头部开始采集</p><p>scan_frequency: 30s         对文件的扫描间隔（每30秒扫描一次文件是否改动）</p><p>fields:                                  添加字段（用于 elasticsearch 过滤、分类，以及 kibana 中查看）</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="bullet">-</span> <span class="string">type</span> <span class="string">:</span> <span class="string">log</span><span class="comment">#采集 abc.com 下 nginx 的 error 日志</span></span><br><span class="line"><span class="attr">  enabled:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">  paths:</span></span><br><span class="line"><span class="bullet">     -</span> <span class="string">/data/server/wwwlog/nginx/abc.com.error.log</span></span><br><span class="line"><span class="attr">  tags:</span> <span class="string">["nginx_error"]</span></span><br><span class="line"><span class="attr">  tail_files:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">  scan_frequency:</span> <span class="number">30</span><span class="string">s</span></span><br><span class="line"><span class="attr">  fields:</span></span><br><span class="line"><span class="attr">    host:</span> <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span></span><br><span class="line"><span class="attr">    project:</span> <span class="string">abc.com</span></span><br></pre></td></tr></table></figure><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="bullet">-</span> <span class="string">type</span> <span class="string">:</span> <span class="string">log</span><span class="comment">#采集 abc.com 下 nginx 的 cache 日志</span></span><br><span class="line"><span class="attr">  enabled:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">  paths:</span></span><br><span class="line"><span class="bullet">     -</span> <span class="string">/data/server/wwwcache/abc.com.cache/application.log</span></span><br><span class="line">  <span class="string">multiline.pattern:</span> <span class="string">'^[0-9]&#123;4&#125;/[0-9]&#123;2&#125;/[0-9]&#123;2&#125;'</span></span><br><span class="line">  <span class="string">multiline.negate:</span> <span class="literal">true</span></span><br><span class="line">  <span class="string">multiline.match:</span> <span class="string">after</span></span><br><span class="line"><span class="attr">  tags:</span> <span class="string">["wwwcache"]</span></span><br><span class="line"><span class="attr">  tail_files:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">  scan_frequency:</span> <span class="number">30</span><span class="string">s</span></span><br><span class="line"><span class="attr">  fields:</span></span><br><span class="line"><span class="attr">    host:</span> <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span></span><br><span class="line"><span class="attr">    project:</span> <span class="string">abc.com</span></span><br></pre></td></tr></table></figure><p>  multiline.pattern: ‘^[0-9]{4}/[0-9]{2}/[0-9]{2}’<br>  multiline.negate: true<br>  multiline.match: after</p><p>以上通过正规表达式，对日志多行进行合并。如下图效果(根据实际情况配置正规表达式，可对任意行进行合并保存在一个 message 中)：</p><p>cache 中日志不需要逐行采集，需要采集某一段</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span>2 /data/server/wwwroot/tui.tongbu.com/index.php(28): CApplication-&gt;run()</span><br><span class="line"><span class="meta">#</span>3 &#123;main&#125;</span><br><span class="line">REQUEST_URI=/apple-touch-icon-120x120-precomposed.png</span><br><span class="line">---</span><br><span class="line">2019/09/06 16:47:32 [error] [exception.CHttpException.404] CHttpException: Unable to resolve the request "apple-touch-icon-120x120.png". in /data/server/wwwroot/yii/framework/web/CWebApplication.php:286</span><br><span class="line">Stack trace:</span><br><span class="line"><span class="meta">#</span>0 /data/server/wwwroot/yii/framework/web/CWebApplication.php(141): CWebApplication-&gt;runController('apple-touch-ico...')</span><br><span class="line"><span class="meta">#</span>1 /data/server/wwwroot/yii/framework/base/CApplication.php(185): CWebApplication-&gt;processRequest()</span><br><span class="line"><span class="meta">#</span>2 /data/server/wwwroot/tui.tongbu.com/index.php(28): CApplication-&gt;run()</span><br><span class="line"><span class="meta">#</span>3 &#123;main&#125;</span><br><span class="line">REQUEST_URI=/apple-touch-icon-120x120.png</span><br><span class="line">---</span><br></pre></td></tr></table></figure><p>增加正规表达式后：</p><p><img src="/2019/09/06/filebeat-yml配置详解/wwwcache_kibana.png" alt="合并多行日志"></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;filebeat.yml配置详解&lt;/p&gt;
    
    </summary>
    
      <category term="ELK日志采集" scheme="http://newpants.top/categories/ELK%E6%97%A5%E5%BF%97%E9%87%87%E9%9B%86/"/>
    
    
      <category term="filebeat" scheme="http://newpants.top/tags/filebeat/"/>
    
  </entry>
  
  <entry>
    <title>ELK+filebeat日志采集（搭建篇）</title>
    <link href="http://newpants.top/2019/08/30/ElkDeploy/"/>
    <id>http://newpants.top/2019/08/30/ElkDeploy/</id>
    <published>2019-08-30T03:14:03.000Z</published>
    <updated>2019-09-11T03:34:34.082Z</updated>
    
    <content type="html"><![CDATA[<p>ELK+filebeat日志采集（搭建篇）</p><a id="more"></a><p><img src="/2019/08/30/ElkDeploy/elastic_top.png" alt></p><p>这里不进行配置文件配置更改的说明。全部使用默认配置文件，此篇主要旨在介绍正常安装及运行。</p><p><strong>每种程序的单独介绍可在以下查看（常用的一些配置和概念）：</strong></p><p><strong><a href>elasticsearch介绍及配置说明(待更新)</a></strong></p><p><strong><a href>logstash介绍配置说明(待更新)</a></strong></p><p><strong><a href>kibana介绍及配置说明(待更新)</a></strong></p><p><strong><a href="https://newpants.top/2019/09/06/filebeat-yml配置详解">filebeat介绍及配置说明(待更新)</a></strong></p><p><a href="https://www.elastic.co/guide/index.html" target="_blank" rel="noopener">elastic官方文档地址</a>   #官方文档说明的都很详细</p><h3 id="1-基本架构图"><a href="#1-基本架构图" class="headerlink" title="1.基本架构图"></a>1.基本架构图</h3><p><img src="/2019/08/30/ElkDeploy/Architecture_diagram.png" alt></p><p>elasticsearch： 一款基于 Lucene 的搜索服务器。可以理解为数据库，我们日后将要采集的日志都将储存在这里。</p><p>logstash： logstash 的主要功能是将数据按照我们的要求进行过滤和筛选。完成我们制定的工作发送给 elasticsearch 后以便我们查询。</p><p>kibana： 基于web的查看页面。已经开始提供越来越多的 api。以前的 elasticsearch 还需要 elasticsearch-head 或者直接服务器上面进行操作和查询。现 kibana 的控制台基本可以满足大部分需求。</p><p>filebeat： 采集工具。因为 logstash 非常的消耗系统资源，为了不影响业务服务器，使用 filebeat ，他非常轻量。基本不占用什么空间和系统资源。</p><p>大致流程：filebeat（采集）–&gt; logstash（过滤）–&gt; elasticsearch（储存）–&gt; kibana(查看)</p><h3 id="2-此例版本号说明"><a href="#2-此例版本号说明" class="headerlink" title="2.此例版本号说明"></a>2.此例版本号说明</h3><table><thead><tr><th>软件</th><th>Java</th><th>Elasticsearch</th><th>Logstash</th><th>Kibana</th><th>Filebeat</th></tr></thead><tbody><tr><td>版本号</td><td>1.8.0_181</td><td>6.7.1</td><td>6.7.1</td><td>6.7.1</td><td>6.7.1</td></tr></tbody></table><p>因为采集量不大，且公司内部部分需求。所以此篇文章是在一台centos7服务器上搭建elasticsearch+logstash+kibana 。其他需要采集的机器上安装 filebeat 进行采集。</p><p>这里需要注意的是，elasticsearch 和 logstash 需要在 java 环境下运行。</p><p><strong>以下安装过程简单带过，网上已经有了很多，遇到问题可以简单进行百度分析。（官方建议最好保持elk+filebeat版本一致性，以避免不可预估的情况发生）</strong></p><h3 id="3-JAVA-环境配置"><a href="#3-JAVA-环境配置" class="headerlink" title="3. JAVA 环境配置"></a>3. JAVA 环境配置</h3><p>此例使用压缩包形式安装，在<a href="https://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html" target="_blank" rel="noopener">orcale官网jdk下载</a>，按照需求选择需要下载的jdk版本，此例使用 jdk-8u201-linux-x64.tar.gz</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">tar -xvzf jdk-8u201-linux-x64.tar.gz     #解压</span><br><span class="line">mv jdk1.8.0_201/ /usr/jdk1.8.0_201       #移动解压包至/usr下</span><br><span class="line"></span><br><span class="line">vim /etc/profile     #编辑系统配置文件，添加 如下java 环境变量</span><br><span class="line">export JAVA_HOME=/usr/jdk1.8.0_201  #如果不生效，在jdk1.8.0_201加“/”，目录按照实际情况</span><br><span class="line">export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar</span><br><span class="line">export PATH=$PATH:$JAVA_HOME/bin</span><br><span class="line"></span><br><span class="line">source /etc/profile                       #重新加载环境变量</span><br><span class="line">java -version                              #验证</span><br></pre></td></tr></table></figure><h3 id="4-RPM形式安装elk"><a href="#4-RPM形式安装elk" class="headerlink" title="4.RPM形式安装elk"></a>4.RPM形式安装elk</h3><p>在elastic官网：<a href="https://www.elastic.co/cn/" target="_blank" rel="noopener">elastic官网</a>，找到产品相应的下载页面。下载rpm包（当然也可以使用yum或者压缩包形式安装，个人认为rpm比较方便，关键在于可以统一版本）</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">rpm -ivh elasticsearch-6.7.1-x86_64.rpm</span><br><span class="line">rpm -ivh logstash-6.7.1.rpm</span><br><span class="line">rpm -ivh kibana-6.7.1-x86_64.rpm</span><br></pre></td></tr></table></figure><p>因资源有限且需求量不大，故本例三种程序都安装在一台 linux centos7 上。安装完成后，查看程序是否正常启动即可。启动顺序最好按照： </p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">systemctl start elasticsearch</span><br><span class="line">systemctl start logstash</span><br><span class="line">systemctl start kibana</span><br></pre></td></tr></table></figure><p>查看是否安装并启动成功</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">netstat -tunlp | grep 9200     #elasticsearch默认开放端口，有返回如下结果代表端口已启动</span><br><span class="line">tcp6     0      0  127.0.0.1:9200          :::*                LISTEN      12427/java</span><br><span class="line"></span><br><span class="line">netstat -tunlp | grep 9600#logstash默认开放端口，有返回如下结果代表端口已启动</span><br><span class="line">tcp6     0      0  127.0.0.1:9600          :::*                LISTEN      17905/java</span><br><span class="line"></span><br><span class="line">netstat -tunlp | grep 5601#kibana默认开放端口，有返回如下结果代表端口已启动</span><br><span class="line">tcp     0      0   127.0.0.1:5601          :::*                LISTEN      4666/node</span><br></pre></td></tr></table></figure><p>此时通过浏览器访问 127.0.0.1:9200 返回类似如下页面，证明 elasticsearch 安装并正常启动：</p><p><img src="/2019/08/30/ElkDeploy/elasticsearch_start.png" alt="4.elasticsearch_start.png"></p><p>此时通过浏览器访问 127.0.0.1:5601 即可看到 kibana 页面：</p><p><img src="/2019/08/30/ElkDeploy/kibana_start.png" alt="4.kibana_start.png"></p><p>logstash的验证相比前两种不太一样</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@study ~]# whereis logstash  #先查看logstash安装的默认位置</span><br><span class="line">logstash: /etc/logstash /usr/share/logstash</span><br><span class="line"></span><br><span class="line">#执行以下命令。说明：input和output是logstash的两个插件，stdin和stdout分别代表了标准输入和标准输出</span><br><span class="line">[root@study ~]# /usr/share/logstash/bin/logstash -e &apos;input &#123; stdin &#123; &#125; &#125; output &#123; stdout &#123; &#125;&#125;&apos;</span><br></pre></td></tr></table></figure><p>看到 {:port =&gt;9600}，我们在光标等待处随便输入点文字</p><p><img src="/2019/08/30/ElkDeploy/logstash-input.png" alt="logstash_input.png"></p><p>如果类似消息输出到屏幕则正常：</p><p><img src="/2019/08/30/ElkDeploy/logstash-output.png" alt></p><p>此时我们还没有用 filebeat 来收集日志，所以也没有生成对应的索引。故此时看到的都是空的。接来下就介绍在需要采集的机器上安装 filebeat 采集日志。</p><h3 id="5-安装-filebeat"><a href="#5-安装-filebeat" class="headerlink" title="5. 安装 filebeat"></a>5. 安装 filebeat</h3><p>在目标采集机器上安装filebeat。因采集机器不同，分为 linux 和 windows 。</p><p>linux：</p><p>安装方式：RPM安装</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@study ~]#rpm -ivh filebeat-6.7.1-x86_64.rpm</span><br><span class="line">[root@study ~]#systemctl start filebeat</span><br></pre></td></tr></table></figure><p>对 filebeat.yml 进行简单的配置：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">filebeat.prospectors:  </span><br><span class="line"> - type : log</span><br><span class="line">   enabled: true  #选择true代表开启</span><br><span class="line">   paths:         #路径</span><br><span class="line">     - /data/*.log #所有.log结尾的日志</span><br><span class="line">   fields:#自定义字段，便于区分</span><br><span class="line">      host: 127.0.0.1</span><br><span class="line">   tail_files: true#从尾部开始采集，若选择false则会从头到尾把日志每行都读取</span><br><span class="line">   scan_frequency: 30s#扫描间隔</span><br><span class="line">   exclude_lines: [&quot;^#&quot;]#正则表达式：排除空行</span><br><span class="line">   tags: [&quot;nginx&quot;]#添加tags</span><br><span class="line">output.logstash:#输出插件到logstash</span><br><span class="line"> hosts: [&quot;127.0.0.1:5044&quot;]#hosts地址 本机为测试在本机上安装filebeat。按照实际情况填写</span><br></pre></td></tr></table></figure><p>对 filebeat.yml 文件进行测试：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@study ~]#cd 到filebeat的安装目录</span><br><span class="line">[root@study ~]#./filebeat test config#测试配置文件正确性</span><br><span class="line">[root@study ~]#./filebeat test output#测试配置文件输出的正确性(需要在开启logstash并且指定开放5044端口的前提下，后面会介绍logstash配置开放5044端口)</span><br><span class="line">如果存在异常会返回error。根据error进行调整。若全部正常，则重新启动filebeat</span><br><span class="line">[root@study ~]#systemctl restart filebeat</span><br></pre></td></tr></table></figure><p>windows:</p><p>安装方式：压缩包安装成系统服务</p><p>下载 filebeat-6.7.1-windows-x86_64.zip 解压到指定文件夹，配置文件基本于上述 linux 一样，”paths: “需要更改一下。其他的测试配置文件都相同。下面主要说下把 filebeat 安装成 windows 的服务启动项。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">1.将zip文件内容解压到C：\Program Files(或者其他路径，如果为其他路径要修改install-service-filebeat文件中的路径地址）</span><br><span class="line">2.将filebeat-&lt;version&gt;-windows目录重新命名为filebeat（必须为filebeat）</span><br><span class="line">3.以管理员身份打开PowerShell提示符</span><br><span class="line">4.在PowerShell下将Filebeat安装成Windows服务：</span><br><span class="line">cd ‘c:\Program Files\Filebeat’</span><br><span class="line">.\install-service-filebeat.ps1</span><br><span class="line">5.如果系统禁止脚本执行，则需要为当前会话设置执行策略以允许脚本执行，例如：</span><br><span class="line">PowerShell.exe -ExecutionPolicy UnRestricted -File .\install-service-filebeat.ps1</span><br></pre></td></tr></table></figure><p>这是在 windows 的服务中就可以看到名为 filebeat 的服务启动项了。启动即可。</p><h3 id="6-配置文件证明连通性"><a href="#6-配置文件证明连通性" class="headerlink" title="6.配置文件证明连通性"></a>6.配置文件证明连通性</h3><p>上述 filebeat.yml 已经配置了输出文件到 logstash 的 5044 端口。5044端口是默认端口，此端口可随意更改，只要该端口可以通就可以。如果添加端口后无法进行通讯，修改防火墙策略增加端口放行，或直接关闭防火墙测试。</p><h4 id="6-1配置-logstash-yml-文件："><a href="#6-1配置-logstash-yml-文件：" class="headerlink" title="6.1配置 logstash.yml 文件："></a>6.1配置 logstash.yml 文件：</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@study ~]#vim /etc/logstash/config/logstash.yml</span><br><span class="line"><span class="meta">#</span>修改或添加：</span><br><span class="line">http.host: "127.0.0.1"  #主机通讯地址，按实际情况而定</span><br><span class="line">http.port: 9600  #开放端口，默认端口，可更改</span><br><span class="line">path.config: /etc/logstash/conf.d/*.conf #指定配置文件路径</span><br></pre></td></tr></table></figure><p>然后我们在指定路径下配置一个名为 /etc/logstash/conf.d/test.conf 的文件如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">input&#123;    #input插件指定由beats输入，且开放端口号为：5044</span><br><span class="line"> beats&#123;</span><br><span class="line">   port =&gt; 5044</span><br><span class="line"> &#125;</span><br><span class="line">&#125;</span><br><span class="line">output &#123;</span><br><span class="line">        stdout &#123;</span><br><span class="line">                codec =&gt; rubydebug  #输出到当前屏幕，调试用。后面可以关掉</span><br><span class="line">        &#125;</span><br><span class="line">        elasticsearch&#123;#输出到 elasticsearch</span><br><span class="line">   hosts =&gt; ["127.0.0.1:9200"]#elasticsearch 的主机地址和端口号</span><br><span class="line">    index =&gt; "127.0.0.1-%&#123;+YYYY.MM&#125;"#自定义索引名称，如不指定，则默认 logstash*</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="6-2配置elasticsearch-yml"><a href="#6-2配置elasticsearch-yml" class="headerlink" title="6.2配置elasticsearch.yml"></a>6.2配置elasticsearch.yml</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span>在elasticsearch.yml添加或修改如下内容</span><br><span class="line">network.host: 127.0.0.1#主机地址</span><br><span class="line">http.port: 9200#主机开放端口</span><br></pre></td></tr></table></figure><h4 id="6-3配置kibana-yml"><a href="#6-3配置kibana-yml" class="headerlink" title="6.3配置kibana.yml"></a>6.3配置kibana.yml</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">server.port: 5601    #kibana开放端口</span><br><span class="line">server.host: "127.0.0.1"#kibana主机地址</span><br><span class="line">elasticsearch.hosts: ["http://127.0.0.1:9200"]#kibana连接到的elasticsearch的主机地址及端口号</span><br></pre></td></tr></table></figure><h3 id="7-打开kibana添加索引验证"><a href="#7-打开kibana添加索引验证" class="headerlink" title="7.打开kibana添加索引验证"></a>7.打开kibana添加索引验证</h3><p>如果一切顺利。重启这些服务。等待都完全启动后。在 filebeat 采集的路径日志中随便输入一些文字来验证。</p><p><strong>注：要使用 echo “xxx” &gt;&gt;  /data/*.log 的形式，而不是 vim 之后添加。因为filebeat是记录着文件的 PID 号。vim 打开保存后会找不到之前的文件 PID。故会重新采集指定路径的文件，造成每次都是从头开始读行文件。而 echo 不会改变文件的 PID 号。</strong></p><p> 如果在<strong>kibana-&gt;管理-&gt;创建索引模式</strong>中可以看到你指定的名为“127.0.0.1-*”的索引。就代表 elk+filebeat 全部运行成功了。</p><p><img src="/2019/08/30/ElkDeploy/kibana_index.png" alt="7.kibana_index.png"></p><p>(我这里没有截图，偷个懒，就用公司已经在用的索引作为图片说明了)</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;ELK+filebeat日志采集（搭建篇）&lt;/p&gt;
    
    </summary>
    
      <category term="ELK日志采集" scheme="http://newpants.top/categories/ELK%E6%97%A5%E5%BF%97%E9%87%87%E9%9B%86/"/>
    
    
      <category term="filebeat" scheme="http://newpants.top/tags/filebeat/"/>
    
      <category term="elasticsearch" scheme="http://newpants.top/tags/elasticsearch/"/>
    
      <category term="logstash" scheme="http://newpants.top/tags/logstash/"/>
    
      <category term="kibana" scheme="http://newpants.top/tags/kibana/"/>
    
  </entry>
  
  <entry>
    <title>new pants</title>
    <link href="http://newpants.top/2019/08/28/new-pants/"/>
    <id>http://newpants.top/2019/08/28/new-pants/</id>
    <published>2019-08-28T08:39:41.000Z</published>
    <updated>2019-08-30T07:20:35.984Z</updated>
    
    <content type="html"><![CDATA[<p>生命因你而火热</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;生命因你而火热&lt;/p&gt;

      
    
    </summary>
    
      <category term="other" scheme="http://newpants.top/categories/other/"/>
    
    
      <category term="pants" scheme="http://newpants.top/tags/pants/"/>
    
  </entry>
  
</feed>
