<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>NewPants</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://newpants_top/"/>
  <updated>2019-11-05T07:09:19.789Z</updated>
  <id>https://newpants_top/</id>
  
  <author>
    <name>未完成</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>shell脚本汇总</title>
    <link href="https://newpants_top/2019/11/05/shell%E8%84%9A%E6%9C%AC%E6%B1%87%E6%80%BB/"/>
    <id>https://newpants_top/2019/11/05/shell脚本汇总/</id>
    <published>2019-11-05T05:26:01.000Z</published>
    <updated>2019-11-05T07:09:19.789Z</updated>
    
    <content type="html"><![CDATA[<p>日常学习、编写的shell脚本汇总。</p><a id="more"></a><!-- toc --><ul><li><a href="#遍历目标目录下所有子文件夹并查询是否有关键字">遍历目标目录下所有子文件夹，并查询是否有关键字</a></li></ul><!-- tocstop --><h4><span id="遍历目标目录下所有子文件夹并查询是否有关键字">遍历目标目录下所有子文件夹，并查询是否有关键字</span></h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span>!/bin/bash</span><br><span class="line"><span class="meta">#</span>功能说明：</span><br><span class="line"><span class="meta">#</span>用户输入查询的关键字，如果关键字存在于文件中，则打印包含关键字的语句及包含关键字文件的路径。</span><br><span class="line"><span class="meta">#</span>如果文件中不包含关键字，不输出任何内容</span><br><span class="line"><span class="meta">#</span>-------------------------------------------------------------------------------------#</span><br><span class="line">echo "输入查询关键字:"</span><br><span class="line">read keyword</span><br><span class="line">function getdir()&#123;</span><br><span class="line">    for element in `ls $1`</span><br><span class="line">    do</span><br><span class="line">        dir_or_file=$1"/"$element</span><br><span class="line">        if [ -d $dir_or_file ]</span><br><span class="line">        then</span><br><span class="line">            getdir $dir_or_file</span><br><span class="line">        else        </span><br><span class="line">            grep_command=`cat $dir_or_file | grep $keyword`</span><br><span class="line">            if [ "$grep_command" = "" ]</span><br><span class="line">            then</span><br><span class="line">                continue</span><br><span class="line">            else</span><br><span class="line">                echo $dir_or_file</span><br><span class="line">                echo ""</span><br><span class="line">                echo $grep_command</span><br><span class="line">                echo ""</span><br><span class="line">                echo '.........................................................................'</span><br><span class="line">            fi</span><br><span class="line">          </span><br><span class="line">        fi</span><br><span class="line">    done</span><br><span class="line">&#125;</span><br><span class="line">getdir '/data/server/wwwroot/cacti-0.8.8h/scripts'</span><br></pre></td></tr></table></figure><p>read keyword：由用户输入关键字，路径也可以用这样的方式，我这里路径基本不会变，所有直接写死在脚本里，如果想要输入路径，参考read keyword 设置输入保存变量即可。</p><p>$1：函数 getdir() 中的第一个参数，也就是路径”/data/server/wwwroot/cacti-0.8.8h/scripts”</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;日常学习、编写的shell脚本汇总。&lt;/p&gt;
    
    </summary>
    
      <category term="shell" scheme="https://newpants_top/categories/shell/"/>
    
    
      <category term="shell" scheme="https://newpants_top/tags/shell/"/>
    
  </entry>
  
  <entry>
    <title>使用防火墙iptables添加、删除规则等基本命令</title>
    <link href="https://newpants_top/2019/11/05/%E4%BD%BF%E7%94%A8%E9%98%B2%E7%81%AB%E5%A2%99iptables%E6%B7%BB%E5%8A%A0%E3%80%81%E5%88%A0%E9%99%A4%E8%A7%84%E5%88%99%E7%AD%89%E5%9F%BA%E6%9C%AC%E5%91%BD%E4%BB%A4/"/>
    <id>https://newpants_top/2019/11/05/使用防火墙iptables添加、删除规则等基本命令/</id>
    <published>2019-11-05T05:24:33.000Z</published>
    <updated>2019-11-05T06:59:08.908Z</updated>
    
    <content type="html"><![CDATA[<p>记一次服务器流量异常检查。</p><a id="more"></a><!-- toc --><ul><li><a href="#iftop">iftop</a><ul><li><a href="#iftop安装">iftop安装</a></li><li><a href="#iftop使用">iftop使用</a></li></ul></li><li><a href="#iptables">iptables</a><ul><li><a href="#iptables命令">iptables命令</a><ul><li><a href="#添加封停ip规则">添加封停IP规则</a></li><li><a href="#删除封停ip规则">删除封停IP规则</a></li><li><a href="#添加封停ip及端口规则">添加封停IP及端口规则</a></li><li><a href="#保存iptables规则">保存iptables规则</a></li><li><a href="#快捷删除规则">快捷删除规则</a></li></ul></li></ul></li><li><a href="#varlogmessages">/var/log/messages</a></li><li><a href="#解决方法">解决方法</a></li></ul><!-- tocstop --><p>周末在家报警邮件一直响起，打开一看发现是两台服务器提示宕机。遂打开xshell想要远程一下，发现卡住。ping该服务器的IP也无法ping通，再查看流量图，带宽已经被占满了。</p><h4><span id="iftop">iftop</span></h4><p>一款linux下实时的网络流量工具，监控TCP/IP连接等。</p><h5><span id="iftop安装">iftop安装</span></h5><p>Centos上安装iftop，如果你的镜像有配置正常，直接使用yum安装即可:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]#yum install iftop</span><br></pre></td></tr></table></figure><p>如果提示缺少一些依赖包，安装即可。</p><h5><span id="iftop使用">iftop使用</span></h5><p>使用起来没有什么花里胡哨的，简单粗暴，安装成功后直接命令行里输入：iftop</p><p>如果想更详细的看到自己的端口和对方的端口，以及选择自己的网卡，输入：iftop -i eth0 -P</p><p>eth0代表着第一个网卡口，如果你有两条网线，输入eth1看第二个口。-P 代表显示端口。</p><p><img src="/2019/11/05/使用防火墙iptables添加、删除规则等基本命令/iftop.png" alt></p><table><thead><tr><th>界面内容</th><th>说明</th></tr></thead><tbody><tr><td>“&lt;=” 和 “=&gt;”</td><td>代表流量的方向，像我这里第一行就是我自己的IP（打码的部分）流向一个IP为23.226.55.114的IP。后面看到已经发送了4M多。</td></tr><tr><td>TX：</td><td>发送流量</td></tr><tr><td>RX：</td><td>接受流量</td></tr><tr><td>TOTAL：</td><td>总流量</td></tr></tbody></table><p>经过查询，发现114的IP为一个香港IP，服务器有大量的数据发送至这个IP，这个服务器是一个web服务器，按理说应该没这么大流量，不管怎么说，先禁掉这个IP才行，服务器已经卡的受不了了。禁IP就可以通过防火墙，iptables来实现了。</p><h4><span id="iptables">iptables</span></h4><p>以centos7为例，7以下的，例如6和5.8，还是自带iptables的，7以上貌似已经换成firewall了。都是防火墙，使用方法也差不太多。以下以5.8系统中的iptables来说明。</p><p>先查看iptables是否有安装：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]# whereis iptables</span><br><span class="line">iptables: /sbin/iptables /usr/share/man/man8/iptables.8.gz</span><br></pre></td></tr></table></figure><p>看来已经有安装了，如果没有安装，可以通过yum方式安装：</p><p>yum install iptables-services</p><p>然后再查看一下iptables的状态：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]#service iptables status</span><br></pre></td></tr></table></figure><p><img src="/2019/11/05/使用防火墙iptables添加、删除规则等基本命令/iptables1.png" alt></p><p>注意一下图中红色部分，这里我已经把114这个IP加进去了。加入的命令在下面会讲到。</p><h5><span id="iptables命令">iptables命令</span></h5><p>以下先举几个常见例子，具体参数在例子后说明：</p><h6><span id="添加封停ip规则">添加封停IP规则</span></h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]#iptables -I INPUT -s ***.***.***.*** -j DROP</span><br></pre></td></tr></table></figure><h6><span id="删除封停ip规则">删除封停IP规则</span></h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]#iptables -D INPUT -s ***.***.***.*** -j DROP</span><br></pre></td></tr></table></figure><h6><span id="添加封停ip及端口规则">添加封停IP及端口规则</span></h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]#iptables -I INPUT -s ***.***.***.*** -p tcp --dport 9100 -j DROP</span><br></pre></td></tr></table></figure><h6><span id="保存iptables规则">保存iptables规则</span></h6><p>添加完规则后一定要记得运行保存的语句，否则重启完iptables后添加的规则就失效了。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]#service iptables save</span><br></pre></td></tr></table></figure><p>然后重启：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]#service iptables restart</span><br></pre></td></tr></table></figure><h6><span id="快捷删除规则">快捷删除规则</span></h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]#iptables -D INPUT 12</span><br></pre></td></tr></table></figure><p>INPUT就是上图中红框内的INPUT，你需要告诉防火墙你是要删除或者添加INPUT规则还是OUTPUT规则。</p><p>12就是上图中最前面那一列，12就是编号为12的那行，结合INPUT或者OUTPUT去删除，确定你是要删除INPUT还是OUTPUT规则，否则可能想要删除进站规则而删除了出站规则。</p><p>参数说明：</p><table><thead><tr><th>参数</th><th>说明</th></tr></thead><tbody><tr><td>-I</td><td>insert，表示添加一条规则</td></tr><tr><td>-D</td><td>delete，表示删除一条规则，并且一定要删除</td></tr><tr><td>-s</td><td>后面接IP地址</td></tr><tr><td>-p</td><td>指定端口的类型，是udp类型还是tcp类型，类似例子中就是指定tcp类型。</td></tr><tr><td>–dport</td><td>指定端口，例子中是9100</td></tr><tr><td>-j</td><td>是DROP还是ACCEPT。DROP代表接受的包全部丢弃，也就是禁止掉了这个IP或者端口发送来的包。而ACCEPT相反，也就是接受发来的包。</td></tr></tbody></table><p>再来看看上面我添加规则的这张图：</p><p><img src="/2019/11/05/使用防火墙iptables添加、删除规则等基本命令/iptables2.png" alt></p><p>完整的命令就是：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]#iptables -I INPUT -s 23.226.55.114 -j DROP</span><br></pre></td></tr></table></figure><p>记得添加完防火墙规则，保存并重启，然后再通过iftop查看网卡状态。发现那个IP已经不见了，而流量也正常了，服务器也不卡了，皆大欢喜。下面就是要看是什么原因造成被大流量请求了。</p><h4><span id="varlogmessages">/var/log/messages</span></h4><p>/var/log/messages包含了系统启动期间的日志，还包括一些报错日志等等。先看看系统是不是有什么报错之类的。结果就看到了上面出现的那个114的IP一直在请求这台服务器上的snmpd服务。然后再向前几天查看，竟然发现还有其他IP也在一直请求，基本上一天一换，看来是snmpd的连接密码和端口号被人知道了，使用我们服务器的流量做了一些转发之类的。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]#cat /var/log/messages |grep "23.226.55.114"</span><br></pre></td></tr></table></figure><p><img src="/2019/11/05/使用防火墙iptables添加、删除规则等基本命令/messages.png" alt></p><p>超多的snmpd端口请求。</p><p>通过”netstat -tunlp | grep snmpd”查看端口情况：</p><p><img src="/2019/11/05/使用防火墙iptables添加、删除规则等基本命令/netstat.png" alt></p><p>端口还是默认的161…而且查看 snmpd.conf 文件发现，密码太简单了。。就是几个字母这样的。</p><p>继续查看防火墙规则发现：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">11    ACCEPT     udp  --  0.0.0.0        0.0.0.0/0           udp dpt:161</span><br></pre></td></tr></table></figure><p>并未对161udp端口作任何限制，因为公司还在使用比较远古的监控工具cacti，而cacti就是通过snmpd的UDP端口来接受数据的。所以我们知道了原因以后，稍微添加以下防火墙规则就可以了。</p><h4><span id="解决方法">解决方法</span></h4><p>删除这条旧规则：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]#iptables -D INPUT 11</span><br></pre></td></tr></table></figure><p>添加新规则，只允许一个ip访问UDP端口161：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]#iptables -I INPUT -s 我的IP -p udp --dport 161 -j ACCEPT</span><br></pre></td></tr></table></figure><p>保存：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]#service iptables save</span><br></pre></td></tr></table></figure><p>重启：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]#service iptables restart</span><br></pre></td></tr></table></figure><p>大功告成。这样以后就不怕莫名其妙的被人偷流量了。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;记一次服务器流量异常检查。&lt;/p&gt;
    
    </summary>
    
      <category term="linux" scheme="https://newpants_top/categories/linux/"/>
    
    
      <category term="iptables" scheme="https://newpants_top/tags/iptables/"/>
    
      <category term="iftop" scheme="https://newpants_top/tags/iftop/"/>
    
  </entry>
  
  <entry>
    <title>windows下python2.0与3.0共存</title>
    <link href="https://newpants_top/2019/11/01/windows%E4%B8%8Bpython2-0%E4%B8%8E3-0%E5%85%B1%E5%AD%98/"/>
    <id>https://newpants_top/2019/11/01/windows下python2-0与3-0共存/</id>
    <published>2019-11-01T06:50:36.000Z</published>
    <updated>2019-11-05T07:16:59.147Z</updated>
    
    <content type="html"><![CDATA[<p>解决烦人的版本兼容问题很简单。</p><a id="more"></a><!-- toc --><ul><li><a href="#下载python">下载python</a></li><li><a href="#安装python">安装python</a></li><li><a href="#更改exe文件名称并删除scripts">更改exe文件名称并删除scripts</a><ul><li><a href="#更改exe文件名">更改exe文件名</a></li><li><a href="#更改exe文件名-1">更改exe文件名</a></li></ul></li><li><a href="#配置环境变量">配置环境变量</a><ul><li><a href="#新建变量名及变量值">新建变量名及变量值</a></li><li><a href="#新建变量名及变量值-1">新建变量名及变量值</a></li></ul></li><li><a href="#添加到系统环境变量">添加到系统环境变量</a></li><li><a href="#测试">测试</a></li></ul><!-- tocstop --><p>python官方一直在劝大家用3.0的版本，也表示2.0的版本只会维护到2020年，这都9021年了，2020年也是近在眼前了。python两个版本最让人不爽的就是，不能向下兼容，2.0和3.0的代码，很多时候一个版本能跑，另外一个版本就需要改动一些才能跑起来，实属让人不爽。</p><p>但是例如像centos7，装机的自带版本就是2.7版本，很多时候想跑个脚本，根本不想在服务器上再装个3.0的python，辛辛苦苦用3.0写完了，也测试没问题了，结果在2.0上面一跑就报错。就很后悔当初没有用2.0来编写和测试。但是又不想放弃未来大趋所示的3.0。</p><p>那就搞下兼容吧，习主席都说了，2020年，我国要全面脱贫！主席，不要丢下我，我还在贫困之中。</p><h4><span id="下载python">下载python</span></h4><p>在官网下载python2.0和3.0两种版本的windows安装包：<a href="https://www.python.org/downloads/" target="_blank" rel="noopener">python官网下载地址</a></p><p>这里下载的是python2.7.17和python3.7.3</p><h4><span id="安装python">安装python</span></h4><p>新建两个文件夹，取好对应的名字，分别安装到对应的文件夹下。这样也方便我们后期管理。</p><p><img src="/2019/11/01/windows下python2-0与3-0共存/python3_intall.png" alt></p><p><img src="/2019/11/01/windows下python2-0与3-0共存/python_dir.png" alt></p><h4><span id="更改exe文件名称并删除scripts">更改exe文件名称并删除scripts</span></h4><p>python3：</p><h5><span id="更改exe文件名">更改exe文件名</span></h5><p><img src="/2019/11/01/windows下python2-0与3-0共存/python3exe.png" alt></p><p>##### </p><p>python2：</p><h5><span id="更改exe文件名">更改exe文件名</span></h5><p><img src="/2019/11/01/windows下python2-0与3-0共存/python2exe.png" alt></p><h4><span id="配置环境变量">配置环境变量</span></h4><p>python3：</p><h5><span id="新建变量名及变量值">新建变量名及变量值</span></h5><p><img src="/2019/11/01/windows下python2-0与3-0共存/python3hjbl.png" alt></p><p>python2：</p><h5><span id="新建变量名及变量值">新建变量名及变量值</span></h5><p><img src="/2019/11/01/windows下python2-0与3-0共存/python2hjbl.png" alt></p><h4><span id="添加到系统环境变量">添加到系统环境变量</span></h4><p>在Path中分别添加：</p><p><strong>Python.exe路径：</strong>%Python3_HOME%;%Python2_HOME%;</p><p><strong>PIP路径：</strong>%Python3_HOME%\Scripts;%Python2_HOME%\Scripts;</p><p>（使用时通过pip2和pip3分别调用对应路径使用）</p><p><img src="/2019/11/01/windows下python2-0与3-0共存/xtbl.png" alt></p><h4><span id="测试">测试</span></h4><p><img src="/2019/11/01/windows下python2-0与3-0共存/testpython.png" alt></p><p>这样我们在使用IDE的时候，就可根据版本需求对路径进行设置就可以了。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;解决烦人的版本兼容问题很简单。&lt;/p&gt;
    
    </summary>
    
      <category term="python" scheme="https://newpants_top/categories/python/"/>
    
    
      <category term="python兼容" scheme="https://newpants_top/tags/python%E5%85%BC%E5%AE%B9/"/>
    
  </entry>
  
  <entry>
    <title>Typora快捷使用</title>
    <link href="https://newpants_top/2019/10/30/Typora%E5%BF%AB%E6%8D%B7%E4%BD%BF%E7%94%A8/"/>
    <id>https://newpants_top/2019/10/30/Typora快捷使用/</id>
    <published>2019-10-30T05:22:41.000Z</published>
    <updated>2019-10-30T06:36:51.728Z</updated>
    
    <content type="html"><![CDATA[<p>Typora快捷使用记录。</p><a id="more"></a><!-- toc --><ul><li><a href="#markdown">Markdown</a></li><li><a href="#typora">Typora</a><ul><li><a href="#快捷键">快捷键</a></li><li><a href="#增加文章类别">增加文章类别</a></li><li><a href="#增加文章内目录">增加文章内目录</a></li><li><a href="#增加链接">增加链接</a></li><li><a href="#增加隐藏文章">增加隐藏文章</a></li></ul></li></ul><!-- tocstop --><h4><span id="markdown">Markdown</span></h4><p>Markdown是一种轻量级标记语言，允许人们使用易读写的纯文本格式编写文档。</p><p>可导出HTML、Word、图像、PDF等多种格式的文档。</p><p>文档后缀名为.md或.markdown</p><h4><span id="typora">Typora</span></h4><p>Typora是一款支持Markdown语法的编辑器。</p><h5><span id="快捷键">快捷键</span></h5><table><thead><tr><th>组合</th><th>说明</th></tr></thead><tbody><tr><td>ctrl+Shift+i</td><td>快速插入图片</td></tr><tr><td>ctrl+b</td><td>加粗</td></tr></tbody></table><h5><span id="增加文章类别">增加文章类别</span></h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"categories: xxx"</span></span><br></pre></td></tr></table></figure><h5><span id="增加文章内目录">增加文章内目录</span></h5><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;!-- toc --&gt;</span><br></pre></td></tr></table></figure><h5><span id="增加链接">增加链接</span></h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[]()</span><br></pre></td></tr></table></figure><h5><span id="增加隐藏文章">增加隐藏文章</span></h5><p>在头部增加：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"notshow: true"</span></span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Typora快捷使用记录。&lt;/p&gt;
    
    </summary>
    
      <category term="Typora" scheme="https://newpants_top/categories/Typora/"/>
    
    
      <category term="Typora" scheme="https://newpants_top/tags/Typora/"/>
    
      <category term="Markdown" scheme="https://newpants_top/tags/Markdown/"/>
    
  </entry>
  
  <entry>
    <title>容器增加扩展并重新编译</title>
    <link href="https://newpants_top/2019/10/30/%E5%AE%B9%E5%99%A8%E5%A2%9E%E5%8A%A0%E6%89%A9%E5%B1%95%E5%B9%B6%E9%87%8D%E6%96%B0%E7%BC%96%E8%AF%91/"/>
    <id>https://newpants_top/2019/10/30/容器增加扩展并重新编译/</id>
    <published>2019-10-30T05:20:34.000Z</published>
    <updated>2019-10-30T06:29:02.783Z</updated>
    
    <content type="html"><![CDATA[<p>容器增加扩展并重新编译</p><a id="more"></a><p>先为工作中的情况记录一下，日后考虑写成脚本运行。</p><!-- toc --><ul><li><a href="#php72增加扩展">php72增加扩展</a></li><li><a href="#重新编译容器">重新编译容器</a></li><li><a href="#增加crond任务">增加crond任务</a></li><li><a href="#容器中安装supervisor">容器中安装supervisor</a></li><li><a href="#容器中配置superviosr">容器中配置superviosr</a></li><li><a href="#启动容器内supervisor服务">启动容器内Supervisor服务</a></li><li><a href="#supervisor命令">Supervisor命令</a></li><li><a href="#其他脚本路径说明">其他脚本路径说明</a><ul><li><a href="#重启php72容器脚本">重启php72容器脚本</a></li><li><a href="#构建触发脚本">构建触发脚本</a></li><li><a href="#项目备份脚本">项目备份脚本</a></li><li><a href="#构建脚本">构建脚本</a></li></ul></li></ul><!-- tocstop --><h4><span id="php72增加扩展">php72增加扩展</span></h4><p>命令：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@VM_0_6_centos ~]#vim /data/docker/dnmp-master/.env</span><br></pre></td></tr></table></figure><p>增加扩展：找到对应版本，在”PHP72_EXTENSIONS”行最后方增加扩展，使用符号：”,”相隔</p><p><img src="/2019/10/30/容器增加扩展并重新编译/addenv.png" alt></p><h4><span id="重新编译容器">重新编译容器</span></h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@VM_0_6_centos ~]#cd /data/docker/dnmp-master/</span><br><span class="line">[root@VM_0_6_centos ~]#docker-compose build php72</span><br><span class="line">[root@VM_0_6_centos ~]#docker-compose up -d php72</span><br></pre></td></tr></table></figure><h4><span id="增加crond任务">增加crond任务</span></h4><p>进入容器：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@VM_0_6_centos ~]#docker exec -it dnmpmaster_php72_1 sh</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">/var/www/html #crontab -e </span><br><span class="line"></span><br><span class="line">&lt;-----------------------------------保存增加--------------------------------------</span><br><span class="line"></span><br><span class="line">*       *       *       *       *       cd /var/www/html/script.airdroid.com &amp;&amp; php artisan schedule:run &gt;&gt; /dev/null 2&gt;&amp;1</span><br><span class="line"></span><br><span class="line"><span class="meta">---------------------------------------------------------------------------------&gt;</span></span><br><span class="line">/var/www/html #crond start</span><br></pre></td></tr></table></figure><h4><span id="容器中安装supervisor">容器中安装supervisor</span></h4><p>进入容器：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@VM_0_6_centos ~]#docker exec -it dnmpmaster_php72_1 sh</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/var/www/html #wget --no-check-certificate https://bootstrap.pypa.io/ez_setup.py -O - | python</span><br></pre></td></tr></table></figure><p>容器中安装：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/var/www/html # easy_install supervisor</span><br></pre></td></tr></table></figure><h4><span id="容器中配置superviosr">容器中配置superviosr</span></h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">/var/www/html #/etc/supervisor</span><br><span class="line">/var/www/html #echo_supervisord_conf &gt; /etc/supervisor/supervisord.conf</span><br></pre></td></tr></table></figure><p>编辑supervisord配置文件：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/var/www/html # vi /etc/supervisor/supervisord.conf</span><br></pre></td></tr></table></figure><p>找到[include]，将files行改为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">files = /etc/supervisor/conf/*.ini</span><br></pre></td></tr></table></figure><p><img src="/2019/10/30/容器增加扩展并重新编译/supervisord_conf.png" alt></p><p>目前两个文件：horizon.ini 和 stat.ini</p><p>容器外备份目录：<strong>/etc/supervisor/docker_backup/</strong></p><p>容器内目录：<strong>/etc/supervisor/conf/</strong></p><p>利用docker cp命令进行拷贝：</p><p>将主机/etc/supervisor/docker_backup/conf目录拷贝到容器dnmpmaster_php72_1/etc/supervisor/下</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@VM_0_6_centos ~]#docker cp /etc/supervisor/docker_backup/conf dnmpmaster_php72_1:/etc/supervisor/</span><br></pre></td></tr></table></figure><p>将容器 dnmpmaster_php72_1的 /etc/supervisor/conf目录拷贝到主机/etc/supervisor/docker_backup/下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@VM_0_6_centos ~]#docker cp dnmpmaster_php72_1:/etc/supervisor/conf /etc/supervisor/docker_backup/</span><br></pre></td></tr></table></figure><h4><span id="启动容器内supervisor服务">启动容器内Supervisor服务</span></h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/var/www/html #supervisord -c /etc/supervisor/supervisord.conf</span><br></pre></td></tr></table></figure><h4><span id="supervisor命令">Supervisor命令</span></h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">supervisorctl status</span><br><span class="line">supervisorctl stop xxx</span><br><span class="line">supervisorctl start xxx</span><br><span class="line">supervisorctl restart xxx</span><br></pre></td></tr></table></figure><h4><span id="其他脚本路径说明">其他脚本路径说明</span></h4><h5><span id="重启php72容器脚本">重启php72容器脚本</span></h5><p><strong>restart_docker_php.sh</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@VM_0_6_centos ~]#cat /root/shell/restart_docker_php.sh</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span>!/bin/bash</span><br><span class="line">docker restart dnmpmaster_php72_1</span><br><span class="line">docker exec dnmpmaster_php72_1 crond start</span><br><span class="line">docker exec dnmpmaster_php72_1 supervisord -c /etc/supervisor/supervisord.conf</span><br></pre></td></tr></table></figure><h5><span id="构建触发脚本">构建触发脚本</span></h5><p><strong>docker_php72.sh</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[root@VM_0_6_centos ~]#cat /root/shell/docker_php72.sh</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span>!/bin/bash</span><br><span class="line">mv /data/docker/dnmp-master/www/</span><br><span class="line">/.env.production /data/docker/dnmp-master/www/script.airdroid.com/.env</span><br><span class="line">docker exec dnmpmaster_php72_1 sh /var/www/html/build.sh</span><br><span class="line">chmod 777 -R /data/docker/dnmp-master/www/script.airdroid.com/storage/</span><br><span class="line">chmod 777 -R /data/docker/dnmp-master/www/script.airdroid.com/bootstrap/cache/</span><br><span class="line"><span class="meta">#</span>mkdir -R /data/docker/dnmp-master/www/script.airdroid.com/storage/framework/sessions</span><br><span class="line"><span class="meta">#</span>chmod 777 -R /data/docker/dnmp-master/www/script.airdroid.com/storage/framework/sessions</span><br><span class="line"><span class="meta">#</span>mv /data/docker/dnmp-master/www/script.airdroid.com/.env.production /data/docker/dnmp-master/www/script.airdroid.com/.env</span><br><span class="line">docker  exec dnmpmaster_php72_1 supervisorctl restart laravel-queue-worker:*</span><br></pre></td></tr></table></figure><h5><span id="项目备份脚本">项目备份脚本</span></h5><p><strong>script.airdroid_backup.sh</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[root@VM_0_6_centos ~]#cat /root/shell/script.airdroid_backup.sh</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span>!/bin/bash</span><br><span class="line"><span class="meta">#</span>&lt;-------利用rsync备份项目script.airdroid.com下的目录：---------&gt;</span><br><span class="line"><span class="meta">#</span>源路径：</span><br><span class="line"><span class="meta">#</span>  script.airdroid.com/public/data</span><br><span class="line"><span class="meta">#</span>         script.airdroid.com/storage/app/sourcesData</span><br><span class="line"><span class="meta">#</span>目标路径(本机):</span><br><span class="line"><span class="meta">#</span>  /mnt/script.airdroid_backup/sourcesData</span><br><span class="line"><span class="meta">#</span>         /mnt/script.airdroid_backup/data</span><br><span class="line"><span class="meta">#</span></span><br><span class="line">rsync -r /data/docker/dnmp-master/www/script.airdroid.com/storage/app/sourcesData /mnt/script.airdroid_backup/</span><br><span class="line">rsync -r /data/docker/dnmp-master/www/script.airdroid.com/public/data /mnt/script.airdroid_backup/</span><br></pre></td></tr></table></figure><h5><span id="构建脚本">构建脚本</span></h5><p><strong>build.sh</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">[root@VM_0_6_centos ~]#cat /data/docker/dnmp-master/www/build.sh</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span>!/bin/bash</span><br><span class="line">cd /var/www/html/script.airdroid.com</span><br><span class="line"><span class="meta">#</span># 检测md5sum值是否更新</span><br><span class="line">file_md5sum_check() &#123;</span><br><span class="line">    file=$1</span><br><span class="line">    test -f $file || echo $file not found</span><br><span class="line">    isinstall=0</span><br><span class="line">    if [ ! -f $&#123;file&#125;.install ] || [ "`md5sum $&#123;file&#125; |awk '&#123;print $1&#125;'`" != "`md5sum $&#123;file&#125;.install |awk '&#123;print $1&#125;'`" ]; then</span><br><span class="line">        isinstall=1</span><br><span class="line">    fi</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span>## PHP 项目编译</span><br><span class="line"><span class="meta">#</span># 检测 composer.lock 文件是否更新</span><br><span class="line"><span class="meta">#</span># 更新，则执行 composer install</span><br><span class="line"><span class="meta">#</span># 最后同步composer.lock文件</span><br><span class="line">composer_install() &#123;</span><br><span class="line">    file_md5sum_check composer.lock</span><br><span class="line"><span class="meta">#</span>    if [ $isinstall -eq 1 ]; then</span><br><span class="line"><span class="meta">#</span>       echo  "waiting for composer install"</span><br><span class="line"><span class="meta">#</span>       command -v composer &gt; /dev/null 2&gt;&amp;1 || echo pls install composer</span><br><span class="line"><span class="meta">#</span>       set -e</span><br><span class="line">    composer install</span><br><span class="line">    php artisan route:clear</span><br><span class="line">    php artisan route:cache</span><br><span class="line">    php artisan config:clear</span><br><span class="line">    php artisan config:cache</span><br><span class="line"></span><br><span class="line">    php artisan clear-compiled</span><br><span class="line">    php artisan optimize</span><br><span class="line"></span><br><span class="line">    composer dump-autoload --optimize</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span>       set +e</span><br><span class="line"><span class="meta">#</span>       \cp -rpf composer.lock composer.lock.install</span><br><span class="line"><span class="meta">#</span>    else</span><br><span class="line"><span class="meta">#</span>        echo  "manual deployment, skip build"</span><br><span class="line"><span class="meta">#</span>    fi</span><br><span class="line"><span class="meta">#</span>    composer update</span><br><span class="line">&#125;</span><br><span class="line">composer_install</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;容器增加扩展并重新编译&lt;/p&gt;
    
    </summary>
    
      <category term="docker" scheme="https://newpants_top/categories/docker/"/>
    
    
      <category term="docker" scheme="https://newpants_top/tags/docker/"/>
    
      <category term="supervisor" scheme="https://newpants_top/tags/supervisor/"/>
    
  </entry>
  
  <entry>
    <title>windows环境下docker部署高可用IP代理池</title>
    <link href="https://newpants_top/2019/10/28/windows%E7%8E%AF%E5%A2%83%E4%B8%8Bdocker%E9%83%A8%E7%BD%B2%E9%AB%98%E5%8F%AF%E7%94%A8IP%E4%BB%A3%E7%90%86%E6%B1%A0/"/>
    <id>https://newpants_top/2019/10/28/windows环境下docker部署高可用IP代理池/</id>
    <published>2019-10-28T09:44:50.000Z</published>
    <updated>2019-10-28T09:46:01.451Z</updated>
    
    <content type="html"><![CDATA[<!-- toc --><!-- tocstop -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- toc --&gt;



&lt;!-- tocstop --&gt;




      
    
    </summary>
    
      <category term="爬虫" scheme="https://newpants_top/categories/%E7%88%AC%E8%99%AB/"/>
    
    
      <category term="docker" scheme="https://newpants_top/tags/docker/"/>
    
      <category term="IP代理池" scheme="https://newpants_top/tags/IP%E4%BB%A3%E7%90%86%E6%B1%A0/"/>
    
  </entry>
  
  <entry>
    <title>学习python3网络爬虫（二）各类库的使用</title>
    <link href="https://newpants_top/2019/10/25/%E5%AD%A6%E4%B9%A0python3%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB%EF%BC%88%E4%BA%8C%EF%BC%89%E5%90%84%E7%B1%BB%E5%BA%93%E7%9A%84%E4%BD%BF%E7%94%A8/"/>
    <id>https://newpants_top/2019/10/25/学习python3网络爬虫（二）各类库的使用/</id>
    <published>2019-10-25T06:07:30.000Z</published>
    <updated>2019-10-30T06:36:18.918Z</updated>
    
    <content type="html"><![CDATA[<p>各类库使用简单举例说明。</p><a id="more"></a><!-- toc --><ul><li><a href="#内置库urllib">内置库urllib</a><ul><li><a href="#urllibrequest模块">urllib.request模块:</a><ul><li><a href="#方法urlopen">方法urlopen()：</a></li><li><a href="#方法request">方法Request()</a></li></ul></li><li><a href="#urlliberror模块">urllib.error模块:</a><ul><li><a href="#urlerror">URLError</a></li><li><a href="#httperror">HTTPError</a></li></ul></li><li><a href="#urllibparse模块">urllib.parse模块:</a><ul><li><a href="#urlparse方法">urlparse()方法</a></li><li><a href="#urlunparse">urlunparse()</a></li><li><a href="#quote和unquote">quote()和unquote()</a></li></ul></li><li><a href="#urllibrobotparser模块">urllib.robotparser模块:</a></li></ul></li><li><a href="#使用requests库">使用requests库</a><ul><li><a href="#方法get">方法get()</a></li><li><a href="#保存cookies">保存cookies</a></li><li><a href="#会话维持-session">会话维持 Session</a></li><li><a href="#ssl证书验证待更">SSL证书验证（待更）</a></li><li><a href="#代理设置-proxies参数">代理设置 proxies参数</a></li></ul></li></ul><!-- tocstop --><p>python版本3.7</p><h4><span id="内置库urllib">内置库urllib</span></h4><p><a href="https://docs.python.org/3/library/urllib.html" target="_blank" rel="noopener">python3.8官方文档 urllib</a></p><h5><span id="urllibrequest模块">urllib.request模块:</span></h5><p>最基本的HTTP请求模块，模拟发送请求。好比在浏览器中输入网址后回车一样，只需要给库方法传递URL以及额外的参数，就可以模拟实现这个过程了。</p><h6><span id="方法urlopen">方法urlopen()：</span></h6><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line">response=urllib.request.urlopen(<span class="string">'https://newpants.top'</span>)</span><br><span class="line">print(type(response))</span><br></pre></td></tr></table></figure><p>得到如下结果：</p><p><img src="/2019/10/25/学习python3网络爬虫（二）各类库的使用/1.png" alt></p><p>其中利用python的type函数，打印我们请求的类型得到结果http.client.HTTPResponse。如果不了解这个http.client.HTTPResponse是什么也没有关系，只要知道这是一个与http协议相关类型就可以了。如以下几个简单的例子：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">print(type(<span class="number">1</span>))</span><br><span class="line">print(type(<span class="string">'newpants'</span>))</span><br><span class="line">print(type(&#123;<span class="number">0</span>:<span class="string">'pants'</span>&#125;))</span><br><span class="line">------------------------&gt;</span><br><span class="line"><span class="comment">#输出结果如下：</span></span><br><span class="line">&lt;<span class="class"><span class="keyword">class</span> '<span class="title">int</span>'&gt;</span></span><br><span class="line"><span class="class">&lt;<span class="title">class</span> '<span class="title">str</span>'&gt;</span></span><br><span class="line"><span class="class">&lt;<span class="title">class</span> '<span class="title">dict</span>'&gt;</span></span><br></pre></td></tr></table></figure><p>类 http.client.HTTPResponse 拥有几个如下属性和函数：</p><p>status，getcode()，getheaders()，read()，url</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line">response=urllib.request.urlopen(<span class="string">'https://newpants.top'</span>)</span><br><span class="line">print(response.status)<span class="comment">#获取状态码</span></span><br><span class="line">print(response.getheaders())<span class="comment">#获取网页头部</span></span><br><span class="line">print(response.getheader(<span class="string">'Server'</span>))<span class="comment">#添加参数，单独截取Server部分</span></span><br></pre></td></tr></table></figure><p><img src="/2019/10/25/学习python3网络爬虫（二）各类库的使用/2.png" alt></p><p>传递参数：urllib.request.urlopen(url, data=None, [timeout, ]*, cafile=None, capath=None, cadefault=False, context=None)</p><h6><span id="方法request">方法Request()</span></h6><p>urlopen()方法只是最基本的发起请求，如果想在请求中加入Headers等信息去模仿浏览器，这里就需要用到Request()</p><p>urllib.request.Request(url, data=None, headers={}, origin_req_host=None, unverifiable=False, method=None)</p><table><thead><tr><th>参数</th><th>说明</th></tr></thead><tbody><tr><td>url</td><td>必传参数，其他都是可选参数</td></tr><tr><td>data</td><td>如果要传，必须传bytes（字节流）类型的，如果为字典，可以先用urllib.parse模块里的urlencode()编码</td></tr><tr><td>headers</td><td>字典，它就是请求头，通过headers参数直接构造，也可以通过调用实例add_header()方法添加</td></tr><tr><td>origin_req_host</td><td>指请求方的host名称或者IP地址</td></tr><tr><td>unverifiable</td><td>表示这个请求是否无法验证，默认false。表示用户没有足够权限来选择接受这个请求的结果</td></tr><tr><td>method</td><td>是一个字符串，用来指示请求使用的方法，如：GET/POST/PUT等。</td></tr></tbody></table><h5><span id="urlliberror模块">urllib.error模块:</span></h5><p>异常处理模块，如果出现请求错误，可以捕获这些一场，然后进行重试或者其他操作以保证程序不会遇到这些错误时停止运行。</p><h6><span id="urlerror">URLError</span></h6><p>URLError累来自urllib库的error模块，继承OSError类，是error异常模块的基类，由request模块生成的异常都可以通过捕获这个类来处理。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib <span class="keyword">import</span> request,error</span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">response=request.urlopen(<span class="string">'https://newpants.top/test.html'</span>)<span class="comment">#访问一个不存在的页面</span></span><br><span class="line"><span class="keyword">except</span> error.URLError <span class="keyword">as</span> e:</span><br><span class="line">print(e.reason)<span class="comment">#属性reason，返回错误的原因</span></span><br><span class="line">&lt;---------------------------------------------------</span><br><span class="line"><span class="comment">#运行结果如下：</span></span><br><span class="line">Not Found</span><br><span class="line">---------------------------------------------------&gt;</span><br><span class="line">看到程序没有因报错而意外停止，而是正常运行完</span><br></pre></td></tr></table></figure><h6><span id="httperror">HTTPError</span></h6><p>URLError的子类，专门用来处理HTTP请求错误，比如认证请求失败等。有如下几个属性：</p><table><thead><tr><th>属性</th><th>说明</th></tr></thead><tbody><tr><td>code</td><td>返回HTTP状态码，比如404表示网页不存在，200表示正常获取网页等。</td></tr><tr><td>reason</td><td>同父类一样，用于返回错误原因。</td></tr><tr><td>headers</td><td>返回请求头。</td></tr></tbody></table><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#比如我们先捕获HTTPError的错误，如果不是HTTPError的错误，再捕获URLError的错误，用else处理正常情况。</span></span><br><span class="line"><span class="keyword">from</span> urllib <span class="keyword">import</span> request,error</span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">response=request.urlopen(<span class="string">'https://newpants.top'</span>)</span><br><span class="line"><span class="keyword">except</span> error.HTTPError <span class="keyword">as</span> e:</span><br><span class="line">print(e.reason,e.code,e.headers,sep=<span class="string">'\n'</span>)</span><br><span class="line"><span class="keyword">except</span> error.URLError <span class="keyword">as</span> e:</span><br><span class="line">print(e.reason)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">print(<span class="string">'Request Normal'</span>)</span><br></pre></td></tr></table></figure><h5><span id="urllibparse模块">urllib.parse模块:</span></h5><p>工具模块，提供多种URL处理方法，比如拆分、解析、合并等。</p><h6><span id="urlparse方法">urlparse()方法</span></h6><p>比如我们访问newpants.top下一个网页的URL：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib.parse <span class="keyword">import</span> urlparse</span><br><span class="line"><span class="keyword">from</span> urllib.parse <span class="keyword">import</span> unquote  <span class="comment">#unquote该方法可以对URL中有中文进行解码，以便我们查看。反之，quote为编码</span></span><br><span class="line">result=urlparse(unquote(<span class="string">'https://newpants.top/2019/10/22/%E5%AE%BF%E4%B8%BB%E6%9C%BAnginx%E8%BF%9E%E6%8E%A5docker%E5%86%85PHP/'</span>))</span><br><span class="line">print(type(result),result)</span><br></pre></td></tr></table></figure><p>运行结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&lt;class &apos;urllib.parse.ParseResult&apos;&gt; </span><br><span class="line">ParseResult(scheme=&apos;https&apos;, netloc=&apos;newpants.top&apos;, path=&apos;/2019/10/22/宿主机nginx连接d</span><br><span class="line">ocker内PHP/&apos;, params=&apos;&apos;, query=&apos;&apos;, fragment=&apos;&apos;)</span><br></pre></td></tr></table></figure><p>可以看到urlparse将结果拆分成了，scheme，netloc，path，params等多个部分。</p><p>urllib.parse.urlparse(urlstring, scheme=’’, allow_fragments=True)</p><table><thead><tr><th>参数</th><th>说明</th></tr></thead><tbody><tr><td>urlstring</td><td>必填项，等待解析的URL。</td></tr><tr><td>scheme</td><td>默认协议（比如，http或https等）。如果链接没有带协议信息，将会以scheme指定的值作为默认协议。</td></tr><tr><td>allow_fragments</td><td>是否忽略fragment。设为Flase时忽略。</td></tr></tbody></table><h6><span id="urlunparse">urlunparse()</span></h6><p>与urlparse()相对应。urlparse是分解，那么urlunparse就是合并。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#注意列表长度必须为6，否则会报错</span></span><br><span class="line"><span class="keyword">from</span> urllib.parse <span class="keyword">import</span> urlunparse</span><br><span class="line"><span class="keyword">from</span> urllib.parse <span class="keyword">import</span> unquote</span><br><span class="line">data=[<span class="string">'https'</span>,<span class="string">'newpants.top'</span>,unquote(<span class="string">'/2019/10/22/%E5%AE%BF%E4%B8%BB%E6%9C%BAnginx%E8%BF%9E%E6%8E%A5docker%E5%86%85PHP/'</span>),<span class="string">''</span>,<span class="string">''</span>,<span class="string">''</span>]</span><br><span class="line">print(urlunparse(data))</span><br></pre></td></tr></table></figure><p>运行结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://newpants.top/2019/10/22/宿主机nginx连接docker内PHP/</span><br></pre></td></tr></table></figure><h6><span id="quote和unquote">quote()和unquote()</span></h6><p>对URL中存在中文参数的情况下，unquote为解码，quote为编码。上述例子已经演示了使用方式。</p><h5><span id="urllibrobotparser模块">urllib.robotparser模块:</span></h5><p>主要用来识别网站robots.txt文件，告诉爬虫和搜索引擎哪些页面是可以抓取，哪些不可以抓取的。也称为爬虫协议、机器人协议。</p><p>简单例子，禁止所有爬虫访问任何目录：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">User-agent: *</span><br><span class="line">Disallow: /</span><br></pre></td></tr></table></figure><table><thead><tr><th>参数</th><th>说明</th></tr></thead><tbody><tr><td>User-agent</td><td>爬虫的名称，*代表任何爬虫</td></tr><tr><td>Disallow</td><td>指定不允许爬取的目录，/就代表了所有页面</td></tr><tr><td>Allow</td><td>表示可以爬取的目录或文件</td></tr></tbody></table><p>常见搜索爬虫名称及对应网站：</p><table><thead><tr><th>爬虫名称</th><th>名称</th><th>网站</th></tr></thead><tbody><tr><td>BaiduSpider</td><td>百度</td><td><a href="http://www.baidu.com" target="_blank" rel="noopener">www.baidu.com</a></td></tr><tr><td>Googlebot</td><td>谷歌</td><td><a href="http://www.google.com" target="_blank" rel="noopener">www.google.com</a></td></tr><tr><td>360Spider</td><td>360搜索</td><td><a href="http://www.so.com" target="_blank" rel="noopener">www.so.com</a></td></tr><tr><td>YodaoBot</td><td>有道</td><td><a href="http://www.youdao.com" target="_blank" rel="noopener">www.youdao.com</a></td></tr></tbody></table><h4><span id="使用requests库">使用requests库</span></h4><p>方便Cookies、登陆验证、代理设置等操作。</p><h5><span id="方法get">方法get()</span></h5><p>相当于urllib库中的urlopen()</p><p>实例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">r=requests.get(<span class="string">'https://www.baidu.com'</span>)</span><br><span class="line">print(type(r))</span><br><span class="line">print(r.status_code)</span><br><span class="line">print(type(r.text))</span><br><span class="line">print(r.text)</span><br></pre></td></tr></table></figure><p>其他请求的使用也很简单，只需：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">r=requests.post()</span><br><span class="line">r=requests.put()</span><br><span class="line">r=requests.delete()</span><br><span class="line">r=requests.head()</span><br><span class="line">r=requests.options()</span><br></pre></td></tr></table></figure><h5><span id="保存cookies">保存cookies</span></h5><p>这里模仿知乎登陆。首先登陆自己的账号，在headers中找到自己的cookie信息。</p><p><img src="/2019/10/25/学习python3网络爬虫（二）各类库的使用/zhihu.png" alt></p><p>通过get()方法指定头部信息，cookie、host和user-agent进行测试：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">headers =&#123;</span><br><span class="line"><span class="string">'Cookie'</span>:<span class="string">'_xsrf=Aft3ehkgV3V5hvMAUo2Znsq7XMyi7fwj; _zap=78af57de-887b-482b-92ea-4ff1a261e7b9; d_c0="AFBmNL--NQ-PTvZQ52LY0XRSFKZLmDdOy4w=|1554084810"; __gads=ID=4332696430ce60d2:T=1554086317:S=ALNI_Mb6t79_WOUa6zaCzYtFuNTFPXetwg; tst=r; q_c1=26a275a42378444daba08cf588784516|1570758046000|1554085804000; tgw_l7_route=f2979fdd289e2265b2f12e4f4a478330; Hm_lvt_98beee57fd2ef70ccdd5ca52b9740c49=1571895327,1571897442,1572230540,1572248034; capsion_ticket="2|1:0|10:1572248035|14:capsion_ticket|44:YzQ5ZjY2YzRkYTgxNDNkY2E5ZWJlNGI0MDE4YTI3NWU=|992d8decf1d71f019bae5ad3948484b37bc07a12a63f5a3e5c28e41f8334de7a"; z_c0="2|1:0|10:1572248069|4:z_c0|92:Mi4xYzZOaEF3QUFBQUFBVUdZMHY3NDFEeVlBQUFCZ0FsVk5CZWlqWGdDVU5jRF85V18xZ0NmYV9qQldGTmlONzhTTFpR|99da1abc31cf21602ad900ebf975a264f1a9b589e2992c5fe87675e06897aaed"; unlock_ticket="AGDAhS3DbAomAAAAYAJVTQ2htl1QHOj5UQ8fHBrpR1awJF4OmJCMqA=="; Hm_lpvt_98beee57fd2ef70ccdd5ca52b9740c49=1572248070'</span>,</span><br><span class="line"><span class="string">'User-Agent'</span>:<span class="string">'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/76.0.3809.100 Safari/537.36'</span>,</span><br><span class="line">&#125;</span><br><span class="line">r=requests.get(<span class="string">'https://www.zhihu.com/creator'</span>,headers=headers)</span><br><span class="line">print(r.text)</span><br></pre></td></tr></table></figure><h5><span id="会话维持-session">会话维持 Session</span></h5><p>方法get()和post()可以做到模拟网页请求，但是第一个利用post()登陆，再通过get()请求页面，是不行的，闲荡与打开两个浏览器分别做了两个动作。</p><p>所以这里有一个Session对象，可以用来维持会话，并且不用担心cookies的问题。</p><p>测试代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="comment">#调用Session对象</span></span><br><span class="line">s = requests.Session()</span><br><span class="line"><span class="comment">#在测试网址http://httpbin.org/cookies/set/下设置一个名为my_cookies，内容为newpants_top的cookies</span></span><br><span class="line">s.get(<span class="string">'http://httpbin.org/cookies/set/my_cookies/newpants_top'</span>) </span><br><span class="line"><span class="comment">#访问cookies获取</span></span><br><span class="line">r=s.get(<span class="string">'http://httpbin.org/cookies'</span>)</span><br><span class="line">print(r.text)</span><br></pre></td></tr></table></figure><p>运行结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;cookies&quot;: &#123;</span><br><span class="line">    &quot;my_cookies&quot;: &quot;newpants_top&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5><span id="ssl证书验证待更">SSL证书验证（待更）</span></h5><h5><span id="代理设置-proxies参数">代理设置 proxies参数</span></h5><p>如果频繁的爬取，有些网站会限制验证码，或者禁止一段时间内访问，甚至直接封掉客户端IP，为了防止这种情况发生，就需要使用代理访问。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;各类库使用简单举例说明。&lt;/p&gt;
    
    </summary>
    
      <category term="爬虫" scheme="https://newpants_top/categories/%E7%88%AC%E8%99%AB/"/>
    
    
      <category term="python" scheme="https://newpants_top/tags/python/"/>
    
  </entry>
  
  <entry>
    <title>学习python3网络爬虫（一）准备工作：安装第三方库</title>
    <link href="https://newpants_top/2019/10/24/%E5%AD%A6%E4%B9%A0python3%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB%EF%BC%88%E4%B8%80%EF%BC%89%E5%87%86%E5%A4%87%E5%B7%A5%E4%BD%9C%EF%BC%9A%E5%AE%89%E8%A3%85%E7%AC%AC%E4%B8%89%E6%96%B9%E5%BA%93/"/>
    <id>https://newpants_top/2019/10/24/学习python3网络爬虫（一）准备工作：安装第三方库/</id>
    <published>2019-10-24T07:26:17.000Z</published>
    <updated>2019-10-25T09:52:01.777Z</updated>
    
    <content type="html"><![CDATA[<p>python3网络爬虫中所需的第三方相关库</p><a id="more"></a><!-- toc --><ul><li><a href="#请求库安装requests-selenium-aiohttp">请求库安装（requests、selenium、aiohttp）</a></li><li><a href="#浏览器插件安装chromedriver">浏览器插件安装（ChromeDriver）</a></li><li><a href="#解析库安装lxml-beautifule-soup-pyquery-tesserocr">解析库安装（lxml、Beautifule Soup、pyquery、tesserocr）</a></li><li><a href="#数据库安装">数据库安装</a></li><li><a href="#存储库安装">存储库安装</a></li><li><a href="#web库安装">WEB库安装</a></li></ul><!-- tocstop --><p>爬虫可以简单分为几步：抓取页面、分析页面和储存数据。</p><p>在抓取页面的过程中，我们需要模拟浏览器向服务器发出请求，所以需要用到一些python库来实现HTTP请求操作。安装所需的一些第三方库如下：</p><h4><span id="请求库安装requests-selenium-aiohttp">请求库安装（requests、selenium、aiohttp）</span></h4><table><thead><tr><th>请求库</th><th>pip安装</th><th>功能</th></tr></thead><tbody><tr><td>requests</td><td>pip3 install requests</td><td>用于http请求的模块</td></tr><tr><td>selenium</td><td>pip3 install selenium</td><td>自动化测试工具，驱动浏览器做如点击、下拉等操作</td></tr><tr><td>aiohttp</td><td>pip3 install aiohttp</td><td>异步web服务库，提高页面数据抓取效率</td></tr></tbody></table><h4><span id="浏览器插件安装chromedriver">浏览器插件安装（ChromeDriver）</span></h4><table><thead><tr><th>浏览器插件</th><th>安装</th><th>功能</th></tr></thead><tbody><tr><td>ChromeDriver</td><td>如下图</td><td>谷歌浏览器插件，驱动谷歌浏览器完成相应的操作</td></tr></tbody></table><p>（1）查看浏览器版本</p><p><img src="/2019/10/24/学习python3网络爬虫（一）准备工作：安装第三方库/chrome.png" alt></p><p>（2）打开<a href="http://npm.taobao.org/mirrors/chromedriver/" target="_blank" rel="noopener">ChromeDriver淘宝镜像下载地址</a>下载对应的版本驱动，例如： “76.0.3809.126/“就代表支持版本为76.0的谷歌浏览器，我使用windows平台，解压并安装。</p><p><img src="/2019/10/24/学习python3网络爬虫（一）准备工作：安装第三方库/driver.png" alt></p><p>（3）直接将chromedriver.exe放入python安装所在路径的scripts目录下</p><p><img src="/2019/10/24/学习python3网络爬虫（一）准备工作：安装第三方库/script.png" alt></p><p>（4）验证。cmd中输入chromedriver</p><p><img src="/2019/10/24/学习python3网络爬虫（一）准备工作：安装第三方库/1.png" alt></p><p>（5）程序验证：控制台进入python环境输入代码</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line">browser=webdriver.Chrome()</span><br></pre></td></tr></table></figure><p><img src="/2019/10/24/学习python3网络爬虫（一）准备工作：安装第三方库/2.png" alt></p><h4><span id="解析库安装lxml-beautifule-soup-pyquery-tesserocr">解析库安装（lxml、Beautifule Soup、pyquery、tesserocr）</span></h4><table><thead><tr><th>解析库</th><th>pip安装</th><th>功能</th></tr></thead><tbody><tr><td>lxml</td><td>pip3 install lxml</td><td>HTML和XML解析，支持XPath解析方式，解析效率较高</td></tr><tr><td>Beautifule Soup</td><td>pip3 install beautifulsoup4</td><td>HTML或XML解析库。强大API和多样解析方式</td></tr><tr><td>pyquery</td><td>pip3 install pyquery</td><td>jQuery类似解析HTML文档，支持CSS选择器</td></tr></tbody></table><p>tesserocr是Python的一个OCR识别库，识别验证码转化为文字，但其实是对<strong>tesseract</strong>做的一层Python <strong>API封装</strong>，所以他的核心是<strong>tesseract</strong>。因此，在安装tesserocr之前，需要安装tesseract：</p><p> <a href="https://digi.bib.uni-mannheim.de/tesseract/" target="_blank" rel="noopener">tesseract官方下载地址</a></p><p>(dev为开发版，选不是dev版本的，我这里选择比较新的64位，4.0版本：tesseract-ocr-w64-setup-v4.0.0.20181030.exe)</p><p><img src="/2019/10/24/学习python3网络爬虫（一）准备工作：安装第三方库/3.png" alt></p><p>tesseract安装成功后再安装tesserocr，windows下安装tesserocr使用pip的方式会<strong>各种报错</strong>，为方便所以此处采用<strong>whl方式安装</strong>。</p><p>首先把tesseract加到系统变量里，顺便打开cmd查看tesseract的版本：</p><p><img src="/2019/10/24/学习python3网络爬虫（一）准备工作：安装第三方库/5.png" alt></p><p>tesseract -v查看版本：</p><p><img src="/2019/10/24/学习python3网络爬虫（一）准备工作：安装第三方库/6.png" alt></p><p>安装tesserocr，在<a href="https://github.com/simonflueckiger/tesserocr-windows_build/releases" target="_blank" rel="noopener">tesserocr github下载地址</a>选择tesseract对应的版本，<strong>注意tesseract和python的版本对应你机器上的版本</strong>：</p><p><img src="/2019/10/24/学习python3网络爬虫（一）准备工作：安装第三方库/7.png" alt></p><p>将下载下来的whl文件放置在某个目录下，进入到目录中，使用命令安装：pip3 install xxxxx.whl</p><p><img src="/2019/10/24/学习python3网络爬虫（一）准备工作：安装第三方库/8.png" alt></p><p>最后来验证一下tesserocr效果：</p><p>（1）验证安装是否正确无误，随便写个程序import导入一下，或者直接在终端中：</p><p><img src="/2019/10/24/学习python3网络爬虫（一）准备工作：安装第三方库/9.png" alt></p><p>（2）随便弄一张字母的图片，也可以保存我下面这张到你本地</p><p><img src="/2019/10/24/学习python3网络爬虫（一）准备工作：安装第三方库/spiderTest.png" alt></p><p>直接新建一个py文件，输入代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tesserocr</span><br><span class="line">print(tesserocr.file_to_text(<span class="string">'D:/spiderTest.png'</span>))</span><br></pre></td></tr></table></figure><p>第一次运行报错”failed to init API ,possibly an invalid tessdata”：</p><p><img src="/2019/10/24/学习python3网络爬虫（一）准备工作：安装第三方库/10.png" alt></p><p>找不到API路径tessdata。</p><p>解决方法，将<strong>tesseract</strong>安装目录下的<strong>tessdata文件夹</strong>复制粘贴到提示的python路径下：</p><p><img src="/2019/10/24/学习python3网络爬虫（一）准备工作：安装第三方库/12.png" alt></p><p>再次运行，成功：</p><p><img src="/2019/10/24/学习python3网络爬虫（一）准备工作：安装第三方库/11.png" alt></p><h4><span id="数据库安装">数据库安装</span></h4><p>数据库作为数据存储，本文使用关系型数据库MySQL，安装版本windows MSI安装，5.7版本。<a href="https://dev.mysql.com/downloads/windows/installer/5.7.html" target="_blank" rel="noopener">Windows MSI Installer 5.7.28 官网下载地址</a></p><h4><span id="存储库安装">存储库安装</span></h4><p>Python存储库，提供Python和数据库交互的方式。MySQL需要安装PyMySQL。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip3 install pymysql</span><br></pre></td></tr></table></figure><p>验证：</p><p><img src="/2019/10/24/学习python3网络爬虫（一）准备工作：安装第三方库/13.png" alt></p><h4><span id="web库安装">WEB库安装</span></h4>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;python3网络爬虫中所需的第三方相关库&lt;/p&gt;
    
    </summary>
    
      <category term="爬虫" scheme="https://newpants_top/categories/%E7%88%AC%E8%99%AB/"/>
    
    
      <category term="python" scheme="https://newpants_top/tags/python/"/>
    
  </entry>
  
  <entry>
    <title>宿主机nginx连接docker内PHP</title>
    <link href="https://newpants_top/2019/10/22/%E5%AE%BF%E4%B8%BB%E6%9C%BAnginx%E8%BF%9E%E6%8E%A5docker%E5%86%85PHP/"/>
    <id>https://newpants_top/2019/10/22/宿主机nginx连接docker内PHP/</id>
    <published>2019-10-22T07:26:21.000Z</published>
    <updated>2019-10-22T07:56:48.902Z</updated>
    
    <content type="html"><![CDATA[<p>宿主机nginx连接docker内PHP</p><a id="more"></a><!-- toc --><!-- tocstop --><p>显示情况下，我们会遇到PHP版本兼容的问题，可能一个老项目是5.6写的，而项目都是一直跑在服务器上自带的nginx上，系统安装的也是5.6版本的PHP。而新项目由PHP7.2编写，这时候我们还想在机器上好好的跑这个项目的话，就需要用到docker了。</p><p>在docker内部署PHP7.2的镜像并启动和映射目录，讲项目代码放进去，再配置宿主机的nginx配置文件。</p><p>例如，我这里已经部署并启动好了一个PHP7.2的容器：</p><p><img src="/2019/10/22/宿主机nginx连接docker内PHP/1.png" alt></p><p>这里我的挂载目录为（也就是映射目录）：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span>查看容器详情</span><br><span class="line">[root@VM_0_6_centos ~]#docker inspect 容器NAMES或者ID</span><br></pre></td></tr></table></figure><p><img src="/2019/10/22/宿主机nginx连接docker内PHP/2.png" alt></p><p>这里我们只要确定好我们项目的映射目录就可以了，像我这里，容器内的映射路径为：/var/www/html</p><p>容器外宿主机的实际路径为：/data/docker/dnmp-master/www</p><p>接下来，直接添加一个项目的*.conf文件，例如我这里的项目是abc.com。放在宿主机/data/docker/dnmp-master/www/abc.com下，映射到容器内/var/www/html/abc.com下。</p><p>abc.conf文件：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">server &#123;</span><br><span class="line">    listen       80;</span><br><span class="line">    server_name  abc.com;</span><br><span class="line">(1) root   /data/docker/dnmp-master/www/abc.com;</span><br><span class="line">    index  index.php index.html index.htm;</span><br><span class="line">    include conf.d/limitip_lan.conf;</span><br><span class="line">    access_log /dev/null;</span><br><span class="line">(4) error_log  /var/log/nginx/abc.error.log  warn;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    error_page   500 502 503 504  /50x.html;</span><br><span class="line">    location = /50x.html &#123;</span><br><span class="line">        root   /usr/local/openresty/nginx/html;</span><br><span class="line">    &#125;</span><br><span class="line">    location / &#123;</span><br><span class="line">        try_files $uri $uri/ /index.php?$query_string;</span><br><span class="line">    &#125;</span><br><span class="line">    location ~ \.php$ &#123;</span><br><span class="line"> </span><br><span class="line">(2)     fastcgi_pass   172.17.0.2:9000;</span><br><span class="line">        fastcgi_index  index.php;</span><br><span class="line">        include        fastcgi_params;</span><br><span class="line">        </span><br><span class="line">(3)     fastcgi_param  SCRIPT_FILENAME /var/www/html/abc.com/$fastcgi_script_name;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>这里比较重要的是上面（1）（2）（3），如果你之前是使用本机自带的PHP，大部分地方是不需要更改的，唯一要注意以上三处需要更改。</p><p>（1）要填入项目所在容器外的实际路径</p><p>（2）fastcgi_pass原本的配置是127.0.0.1:9000;或localhost:9000;</p><p>那是因为要访问本地的PHP，但我们现在需要访问docker内的PHP，通过docker ps 我们可以看到端口映射还是9000，所以就不用更改，唯一是这个IP。这里需要改成docker的IP，通过命令查看：</p><p><img src="/2019/10/22/宿主机nginx连接docker内PHP/3.png" alt></p><p>通过查看得知docker内IP，这时更改fastcgi_pass 172.17.0.2:9000;即可</p><p>（3）</p><p>默认配置为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fastcgi_param  SCRIPT_FILENAME  $document_root$fastcgi_script_name;</span><br></pre></td></tr></table></figure><p>更改后的配置为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fastcgi_param  SCRIPT_FILENAME /var/www/html/abc.com/$fastcgi_script_name;</span><br></pre></td></tr></table></figure><p>其中$document_root要更改为的路径是容器映射的路径，我们已经通过命令：”docker inspect 容器NAMES或者ID”查看过了。所以这里也要对应才行，记得项目后一定要加上”/“，否则会找不到路径。</p><p>配置完.conf文件后，对nginx服务器进行测试并重启。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@VM_0_6_centos ~]#nginx -t</span><br><span class="line">[root@VM_0_6_centos ~]#nginx -s reload</span><br></pre></td></tr></table></figure><p>没有报错后，就用浏览器看看项目是否正常吧。如果不能正确访问，再通过abc.conf文件(4)指定的error_log查看具体错误进行解决。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;宿主机nginx连接docker内PHP&lt;/p&gt;
    
    </summary>
    
      <category term="docker" scheme="https://newpants_top/categories/docker/"/>
    
    
      <category term="docker" scheme="https://newpants_top/tags/docker/"/>
    
      <category term="nginx" scheme="https://newpants_top/tags/nginx/"/>
    
  </entry>
  
  <entry>
    <title>elasticsearch配置及优化</title>
    <link href="https://newpants_top/2019/10/22/elasticsearch%E9%85%8D%E7%BD%AE%E5%8F%8A%E4%BC%98%E5%8C%96/"/>
    <id>https://newpants_top/2019/10/22/elasticsearch配置及优化/</id>
    <published>2019-10-22T06:18:29.000Z</published>
    <updated>2019-10-22T07:56:50.931Z</updated>
    
    <content type="html"><![CDATA[<p>elasticsearch配置及优化</p><a id="more"></a><!-- toc --><ul><li><a href="#elasticsearchyml文件基本配置">elasticsearch.yml文件基本配置</a></li><li><a href="#设置elasticsearch的java虚拟机jvm最大可用内存">设置elasticsearch的java虚拟机（jvm）最大可用内存</a></li><li><a href="#修改操作系统打开的文件描述符以满足elasticsearch使用">修改操作系统打开的文件描述符以满足elasticsearch使用</a></li><li><a href="#关于elasticsearch中常用术语及概念">关于elasticsearch中常用术语及概念</a><ul><li><a href="#cluster集群">cluster(集群)</a></li><li><a href="#node节点">node(节点)</a></li><li><a href="#document文档">document(文档)</a></li><li><a href="#field字段">field(字段)</a></li><li><a href="#index索引">index(索引)</a></li><li><a href="#shard分片">shard(分片)</a></li><li><a href="#type类型">type(类型)</a></li><li><a href="#mapping映射">mapping(映射)</a></li></ul></li><li><a href="#elasticsearch索引查询使用指南">elasticsearch索引查询使用指南</a><ul><li><a href="#查看集群健康状态">查看集群健康状态</a></li><li><a href="#获取所有节点">获取所有节点</a></li><li><a href="#列出所有索引">列出所有索引</a></li><li><a href="#创建索引">创建索引</a></li><li><a href="#删除索引">删除索引</a></li></ul></li></ul><!-- tocstop --><p>elasticsearch安装好后，也运行正常了。接下来就需要通过一些实际的环境对elasticsearch的一些配置做出一些优化。elasticsearch在ELK整套系统中扮演着类似数据库的角色，我们要把查到的数据储存在elasticsearch中，随后调用他的9200端口（默认）来查询。</p><h4><span id="elasticsearchyml文件基本配置">elasticsearch.yml文件基本配置</span></h4><p>如果你是按照rpm方式安装，安装完成后，通过shell命令:”whereis elasticsearch”找到elasticsearch的安装目录。正常情况下，elasticsearch.yml文件会在路径：”/etc/elasticsearch/elasticsearch.yml”下：</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#这里放上我的配置以供参考，注：我这里没有设置集群</span></span><br><span class="line"><span class="comment"># ======================== Elasticsearch Configuration =========================</span></span><br><span class="line"><span class="comment"># 集群名称，默认是elasticsearch</span></span><br><span class="line"><span class="comment"># cluster.name: my-application</span></span><br><span class="line"><span class="comment"># </span></span><br><span class="line"><span class="comment"># 节点名称，默认从elasticsearch-2.4.3/lib/elasticsearch-2.4.3.jar!config/names.txt中随机选择一个名称</span></span><br><span class="line"><span class="comment"># node.name: node-1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># ----------------------------------- Paths ------------------------------------</span></span><br><span class="line"><span class="comment">#node存储数据的路径，因为采集日志的量很大，尽量选择比较充裕的磁盘</span></span><br><span class="line"><span class="string">path.data:</span> <span class="string">/data/elasticsearch_paths/elasticsearch_data</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#日志路径，为后续出现问题方便排查</span></span><br><span class="line"><span class="string">path.logs:</span> <span class="string">/data/elasticsearch_paths/elasticsearch_logs</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># ----------------------------------- Memory -----------------------------------</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#若启动日志报错：&lt;----------------------</span></span><br><span class="line"><span class="comment">#[1] bootstrap checks failed</span></span><br><span class="line"><span class="comment">#[1]: memory locking requested for elasticsearch process but memory is not locked</span></span><br><span class="line"><span class="comment">#---------------------------&gt;</span></span><br><span class="line"><span class="comment">#这个配置的意义：锁定物理内存地址，防止es内存被交换出去，也就是避免es使用swap交换分区，频繁的交换，会导致IOPS变高。导致以上报错原因：使用默认值false，或者/etc/security/limits.conf下内存锁限制没有设置</span></span><br><span class="line"><span class="string">bootstrap.memory_lock:</span> <span class="literal">true</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#若启动日志报错：&lt;----------------------</span></span><br><span class="line"><span class="comment">#[1]:system call filters failed to install; check the logs and fix your configuration or disable system call filters at your own risk</span></span><br><span class="line"><span class="comment">#---------------------------&gt;</span></span><br><span class="line"><span class="string">bootstrap.system_call_filter:</span> <span class="literal">false</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Make sure that the heap size is set to about half the memory available</span></span><br><span class="line"><span class="string">monitor.jvm.gc.overhead.warn:</span> <span class="number">90</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># ---------------------------------- Network -----------------------------------</span></span><br><span class="line"><span class="comment">#设置elasticsearch的host ip，可以设为127.0.0.1或者localhost，但为了其他机器也能访问该服务器的端口，这里直接使用该台服务器的IP地址</span></span><br><span class="line"><span class="string">network.host:</span> <span class="number">192.168</span><span class="number">.40</span><span class="number">.248</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#自定义端口号，默认为9200，elasticsearch开启后，除了这里设置的端口，还会有一个9300的端口</span></span><br><span class="line"><span class="string">http.port:</span> <span class="number">9200</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#注：因为我这里没有配置集群，所以集群名字采用默认，并且注释掉node节点名字，防止脑裂发生，导致程序失效</span></span><br></pre></td></tr></table></figure><h4><span id="设置elasticsearch的java虚拟机jvm最大可用内存">设置elasticsearch的java虚拟机（jvm）最大可用内存</span></h4><p>默认路径：”/etc/elasticsearch/jvm.options”</p><p>为了设置用于elastcisearch最大可用内存，如果启动时日志中报内存不足的信息，根据实际机器内存情况修改此处大小就可以了。</p><p><img src="/2019/10/22/elasticsearch配置及优化/jvm.png" alt></p><p>默认512M，刚开始启动是没问题的，但是随着你文件数量的增加，就无法启动。我这里设置11G，根据机器实际情况来设置，官方提示最大不能超过32G。</p><h4><span id="修改操作系统打开的文件描述符以满足elasticsearch使用">修改操作系统打开的文件描述符以满足elasticsearch使用</span></h4><p>启动报关于<code>[1]: max ``file</code> <code>descriptors [65535] ``for</code> <code>elasticsearch process is too low, increase to at least [65536]</code>的错误，是限制了打开最多文件描述符的问题，只要修改文件：/etc/security/limits.conf</p><p><img src="/2019/10/22/elasticsearch配置及优化/limits.png" alt></p><p>*:代表不限制账户，如果你是用elasticsearch专属用户启动，那么这里建议改成elasticsearch</p><p>具体这个文件的含义可以百度一下。</p><h4><span id="关于elasticsearch中常用术语及概念">关于elasticsearch中常用术语及概念</span></h4><h5><span id="cluster集群">cluster(集群)</span></h5><p>解释：表示由多个节点组成的ES集群（常见集群种类：HA，HB，HP，具体可自行查阅资料）。集群有一个名称，默认是elasticsearch，可以在配置文件中通过cluster.name字段手动指定，集群最小节点数可以为1个。</p><h5><span id="node节点">node(节点)</span></h5><p>解释：集群中的节点。节点也有自己的名称，默认是随机分配的，默认情况下，节点启动之后，会自动去寻找名称为cluster.name字段所指定的集群。如果在默认不修改cluster.name的情况下，启动多个节点之后，它们会自动组成一个ES集群。</p><h5><span id="document文档">document(文档)</span></h5><p>解释：文档。它是ES中的最小数据单元，通常使用JSON数据结构表示，每个index(索引)的type(类型)中，都可以存储多个Document。</p><h5><span id="field字段">field(字段)</span></h5><p>解释：表示字段，具体指的是Document中的某一个数据字段。比如学生信息文档中的学号字段。</p><h5><span id="index索引">index(索引)</span></h5><p>解释：索引。是多个有相似结构的文档数据的集合，类似于MySQL数据库中的数据库概念。</p><h5><span id="shard分片">shard(分片)</span></h5><p>解释：每个index会被拆分为多个shard，每个shard就会存放这个index的一部分数据，这此shard会散落在多台服务器上。有了shard就可以进行横向扩展，存储更多数据，让搜索和分析等操作分布到多台服务器上去执行，提升吞吐量和性能。shard又分为replica shard和primary shard，每个shard都是一个lucene index.</p><h5><span id="type类型">type(类型)</span></h5><p>解释：类型。表示某个索引下面的某种相同数据结构的结合。在较低版本的ES中，一个索引中可以有多个type，高版本中一个索引下只能有一个类型，官方建议每个索引下最好只有一个type。如果一个index下有多个type，在不同的搜索场景下可能会相互有影响，比如：一个索引下面有一个用于统计分析的type和一个用于搜索的type，如果统计请求比较慢，有可能会阻塞到查询请求。</p><h5><span id="mapping映射">mapping(映射)</span></h5><p>解释：映射像关系数据库中的表结构，每一个索引都有一个映射，它定义了索引中的每一个字段类型，以及一个索引范围内的设置。一个映射可以事先被定义，或者在第一次储存文档的时候被自动识别。</p><h4><span id="elasticsearch索引查询使用指南">elasticsearch索引查询使用指南</span></h4><p>通过端口来对elasticsearch状态进行查询，创建，删除节点等操作。其实高级版本的kibana已经为我们提供了API接口来做所有的事情。所以以下这些语句，可以直接复制粘贴到kibana的开发工具中使用，因为kibana会帮你自动转换。</p><h5><span id="查看集群健康状态">查看集群健康状态</span></h5><p>curl ‘192.168.40.248:9200/_cat/health?v’</p><p><img src="/2019/10/22/elasticsearch配置及优化/cat.png" alt></p><p>这里的IP就要写我们在elasticsearch.yml中配置的host IP了。</p><p>通过查询可以看到集群状态，同样也可以用浏览器直接打开网址+端口的方式：</p><p><img src="/2019/10/22/elasticsearch配置及优化/9200.png" alt></p><p>注：green代表所有节点、分片都可用，yellow代表可能部分分片不可用，red代表集群存在问题。如果你并没有设置集群，但是使用了默认的分片规则，那么是一定会导致yellow的，更多请学习分片概念，同样在下方kibana使用的链接中展示。</p><p>以下语句就不一一截图列举了，更多实际使用效果在kibana的使用中展示，<a href>待更新</a>：</p><h5><span id="获取所有节点">获取所有节点</span></h5><p>curl ‘192.168.40.248:9200/_cat/nodes?v’</p><h5><span id="列出所有索引">列出所有索引</span></h5><p>curl ‘192.168.40.248:9200/_cat/indices?v’</p><h5><span id="创建索引">创建索引</span></h5><p>curl -XPUT ‘192.168.40.248:9200/customer?pretty’</p><h5><span id="删除索引">删除索引</span></h5><p>curl -XDELETE ‘192.168.40.248:9200/customer?pretty’</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;elasticsearch配置及优化&lt;/p&gt;
    
    </summary>
    
      <category term="ELK" scheme="https://newpants_top/categories/ELK/"/>
    
    
      <category term="elasticsearch" scheme="https://newpants_top/tags/elasticsearch/"/>
    
  </entry>
  
  <entry>
    <title>tinyfecvpn、tinyPortmapper、ss科学上网</title>
    <link href="https://newpants_top/2019/09/29/tinyvpn%E3%80%81tinymapper%E3%80%81ss%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91/"/>
    <id>https://newpants_top/2019/09/29/tinyvpn、tinymapper、ss科学上网/</id>
    <published>2019-09-29T08:49:26.000Z</published>
    <updated>2019-09-30T03:49:00.168Z</updated>
    
    <content type="html"><![CDATA[<p>外面的世界很精彩，外面的世界很无奈。</p><a id="more"></a><!-- toc --><ul><li><a href="#tinyfecyvpn">tinyfecyvpn</a></li><li><a href="#tinyportmapper">tinyPortmapper</a></li><li><a href="#shadowsocks">shadowsocks</a></li><li><a href="#原理">原理</a></li><li><a href="#搭建tinyvpn">搭建tinyvpn</a><ul><li><a href="#服务端">服务端</a></li><li><a href="#客户端">客户端</a></li><li><a href="#效果测试">效果测试</a></li></ul></li><li><a href="#搭建tinyportmapper">搭建tinyPortmapper</a></li><li><a href="#搭建shadowsocks">搭建shadowsocks</a><ul><li><a href="#服务端-1">服务端</a></li><li><a href="#客户端-1">客户端</a></li><li><a href="#测试效果">测试效果</a></li></ul></li></ul><!-- tocstop --><h4><span id="tinyfecyvpn">tinyfecyvpn</span></h4><p>tinyfecyvpn主要是在两台机器相互之间网络很差的情况下使用，比如，一台是国外机器，一台是国内的，或者其他一些因素导致两端网络不稳定。此时tinyfecyvpn为两端建立一个vpn通道。再通过一些参数设置，可以轻易把网络丢包率降低到万分之一以下。</p><p><a href="https://github.com/wangyu-/tinyfecVPN" target="_blank" rel="noopener">tinfecyvpn  Github地址</a></p><p>可以直接看作者的github中文说明，已经很详细了。</p><h4><span id="tinyportmapper">tinyPortmapper</span></h4><p>主要负责端口和流量的转发，后面的搭建过程中我们就可以看到，tinyfecyvpn直接是UDP协议。而tinyPortmapper是TCP协议。</p><p><a href="https://github.com/wangyu-/tinyPortMapper" target="_blank" rel="noopener">tinyPortmapper Github地址</a></p><h4><span id="shadowsocks">shadowsocks</span></h4><p>我们最后实则需要使用到的FAN墙软件。搭建过程比较简单。分为客户端和服务端。原理其实就是我们通过客户端访问服务端这个软件，服务端再去访问我们想要的网站。服务端需要是国外服务器。</p><p><a href="https://github.com/shadowsocks/shadowsocks-windows" target="_blank" rel="noopener">shadowsocks-windows版本Github地址</a></p><p>注：linux版本通过命令安装，后续会讲。</p><h4><span id="原理">原理</span></h4><p><img src="/2019/09/29/tinyvpn、tinymapper、ss科学上网/vpn.png" alt></p><p>基本原理就如上图所示，然后这里说明一下：</p><p>为了方便，我这里用 </p><p><strong>1.1.1.1</strong> 替代 <strong>SS客户端IP</strong></p><p><strong>2.2.2.2</strong> 代替 <strong>国内转发服务器IP</strong></p><p><strong>3.3.3.3</strong> 代替 <strong>国外SS服务端IP</strong></p><p>在接下来需要使用到真实IP的地方，我都会使用以上对应的IP来代替。</p><p>SS是shadowsocks的简称，以下用SS来代替（防止和谐）。</p><h4><span id="搭建tinyvpn">搭建tinyvpn</span></h4><p>首先在国外我们需要作为SS服务端和国内转发端的服务器之间搭建tinyfecyvpn。也就是上面代替IP中的2.2.2.2和3.3.3.3之间搭建。</p><p><a href="https://github.com/wangyu-/tinyfecVPN" target="_blank" rel="noopener">tinfecyvpn  Github地址</a></p><p>从上面给的Github里下载tinyfecyvpn并解压：</p><p><img src="/2019/09/29/tinyvpn、tinymapper、ss科学上网/download_vpn.png" alt></p><p>这里面是有好多个版本的，这时候要看你要使用的机器是什么版本，我的机器是linux，系统是Centos7。可以通过在命令行里执行：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]# uname -m</span><br><span class="line">x86_64</span><br></pre></td></tr></table></figure><p>返回：x86_64。所以只使用上图中的tinyvpn_amd64这个文件就可以了。（这里我为了展示，所以使用windows的截图，软件使用过程中都是在centos7上面配置）</p><p><img src="/2019/09/29/tinyvpn、tinymapper、ss科学上网/vpn1.png" alt></p><p>如上图，我们先配置服务端，将”tinyvpn_amd64”拷贝到服务器上，查看一下默认是没有执行权限的，所以”chmod +x”一下，然后按照官方的文档运行。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]# chmod +x tinyvpn_amd64</span><br><span class="line">[root@localhost ~]# ./tinyvpn_amd64 -s -l0.0.0.0:4096 -f20:10 -k &quot;passwd&quot; --sub-net 10.22.22.0</span><br></pre></td></tr></table></figure><p>注意：这里我们是将这台作为服务端，也就是3.3.3.3这台。而tinyvpn服务端和客户端的命令参数是不一样的，下面放上官方给出的例子来进行对比。</p><table><thead><tr><th>服务端</th><th>./tinyvpn -s -l0.0.0.0:4096 -f20:10 -k “passwd” –sub-net 10.22.22.0</th></tr></thead><tbody><tr><td>客户端</td><td>./tinyvpn -c -r44.55.66.77:4096 -f20:10 -k “passwd” –sub-net 10.22.22.0</td></tr></tbody></table><h5><span id="服务端">服务端</span></h5><p>其中参数选项和参数之间是可以不存在空格的，就比如其中的”-l0.0.0.0:4096”，但是你写成”-l 0.0.0.0:4096”也是可以的。</p><table><thead><tr><th>-l0.0.0.0:4096</th><th>因为是服务端，0.0.0.0代表允许所有IP访问。端口号自定义</th></tr></thead><tbody><tr><td>-f20:10</td><td>表示对每20个原始数据发送10个冗余包。后期通过调整这个值来达到最佳效果</td></tr><tr><td>-k “passwd”</td><td>指定一个字符串，开启简单的异或加密</td></tr><tr><td>–sub-net 10.22.22.0</td><td>指定VPN的子网，格式为xxx.xxx.xxx.0</td></tr></tbody></table><p>注: 对于–sub-net 10.10.10.0, server的IP会被设置成10.10.10.1,client的IP会被设置成10.10.10.2 。按照我的理解，这里就相当于两台机器组成了一个内网。</p><p>从下图中我们看出端口和IP情况：</p><p><img src="/2019/09/29/tinyvpn、tinymapper、ss科学上网/vpn2.png" alt></p><h5><span id="客户端">客户端</span></h5><p><img src="/2019/09/29/tinyvpn、tinymapper、ss科学上网/vpn3.png" alt></p><p>客户端基本和服务端没有太大区别，记得参数改一下就好，我这里就没截图，使用一下以前的截图。</p><p>注意”-c -r IP”这里的IP要填你服务端的公网IP。比如我们的例子IP，那么这里就是要填”3.3.3.3”。</p><h5><span id="效果测试">效果测试</span></h5><p>我们先关闭tinyvpn。ping一下看看网络情况（这里直接ping服务端的公网IP，比如例子IP：3.3.3.3）：</p><p><img src="/2019/09/29/tinyvpn、tinymapper、ss科学上网/vpn4.png" alt></p><p>可以看到，因为是在国外，掉包率还是很高的。这样情况下操作服务器或者传输文件基本用起来是很痛苦。</p><p>然后再打开tinyvpn，ping一下看看网络情况（这里ping我们tinyvpn配置好的内网IP，也就是10.10.10.x。这里分清自己的IP是多少，然后ping另外一台IP测试就可以了。不要傻傻的ping自己的IP，那肯定是很稳定的…）</p><p><img src="/2019/09/29/tinyvpn、tinymapper、ss科学上网/vpn5.png" alt></p><p>我们看到效果好了不少。但还差一些。这时候就要调整上面的”-f20:10”参数了。根据实际情况来调整，注意x:y，x+y的值不能超过255即可。（早中晚的网络情况可能都稍有不同，然后你国外服务器的地理位置也有可能会影响）</p><p>我再调整参数的值（这个值意义不是特别清楚，网络方面的知识，官方也是一笔带过，总之多尝试吧），我这里是直接改到”100:150”，看下效果：</p><p><img src="/2019/09/29/tinyvpn、tinymapper、ss科学上网/vpn6.png" alt></p><p>基本不会掉包了。那么tinyvpn的搭建就算完成了。</p><p>注：</p><p>把程序后台运行输出到日志，例如通过”nohup”和”&amp;”：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]# /tinyvpn/tinyvpn_amd64 -s -l0.0.0.0:4096 -f100:150 -k tb123 --sub-net 10.22.22.0 &gt;&gt;/root/tinyvpn_output.log 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure><p>还有如果是云主机，记得在控制台开放安全组策略，也就是开放我们需要访问的端口</p><table><thead><tr><th>类型</th><th>测试端口开放情况命令</th></tr></thead><tbody><tr><td>TCP</td><td>telnet 1.1.1.1 4096</td></tr><tr><td>UDP</td><td>nc -vu 1.1.1.1 4096</td></tr></tbody></table><h4><span id="搭建tinyportmapper">搭建tinyPortmapper</span></h4><p>VPN隧道已经搭建完成，接下来就需要为转发服务器配置转发流量和端口了。（也就是在例子IP：2.2.2.2这台上完成）</p><p><a href="https://github.com/wangyu-/tinyPortMapper" target="_blank" rel="noopener">tinyPortmapper Github地址</a></p><p>一样的我们可以看到有几个版本，选择我们需要的版本上传到服务器就可以了：</p><p><img src="/2019/09/29/tinyvpn、tinymapper、ss科学上网/vpn7.png" alt></p><p>按照官方的命令，执行命令:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]#/usr/software/tinymapper_amd64 -l0.0.0.0:2333 -r10.22.22.1:18092 -t -u</span><br></pre></td></tr></table></figure><p>参数 -t 和 -u 代表 TCP和UDP流量都转发，具体可以查看最上面的官方说明。</p><p><img src="/2019/09/29/tinyvpn、tinymapper、ss科学上网/vpn8.png" alt></p><table><thead><tr><th>-l0.0.0.0:2333</th><th>0.0.0.0代表允许所有IP访问。端口号自定义，不存在冲突即可</th></tr></thead><tbody><tr><td>-r10.22.22.1:18092</td><td>10.22.22.1就是我们服务端的VPN IP。我们这台客户端的IP是10.22.22.2</td></tr></tbody></table><p>18092是我们指定服务端接收的端口号，程序正常启动后，可以在服务端通过”netstat -tunlp | grep 18092”查看。</p><p>我上面的输出是因为我已经用ss来连接了。如果你没有这么多输出，不用管，程序运行没有报错就好。扔到后台去运行，我们下面去配置ss。</p><h4><span id="搭建shadowsocks">搭建shadowsocks</span></h4><h5><span id="服务端">服务端</span></h5><p>ss我们需要一个客户端，一个服务端。客户端我们用自己电脑就好，总归是要上浏览器的。所以我们去官网下载windows版本的就好。<a href="https://github.com/shadowsocks/shadowsocks-windows" target="_blank" rel="noopener">shadowsocks-windows版本Github地址</a></p><p>不急着先配置windows的连接。打开ss的服务端，比如我们例子IP中的3.3.3.3这台。</p><p>因为这台是centos7的，我们直接命令行安装，需要安装pip（python提供的一种类似yum的仓库，解决各种依赖问题，然后再通过pip安装）</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]#yum install python-setuptools &amp;&amp; easy_install pip</span><br><span class="line">[root@localhost ~]#pip install shadowsocks</span><br><span class="line"><span class="meta">#</span>安装完查看一下是否成功</span><br><span class="line">[root@localhost ~]#whereis shadowsocks</span><br><span class="line">shadowsocks: /etc/shadowsocks.json_old /etc/shadowsocks.json~ /etc/shadowsocks.json /usr/local/shadowsocks</span><br></pre></td></tr></table></figure><p>然后编辑”<strong>/etc/shadowsocks.json</strong>“，这个是ss最重要的文件，如果没有，就新建一个名字相同的文件。下面是我的配置：</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    "server":"0.0.0.0",#表示所有IP可访问</span><br><span class="line">    "server_ipv6":"[::]",</span><br><span class="line">    "server_port":18092,#这里要记得和我们上面tinyPortmapper配置转发的端口保持一致</span><br><span class="line">    "local_address":"127.0.0.1",</span><br><span class="line">    "local_port":1092,</span><br><span class="line">    "password":"123456",#连接的密码</span><br><span class="line">    "timeout":120,</span><br><span class="line">    "method":"aes-256-cfb",#加密方式</span><br><span class="line">    "protocol":"origin",</span><br><span class="line">    "protocol_param":"",</span><br><span class="line">    "obfs":"plain",</span><br><span class="line">    "obfs_param":"",</span><br><span class="line">    "redirect":"",</span><br><span class="line">    "dns_ipv6":false,</span><br><span class="line">    "fast_open":false,</span><br><span class="line">    "workers":1</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>配置好后执行运行命令:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]#ssserver -c /etc/shadowsocks.json -d start</span><br><span class="line"><span class="meta">#</span>停止命令：</span><br><span class="line">[root@localhost ~]#ssserver -c /etc/shadowsocks.json -d stop</span><br></pre></td></tr></table></figure><p>如果报错，就好好检查一下”shadowsocks.json”文件。</p><h5><span id="客户端">客户端</span></h5><p><img src="/2019/09/29/tinyvpn、tinymapper、ss科学上网/ss1.png" alt></p><p>客户端安装好后，勾选启用代理，选择PAC模式。</p><p>然后再点击”系统代理模式”下方的”服务器”，编辑服务器。</p><p><img src="/2019/09/29/tinyvpn、tinymapper、ss科学上网/ss2.png" alt></p><p>这里填入我们转发服务器（例子IP中的2.2.2.2）的公网IP和tinyPortmapper设置的转发端口：</p><p><img src="/2019/09/29/tinyvpn、tinymapper、ss科学上网/ss3.png" alt></p><p>加密方式和密码，就是我们在ss服务器（例子IP中的3.3.3.3）上配置的”<strong>shadowsocks.json</strong>“文件。</p><p>到这里你应该大致明白了这一套流程下来，我们这么做的意义和方式了。</p><p>接下来配置好后就试试看能不能访问外面的世界吧！</p><h5><span id="测试效果">测试效果</span></h5><p><img src="/2019/09/29/tinyvpn、tinymapper、ss科学上网/goog.png" alt></p><p><u>外面的世界很精彩，外面的世界很无奈。</u></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;外面的世界很精彩，外面的世界很无奈。&lt;/p&gt;
    
    </summary>
    
      <category term="科学上网" scheme="https://newpants_top/categories/%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91/"/>
    
    
      <category term="tinyfecvpn" scheme="https://newpants_top/tags/tinyfecvpn/"/>
    
      <category term="tinyPortmapper" scheme="https://newpants_top/tags/tinyPortmapper/"/>
    
      <category term="shadowsocks" scheme="https://newpants_top/tags/shadowsocks/"/>
    
  </entry>
  
  <entry>
    <title>利用zabbix远程执行python脚本</title>
    <link href="https://newpants_top/2019/09/27/%E5%88%A9%E7%94%A8zabbix%E8%BF%9C%E7%A8%8B%E6%89%A7%E8%A1%8Cpython%E8%84%9A%E6%9C%AC/"/>
    <id>https://newpants_top/2019/09/27/利用zabbix远程执行python脚本/</id>
    <published>2019-09-27T02:09:27.000Z</published>
    <updated>2019-09-30T03:52:46.716Z</updated>
    
    <content type="html"><![CDATA[<p>本文通过zabbix与python结合，实现对服务器上日志自动化的清理。</p><a id="more"></a><!-- toc --><ul><li><a href="#开启zabbix_agent端远程命令权限">开启zabbix_agent端远程命令权限</a></li><li><a href="#zabbix_get验证连通性">zabbix_get验证连通性</a></li><li><a href="#编写python脚本">编写python脚本</a></li><li><a href="#为触发器添加动作">为触发器添加动作</a></li><li><a href="#效果图">效果图</a></li></ul><!-- tocstop --><p>服务器其实最基本的问题就是容量的问题，秉承着，能不花钱就不花钱的理念。基本像web服务器，这种基本不占什么容量的服务来说，服务器的容量都很小。所以基本云主机都是买一个容量最小最便宜的放在线上。</p><p>不过一段时间下来，web产生的大量日志就是一个头疼的问题了。一共就那么几十G，再放上web程序，日志没几天就占满了磁盘空间。这些日志很多都不是那么重要的，基本是记录操作记录的信息，所以时间比较久远的日志参考意义就不大了，而且假如真的需要保存这些信息的话，其实已经可以通过elk采集到我们需要保存的服务器上进行备份。</p><h4><span id="开启zabbix_agent端远程命令权限">开启zabbix_agent端远程命令权限</span></h4><p>首先第一步就是要先开启agent端允许server端远程执行命令的权限。找到配置文件，每个人配置文件名称可能不通。我这里是windows主机，名称为：“zabbix_agentd.win.conf”。找到如下图这行：</p><p><img src="/2019/09/27/利用zabbix远程执行python脚本/agent_remote.png" alt></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">#默认0代表关闭，1为启用</span><br><span class="line">EnableRemoteCommands=1</span><br></pre></td></tr></table></figure><p>设置保存后，需要<strong>重启</strong>对应的agent端的zabbix服务才会生效。</p><h4><span id="zabbix_get验证连通性">zabbix_get验证连通性</span></h4><p>zabbix_get是zabbix官方提供的一个工具。将这个工具安装在server端，即可实现对agent端的数据采集。通过这个工具可以测试我们的配置是否有问题。<a href="https://www.zabbix.com/documentation/3.0/manpages/zabbix_get" target="_blank" rel="noopener">zabbix_get官方文档</a></p><p>如果没有安装该工具，通过yum或者下载镜像方式安装，yum安装：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install -y zabbix-get.x86_64</span><br></pre></td></tr></table></figure><p>安装完成后测试是否正常：</p><p><img src="/2019/09/27/利用zabbix远程执行python脚本/zabbix_get_v.png" alt></p><p>zabbix_get使用方法（直接引用官网文档，点击上面那个链接一样可以看到）：</p><p><strong>zabbix_get -s</strong> <em>host-name-or-IP</em> [<strong>-p</strong> <em>port-number<em>] [*</em>-I** <em>IP-address</em>] <strong>-k</strong> *item-key</em><br><strong>zabbix_get -s</strong> <em>host-name-or-IP</em> [<strong>-p</strong> <em>port-number<em>] [*</em>-I** <em>IP-address</em>] <strong>–tls-connect</strong> <strong>cert</strong> <strong>–tls-ca-file</strong> *CA-file</em> [<strong>–tls-crl-file</strong> <em>CRL-file<em>] [*</em>–tls-agent-cert-issuer** <em>cert-issuer</em>] [<strong>–tls-agent-cert-subject</strong> <em>cert-subject</em>] <strong>–tls-cert-file</strong> *cert-file</em> <strong>–tls-key-file</strong> <em>key-file</em> <strong>-k</strong> <em>item-key</em><br><strong>zabbix_get -s</strong> <em>host-name-or-IP</em> [<strong>-p</strong> <em>port-number<em>] [*</em>-I** <em>IP-address</em>] <strong>–tls-connect</strong> <strong>psk</strong> <strong>–tls-psk-identity</strong> *PSK-identity</em> <strong>–tls-psk-file*</strong>PSK-file* <strong>-k</strong> <em>item-key</em><br><strong>zabbix_get -h</strong><br><strong>zabbix_get -V</strong>  </p><p>我们刚才已经开启了agent端的远程执行功能，现在直接在server端测试一下：</p><p><img src="/2019/09/27/利用zabbix远程执行python脚本/zabbix_get.png" alt></p><p>这是一个获取所有cpu平均1分钟负载值的命令。看到我们已经返回了结果，证明连通正常，可以远程执行命令。</p><h4><span id="编写python脚本">编写python脚本</span></h4><p>完成上面两个步骤后，zabbix方面可以先放一放，因为这个才是我们最重要的步骤，编写python脚本。话不多说，直接先上脚本：</p><p><strong>注：本脚本在windows主机，python3的环境下运行。若为python2，脚本中的一些模块可能会运行报错，建议先测试一下正常后再使用。</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># encoding:utf-8</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">功能:</span></span><br><span class="line"><span class="string">1）判断文件/文件夹最后修改日期</span></span><br><span class="line"><span class="string">2）按照if语句删除（天数作为条件）</span></span><br><span class="line"><span class="string">说明：此脚本由内网40.17zabbix服务器触发触发器执行动作，远程执行</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">import</span> logging</span><br><span class="line"><span class="keyword">import</span> shutil</span><br><span class="line">logging.basicConfig(level=logging.INFO,</span><br><span class="line">                    filename=<span class="string">"C:/python/python_scripts/del_dir.log"</span> </span><br><span class="line">                    <span class="comment">#有了filename参数就不会直接输出显示到控制台，而是直接写入文件</span></span><br><span class="line">                    )</span><br><span class="line"></span><br><span class="line"><span class="comment">#定义删除文件夹的函数 del_directory(),参数my_path</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">del_directory</span><span class="params">(my_path)</span>:</span></span><br><span class="line"><span class="comment">#定义日期时间格式</span></span><br><span class="line">format=<span class="string">'%Y-%m-%d'</span></span><br><span class="line"><span class="comment">#获取当前的时间转换成字符串格式</span></span><br><span class="line">current_time=str(time.strftime(format,time.localtime()))</span><br><span class="line"><span class="comment">#删除时间，方便日志查看</span></span><br><span class="line">del_time=time.strftime(<span class="string">"%Y-%m-%d %H:%M:%S"</span>,time.localtime())</span><br><span class="line"><span class="comment">#遍历目标路径下的文件夹</span></span><br><span class="line"><span class="keyword">for</span> d_f_name <span class="keyword">in</span> os.listdir(my_path):</span><br><span class="line"><span class="comment">#获取文件绝对路径</span></span><br><span class="line">full_dirct_path=os.path.join(my_path,d_f_name)</span><br><span class="line"><span class="comment">#获取文件最后修改时间</span></span><br><span class="line">modifiedTime=time.localtime(os.stat(full_dirct_path).st_mtime)</span><br><span class="line">mTime=str(time.strftime(format,modifiedTime))</span><br><span class="line"><span class="comment">#判断修改日期距离今天为止的间隔时间（天）</span></span><br><span class="line">interval_time=datetime.datetime.strptime(current_time,format) - datetime.datetime.strptime(mTime,format)</span><br><span class="line"><span class="comment">#判断修改日期距离今天是否大于x天</span></span><br><span class="line"><span class="keyword">if</span> interval_time.days &gt; <span class="number">5</span>:</span><br><span class="line"><span class="comment">#判断是否为文件夹</span></span><br><span class="line"><span class="keyword">if</span> os.path.isdir(full_dirct_path):</span><br><span class="line"><span class="comment">#删除非空文件夹 注：直接删除整个非空文件夹</span></span><br><span class="line">shutil.rmtree(full_dirct_path)</span><br><span class="line">logging.info(del_time+<span class="string">" 已成功删除[目录]: "</span>+full_dirct_path)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line"><span class="comment">#删除文件</span></span><br><span class="line">os.remove(full_dirct_path)</span><br><span class="line">logging.info(del_time+<span class="string">" 已成功删除_文件_: "</span>+full_dirct_path)</span><br><span class="line"></span><br><span class="line">del_directory(<span class="string">'D:\\wwwlog\\commctrl\\dir1\\'</span>)</span><br><span class="line">del_directory(<span class="string">'D:\\wwwlog\\dir2\\'</span>)</span><br></pre></td></tr></table></figure><p>基本上面每一步的作用，我都有在注释里面标注了。主要是运用几个模块，定义了一个删除文件和目录的函数。最后再实例化。</p><p>唯一需要注意的是最下面实例化，添加路径的时候，一定要写对绝对路径，不要删错文件就好。</p><p>编写完毕测试正常后，我们把脚本放在一个目录下，我这里放在“C:/python/python_scripts/del_dir_20.py”</p><h4><span id="为触发器添加动作">为触发器添加动作</span></h4><p>首先要在zabbix web的界面建好我们的触发器（我这边已经建好了，是一个D盘容量小于百分之5就触发的报警）：</p><p><img src="/2019/09/27/利用zabbix远程执行python脚本/triggers.png" alt></p><p>触发器好了以后，我们为触发器添加一个动作，configuration-&gt;Actions-&gt;Event source(选择Triggers)-&gt;Create action。因为我们想要触发触发器后执行脚本，所以创建动作时，选择Triggers。</p><p><img src="/2019/09/27/利用zabbix远程执行python脚本/create_action.png" alt></p><p>填入名称，增加触发器：</p><p><img src="/2019/09/27/利用zabbix远程执行python脚本/create1.png" alt></p><p>选择对应的触发器：</p><p><img src="/2019/09/27/利用zabbix远程执行python脚本/create2.png" alt></p><p>选择完一定要记得点击“add”，如果没有“add”，触发器是没有添加上去的：</p><p><img src="/2019/09/27/利用zabbix远程执行python脚本/create3.png" alt></p><p>最后的状态：</p><p><img src="/2019/09/27/利用zabbix远程执行python脚本/create4.png" alt></p><p>下面也是比较关键的一步，添加我们的动作内容，点击Action旁边的Operations:</p><p><img src="/2019/09/27/利用zabbix远程执行python脚本/create5.png" alt></p><p>每步的步骤的作用都有详细说明了，单机图片可放大查看。</p><p>Target list的部分忘记标注了，这里记得新建一个把我们要执行脚本的主机添加进来，选择host-&gt;选择主机：</p><p><img src="/2019/09/27/利用zabbix远程执行python脚本/create6.png" alt></p><hr><h4><span id="效果图">效果图</span></h4><p>以上一切做好后，就可以静静的等待触发器被触发，自动远程执行我们的python脚本了。</p><p>如果报警触发，我们可以在Reports-&gt;Action log中查看我们的动作详情，我们看到触发器触发后，自动就恢复了，不需要人工参与：</p><p><img src="/2019/09/27/利用zabbix远程执行python脚本/report1.png" alt></p><p>如果想看什么时间都删除了哪些文件，可以看看在目标服务器上，我们利用python输出的日志内容：</p><p><img src="/2019/09/27/利用zabbix远程执行python脚本/del_log.png" alt></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文通过zabbix与python结合，实现对服务器上日志自动化的清理。&lt;/p&gt;
    
    </summary>
    
      <category term="zabbix" scheme="https://newpants_top/categories/zabbix/"/>
    
    
      <category term="zabbix" scheme="https://newpants_top/tags/zabbix/"/>
    
      <category term="python" scheme="https://newpants_top/tags/python/"/>
    
      <category term="自动化运维" scheme="https://newpants_top/tags/%E8%87%AA%E5%8A%A8%E5%8C%96%E8%BF%90%E7%BB%B4/"/>
    
  </entry>
  
  <entry>
    <title>利用性能分析工具sar、iotop对linux服务器高负载问题排查</title>
    <link href="https://newpants_top/2019/09/25/%E5%88%A9%E7%94%A8%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E5%B7%A5%E5%85%B7sar%E3%80%81iotop%E5%AF%B9linux%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%AB%98%E8%B4%9F%E8%BD%BD%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5/"/>
    <id>https://newpants_top/2019/09/25/利用性能分析工具sar、iotop对linux服务器高负载问题排查/</id>
    <published>2019-09-25T08:03:38.000Z</published>
    <updated>2019-09-30T03:53:18.671Z</updated>
    
    <content type="html"><![CDATA[<p>sar、iotop的使用。</p><a id="more"></a><!-- toc --><ul><li><a href="#1sar的使用">1.sar的使用</a><ul><li><a href="#11-iostat">1.1 iostat</a></li></ul></li><li><a href="#2iotop">2.iotop</a></li></ul><!-- tocstop --><p>工作中我们有时候会遇到一些服务器性能上的问题。比如：内存不足、io等待时间过长、cpu使用率高等等等等。其实原本这些东西在我们服务器上线之前就应该经过压力测验了，所以不管是云服务器还是实体机，最开始的配置其实还是可以满足实际业务需求的。</p><p>但是随着机器年限的提升，为了节约成本或者一些新的需求，又或者是长时间运行，一些问题还是会暴露出来。</p><p>这几天工作中同事经常会和我说一台linux的服务器cpu负载偶尔会变得很高。</p><p>这里说下这台服务器的配置：</p><table><thead><tr><th>说明</th><th>详细</th></tr></thead><tbody><tr><td>系统</td><td>centos7</td></tr><tr><td>性质</td><td>腾讯云主机</td></tr><tr><td>内存</td><td>4G</td></tr><tr><td>物理CPU个数</td><td>1</td></tr><tr><td>CPU核数</td><td>2</td></tr><tr><td>逻辑CPU个数（即物理CPU个数×核数）</td><td>2</td></tr></tbody></table><p>因为是用作web网站的，基本不太需要很大的资源，这样配置的主机已经是够了的。</p><p>我们先从zabbix报警的图形中看一下cpu负载的状况：</p><p><img src="/2019/09/25/利用性能分析工具sar、iotop对linux服务器高负载问题排查/cpu_load.png" alt></p><p>从上图可以看出，1分钟的平均负载已经达到了5，5分钟的平均负载则达到了2.0多，15分钟的负载就相对正常。如果这样看还好，只是短暂的负载飙升。这个值的正常大小主要取决于你的CPU逻辑个数。即，不超过2以上系统就基本没啥问题正常运行。一旦超过这个最大值以后，其实你的系统会变得非常的卡，就好比我们用windows时，鼠标直接都没办法移动的这种情况。这种情况下，web服务器基本属于宕机状态，是没办法为客户提供服务的。虽说偶尔才会出现，而且每次的影响也就是十几个连接超时。但我们遇到问题，还是要先排查一下，排查的过程中还是可以学习到非常多的知识的。</p><p>虽然linux自带的top命令一样可以查看关于各类报告的数值，但是比较局限，一是不能按时间戳查看（比如想看昨天的，或者统计数据），二是也无法对数据进行细化查看（查看到底是哪个进程，或者占用比例）。</p><p>所以我们使用以下两种软件来达到我们的目的：sar和iotop</p><h4><span id="1sar的使用">1.sar的使用</span></h4><p>sar，全称：”System Activity Reporter” ，直译就是：系统活动情况报告。例如：文件读写情况报告、CPU效率报告、内存使用情况报告、磁盘I/O报告等。</p><p>安装我们使用yum方式安装，保证镜像源可用后直接输入</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@padim ~]#yum -y install sysstat</span><br></pre></td></tr></table></figure><p>开箱即用，先输入”sar –help”查看一下是否安装正常，并且查看可用的参数，如下图：</p><p><img src="/2019/09/25/利用性能分析工具sar、iotop对linux服务器高负载问题排查/sar_help.png" alt></p><p>以下列出一些常用的参数详解：</p><table><thead><tr><th>参数选项</th><th>参数说明</th></tr></thead><tbody><tr><td>-A</td><td>所有报告的总和</td></tr><tr><td>-u</td><td>输出<a href="http://lovesoo.org/tag/cpu" target="_blank" rel="noopener">CPU</a>使用情况的统计信息</td></tr><tr><td>-v</td><td>输出inode、文件和其他内核表的统计信息</td></tr><tr><td>-d</td><td>输出每一个块设备的活动信息</td></tr><tr><td>-r</td><td>输出<a href="http://lovesoo.org/tag/内存" target="_blank" rel="noopener">内存</a>和交换空间的统计信息</td></tr><tr><td>-b</td><td>显示<a href="http://lovesoo.org/tag/io" target="_blank" rel="noopener">I/O</a>和传送速率的统计信息</td></tr><tr><td>-a</td><td>文件读写情况</td></tr><tr><td>-c</td><td>输出进程统计信息，每秒创建的进程数</td></tr><tr><td>-R</td><td>输出内存页面的统计信息</td></tr><tr><td>-y</td><td>终端设备活动情况</td></tr><tr><td>-w</td><td>输出系统交换活动信息</td></tr></tbody></table><p>因为我们想看CPU相关的信息，直接输入：”sar -u”，找到我们监控对应的上午08:30分左右，如下图：</p><p><img src="/2019/09/25/利用性能分析工具sar、iotop对linux服务器高负载问题排查/sar_u.png" alt></p><p>太好了，果然08:30跟其他的凡夫俗子不一样啊。很突出的彰显着自己的王霸之气。可以看到%iowait比其他的高出非常多。已经达到了百分之10+。</p><p>说实话我对iowait理解也不是特别透彻，比较浅显的理解就是，系统在做io，进程在等到io完成。所以此时进程是不工作的，如果iowait值很大，那么进程的等待时间就越长，所以进程等待这么长的时间，换谁也坐不住了，生命就这样流逝啊。</p><p>知道了可能是iowait的问题后，那么可以查看是哪些进程在做IO导致系统在等待。</p><h5><span id="11-iostat">1.1 iostat</span></h5><p>sysstat包下还有一个iostat的软件，iostat是专门来查看io相关信息的软件，有如下几个参数：</p><table><thead><tr><th>参数选项</th><th>参数说明</th></tr></thead><tbody><tr><td>-c</td><td>仅显示CPU使用情况</td></tr><tr><td>-d</td><td>仅显示设备利用率</td></tr><tr><td>-k</td><td>显示状态以千字节每秒为单位，而不适用块每秒</td></tr><tr><td>-m</td><td>显示状态以兆字节每秒为单位</td></tr><tr><td>-p</td><td>仅显示块设备和所有被使用的其他分区的状态</td></tr><tr><td>-t</td><td>显示每个报告产生时的时间</td></tr><tr><td>-V</td><td>显示版号并退出</td></tr><tr><td>-x</td><td>显示扩展状态</td></tr></tbody></table><p>我们使用一个”-t”的参数看下效果，如下图：</p><p><img src="/2019/09/25/利用性能分析工具sar、iotop对linux服务器高负载问题排查/iostat_t.png" alt></p><p>各属性说明：</p><table><thead><tr><th>属性</th><th>属性说明</th><th>备注</th></tr></thead><tbody><tr><td>%user</td><td>CPU处在用户模式下的时间百分比</td><td></td></tr><tr><td>%nice</td><td>CPU处于带NICE值的用户模式下的时间百分比</td><td></td></tr><tr><td>%system</td><td>CPU处于系统模式下的时间百分比</td><td></td></tr><tr><td>%iowait</td><td>CPU等待输入输出完成时间的百分比</td><td>如果%iowait值过高，表示硬盘存在I/O瓶颈</td></tr><tr><td>%steal</td><td>管理程序维护另一个虚拟处理器时，虚拟CPU的无意识等待时间百分比</td><td></td></tr><tr><td>%idle</td><td>CPU空闲时间百分比</td><td><strong>1）</strong>如果%idle值持续低于10，表明CPU处理能力相对较低，系统中最需要解决的资源是CPU。<strong>2）</strong>如果%idle值高，表示CPU较空闲。<strong>3）</strong>如果%idle值高但系统响应慢时，可能是CPU等待分配内存，应加大内存容量</td></tr><tr><td>tps</td><td>该设备每秒的传输次数</td><td></td></tr><tr><td>kB_read/s</td><td>每秒从设备读取的数据量</td><td></td></tr><tr><td>kB_wrtn/s</td><td>每秒从设备写入的数据量</td><td></td></tr><tr><td>kB_read</td><td>读取的数据总量</td><td></td></tr><tr><td>kB_wrtn</td><td>写入的数据总量</td><td></td></tr></tbody></table><p>如果你对top很熟悉，那么上面的输出内容基本也是看得懂的。基本可以看出，是vda这块盘的读写量很大。但是不能细化到是哪个进程。这时候就要用到下面所说的”iotop”了。</p><h4><span id="2iotop">2.iotop</span></h4><p>iotop和top名字很像，也是可以动态监视并查看系统状态的工具，是用python来编写的。</p><p>安装iotop我们也是使用yum方式安装：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@padim ~]#yum -y install iotop</span><br></pre></td></tr></table></figure><p>iotop参数说明：</p><table><thead><tr><th>参数选项</th><th>参数说明</th></tr></thead><tbody><tr><td>–version</td><td>表示显示版本号</td></tr><tr><td>-h</td><td>–help 表示显示帮助信息</td></tr><tr><td>-o，–only</td><td>表示显示进程或者线程实际上正在做的I/O，而不是全部的，可以随时切换按o</td></tr><tr><td>-b，–batch</td><td>表示运行在非交互式的模式</td></tr><tr><td>-n，NUM, –iter=NUM</td><td>表示在非交互式模式下，设置显示的次数</td></tr><tr><td>-d，SEC, –delay=SEC</td><td>表示设置显示的间隔秒数</td></tr><tr><td>-p，PID, –pid=PID</td><td>表示显示指定PID的信息</td></tr><tr><td>-u，USER, –user=USER</td><td>表示显示指定用户的进程信息</td></tr><tr><td>-P，–processes</td><td>表示只显示进程信息</td></tr><tr><td>-a，–accumulated</td><td>表示显示从iotop启动后每个线程完成了的IO总数</td></tr><tr><td>-k，–kilobytes</td><td>表示以千字节显示</td></tr><tr><td>-t，–time</td><td>表示在每一行前添加一个当前的时间</td></tr></tbody></table><p>我们输入”iotop -oPa”来查看当前服务器上运行的程序的I/O情况：</p><p><img src="/2019/09/25/利用性能分析工具sar、iotop对linux服务器高负载问题排查/iotop.png" alt></p><p>可以通过键盘左右键选则，选中想要排序的项目对其进行排序查看。这里我选中磁盘的写操作排序。</p><p>可以看到第一行是一个名为”systemd-journald”的命令。该命令是linux系统自带的系统服务。第二行是www用户运行的一个node脚本。</p><p>因为我们之前使用过命令iostat查看过%user和%system的情况。%user占用的比例是比%system高的。所以非常有可能的是当时占用cpu资源的是user用户执行的程序，如下图（之前iostat查看到的信息）：</p><p><img src="/2019/09/25/利用性能分析工具sar、iotop对linux服务器高负载问题排查/iostat_t2.png" alt></p><p>所以到这里我们猜测，可能是node这个脚本，存在着较大的读写操作，导致服务器iowait变长，从而增加了CPU的负载值。</p><p>那其实到底是不是…还需要来看看这个js脚本。这时候需要呼叫开发小哥了。然后其他的进程也去网上百度一下，搜搜看哪里是不是需要优化的地方。改完以后再去观察监控，看是不是还会出现之前的问题。</p><p>不过说到底不管是不是，我们至少学会了如何使用sar和iotop去查找问题的根源。在这方面自己也是还算个新手，如果有不对的地方，希望大家指出。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;sar、iotop的使用。&lt;/p&gt;
    
    </summary>
    
      <category term="linux" scheme="https://newpants_top/categories/linux/"/>
    
    
      <category term="sar" scheme="https://newpants_top/tags/sar/"/>
    
      <category term="iotop" scheme="https://newpants_top/tags/iotop/"/>
    
  </entry>
  
  <entry>
    <title>还能欢笑如此吗</title>
    <link href="https://newpants_top/2019/09/21/%E8%BF%98%E8%83%BD%E6%AC%A2%E7%AC%91%E5%A6%82%E6%AD%A4%E5%90%97/"/>
    <id>https://newpants_top/2019/09/21/还能欢笑如此吗/</id>
    <published>2019-09-21T14:14:30.000Z</published>
    <updated>2019-09-25T07:37:22.020Z</updated>
    
    <content type="html"><![CDATA[<div id="hbe-security">  <div class="hbe-input-container">  <input type="password" class="hbe-form-control" id="pass" placeholder="抱歉，此文暂时不对外开放.">    <label for="pass">抱歉，此文暂时不对外开放.</label>    <div class="bottom-line"></div>  </div></div><div id="decryptionError" style="display:none;">Incorrect Password!</div><div id="noContentError" style="display:none;">No content to display!</div><div id="encrypt-blog" style="display:none">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</div><script src="/lib/crypto-js.js"></script><script src="/lib/blog-encrypt.js"></script><link href="/css/blog-encrypt.css" rel="stylesheet" type="text/css">]]></content>
    
    <summary type="html">
    
      抱歉，此文暂时不对外开放.&lt;/br&gt;
    
    </summary>
    
    
      <category term="Ref:rain" scheme="https://newpants_top/tags/Ref-rain/"/>
    
  </entry>
  
  <entry>
    <title>多端更新hexo博客</title>
    <link href="https://newpants_top/2019/09/21/%E5%A4%9A%E7%AB%AF%E6%9B%B4%E6%96%B0hexo%E5%8D%9A%E5%AE%A2/"/>
    <id>https://newpants_top/2019/09/21/多端更新hexo博客/</id>
    <published>2019-09-21T03:49:11.000Z</published>
    <updated>2019-09-30T03:58:22.420Z</updated>
    
    <content type="html"><![CDATA[<p>正义的键盘侠，不能对这个悲惨的世界坐视不管！</p><a id="more"></a><!-- toc --><ul><li><a href="#1把本地hexo代码上传到github">1.把本地hexo代码上传到github</a><ul><li><a href="#11-git文件夹的删除">1.1 .git文件夹的删除</a></li><li><a href="#12上传需要的文件夹">1.2上传需要的文件夹</a><ul><li><a href="#121添加远程仓库">1.2.1添加远程仓库</a></li><li><a href="#122上传文件夹到仓库">1.2.2上传文件夹到仓库</a></li></ul></li></ul></li><li><a href="#2clone仓库代码到新机器上继续使用">2.clone仓库代码到新机器上继续使用</a></li></ul><!-- tocstop --><p>在公司的电脑上部署了hexo，想要家里也可以更新。就想着把整个文件夹上传到github或者coding上面，再clone下来更新。其中还是遇到蛮多坑的。主要还是hexo框架的问题。还有git这个工具其实单独拿出来就可以写好几篇教程，本文对git部分稍微介绍，只列出此过程中使用到的git命令。</p><h4><span id="1把本地hexo代码上传到github">1.把本地hexo代码上传到github</span></h4><p>首先先把本地正常运行的hexo框架上传到github上面去。（原本想上传到coding，但是不知道coding抽什么风，直接不通。难怪有时候访问网站时都超时（网站访问的源是coding的仓库），国内这个做的还是稍微差点）</p><p>这里有几个需要注意的地方：</p><p>1）git文件夹的问题</p><p>2）上传的文件夹中需要剔除的部分，通过.gitignore文件</p><p>3）已经下载过的第三方插件问题（在最后面clone到本地时再说）</p><p>那么接下来一个个来说。</p><h5><span id="11-git文件夹的删除">1.1 .git文件夹的删除</span></h5><p><img src="/2019/09/21/多端更新hexo博客/git.png" alt></p><p>如上图，git是不支持嵌套的，这就意味着，假如我在A文件夹中初始化了本地仓库git，想要上传A仓库中所有的文件夹包括其中的B文件夹，但是B文件夹我们看到也是存在git仓库的。所以这时候我们去上传文件夹时，B文件夹中的内容是不能被上传的。</p><p>所以我们使用hexo时，像themes中我们下载的next主题是从github上面下载来的，所以里面会自带一个.git文件夹。所以我们要把所有的.git文件夹删除才行。</p><p><strong><img src="/2019/09/21/多端更新hexo博客/delgit.png" alt></strong></p><p>我们平时使用hexo部署时，上传到github或者coding的文件夹里面只是包含我们使用hexo编译生成的静态页面，其中是没有我们的主题、配置文件、插件等等的文件的。我们可以看一下仓库里面的文件夹：</p><p><img src="/2019/09/21/多端更新hexo博客/gitdir.png" alt></p><p>我们本地所有的文件：</p><p><img src="/2019/09/21/多端更新hexo博客/hexodir.png" alt></p><p>其实我们上传到仓库的代码仅仅是上图中.deploy_git中的部署文件，点开就可以看到。public是hexo引擎编译生成的静态页面文件。</p><h5><span id="12上传需要的文件夹">1.2上传需要的文件夹</span></h5><p>我们可以在文件夹中找到一个名为”.gitignore”的文件，此文件是为了在git push过程中过滤掉不需要的文件，下面贴出我的这个文件的内容：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">.DS_Store</span><br><span class="line">Thumbs.db</span><br><span class="line">db.json</span><br><span class="line">*.log</span><br><span class="line">node_modules/</span><br><span class="line">public/</span><br><span class="line">.deploy*/</span><br><span class="line">/.deploy_git</span><br><span class="line">/public</span><br></pre></td></tr></table></figure><p>我这里除了一些默认的文件以外，还在末尾加上了：/.deploy_git和/public。这是为了不包含这两个文件夹。这两个文件夹我们是不需要的。</p><p>然后就可以初始化本地文件夹：git init 。文件夹中出现.git文件夹即可。</p><h6><span id="121添加远程仓库">1.2.1添加远程仓库</span></h6><p>在github新建一个仓库，设为私有，名字随意，清晰就好。</p><p>打开git bash：</p><p>1)测试连通性：ssh -T <a href="mailto:git@github.com" target="_blank" rel="noopener">git@github.com</a></p><p><img src="/2019/09/21/多端更新hexo博客/ssh_test.png" alt></p><p>2)添加远程仓库</p><p><img src="/2019/09/21/多端更新hexo博客/ssh2.png" alt></p><p>git remote add <em>仓库名 git地址</em></p><p>git remote -v :查看已经添加的远程仓库地址</p><h6><span id="122上传文件夹到仓库">1.2.2上传文件夹到仓库</span></h6><p>1) git add .    #注意后面的 “.” ，代表当前文件夹中所有文件。</p><p>2)git commit -m “说明”   #提交到本地仓库，说明随意。</p><p>3)git push -u <em>仓库名 分支</em>    #推送到远程仓库地址，仓库名要对应你上面添加的远程仓库名，分支默认是master，你也可以推送到其他分支，根据实际情况而定。</p><p><img src="/2019/09/21/多端更新hexo博客/ssh3.png" alt></p><p> 我已经推送过一次了，所以这里就简单演示一下。如果你第一次推送，会打印非常多的信息，只要没报错就万事大吉了。我的远程库名字为”github”，这里要看你自己的远程库起的名字是什么，对应替换就可以了。</p><p>这时候我们打开github的仓库进行查看，就可以看到我们推送上来所有我们需要在另外一台电脑使用的文件夹了。</p><p><img src="/2019/09/21/多端更新hexo博客/gitdir2.png" alt></p><h4><span id="2clone仓库代码到新机器上继续使用">2.clone仓库代码到新机器上继续使用</span></h4><p>如果你是自己部署搭建的hexo环境的话，那么接下来问题就不大了。同样的遵循以下几个步骤：</p><p>1)新机添加ssh秘钥，github或coding上面添加公钥</p><p>2)测试连通性确保链接正常</p><p>3)新机下载安装   <a href="https://nodejs.org/en/" target="_blank" rel="noopener">node官网下载地址</a>        #cmd中使用 node -v 检验是否安装成功</p><p>4)新机下载安装   <a href="https://gitforwindows.org/" target="_blank" rel="noopener">git windows版本官网下载地址</a>  #同样cmd中 git –version检测。或者在菜单栏中能看到新安装的git bash就可以了</p><p> 5)安装hexo框架（切换到你要保存的目录右键选择”Git Bash here”）：npm install hexo –save</p><p> <img src="/2019/09/21/多端更新hexo博客/gitbash.png" alt></p><p>6)克隆远程仓库代码到本地</p><p><img src="/2019/09/21/多端更新hexo博客/gitclone.png" alt></p><p>看到我们需要的都在这里了：</p><p><img src="/2019/09/21/多端更新hexo博客/gitclone2.png" alt></p><p>我们先尝试 hexo g 看看编译会不会出错，果然出错了，一开始还算顺利，但是到后面提示我们有个文件找不到：</p><p><img src="/2019/09/21/多端更新hexo博客/error1.png" alt></p><p>这里的”calendar.swing”是因为我的博客中有使用了一些网上写好的插件，如提交日历插件、加载动画插件、官方提供的动态背景插件等等。</p><p>我们顺着路径去找：/themes/next/source/lib</p><p>发现路径下竟然是空的，因为之前是安装官方的文档，把几个插件下载在这个文件夹中，不知道为什么git过程中这几个文件夹没有上传上去。原本这几个文件夹中因为是git clone下来的，所以是带有”.git”文件夹，但是我删除后，再上传，这几个文件夹还是空的。</p><p>不过不是很重要，这几个文件很小，我们直接从公司的电脑复制这几个文件夹到我们家里的电脑相对应的路径中就可以了。</p><p><img src="/2019/09/21/多端更新hexo博客/error2.png" alt></p><p>然后再次编译：</p><p><img src="/2019/09/21/多端更新hexo博客/error3.png" alt></p><p>没有错误了。大功告成，再在本地”hexo s”启动一下试试，访问本地”localhost:4000”:</p><p><img src="/2019/09/21/多端更新hexo博客/end.png" alt></p><p>一切正常。终于可以在家更新博客了。不容易啊。因为其他配置都是原先那台电脑的，所以也不用更改任何东西。一样的”hexo d”部署就可以了。</p><p>不过想要实现电脑和家中的所有配置文件，文章等等都是同步的，那么还是需要借助git仓库，每次更新完文章，或者更改配置后，都要去git push和git pull保持多端同步的状态。</p><p>更多git使用教程后续：</p><p><a href>git使用教程(待更新)</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;正义的键盘侠，不能对这个悲惨的世界坐视不管！&lt;/p&gt;
    
    </summary>
    
      <category term="hexo" scheme="https://newpants_top/categories/hexo/"/>
    
    
      <category term="hexo" scheme="https://newpants_top/tags/hexo/"/>
    
      <category term="git" scheme="https://newpants_top/tags/git/"/>
    
  </entry>
  
  <entry>
    <title>ansible批量添加用户及配置用户秘钥</title>
    <link href="https://newpants_top/2019/09/12/ansible%E6%89%B9%E9%87%8F%E6%B7%BB%E5%8A%A0%E7%94%A8%E6%88%B7%E5%8F%8A%E9%85%8D%E7%BD%AE%E7%94%A8%E6%88%B7%E7%A7%98%E9%92%A5/"/>
    <id>https://newpants_top/2019/09/12/ansible批量添加用户及配置用户秘钥/</id>
    <published>2019-09-12T08:38:33.000Z</published>
    <updated>2019-09-30T03:50:28.047Z</updated>
    
    <content type="html"><![CDATA[<p>使用自动化运维工具 ansible 为多台服务器添加用户，并配置秘钥。</p><a id="more"></a><!-- toc --><ul><li><a href="#1ansible简介">1.ansible简介</a></li><li><a href="#2ansible安装及基本文件配置">2.ansible安装及基本文件配置</a><ul><li><a href="#21-hosts文件配置">2.1 hosts文件配置</a></li><li><a href="#22-ansiblecfg文件配置">2.2 ansible.cfg文件配置</a></li></ul></li><li><a href="#3编写playbook">3.编写playbook</a><ul><li><a href="#31-adduseryaml">3.1 adduser.yaml</a></li><li><a href="#32-deluseryaml">3.2 deluser.yaml</a></li><li><a href="#33关于模块">3.3关于模块</a></li></ul></li></ul><!-- tocstop --><h4><span id="1ansible简介">1.ansible简介</span></h4><p>ansible是一款基于python编写的自动化运维工具，多应用的场景是需要批量统一操作，类似：为多台服务器增加指定用户；更改多台服务器上某一配置文件；为多台服务器安装应用程序等等。</p><p>试想，如果是只有3台服务器，那么还好办，用xshell这类的远程工具，一台台远程过去操作就好。但是如果有30台，300台，光是想想这个数量就难免让人沮丧了。</p><p>其实市面上有很多款类似的开源软件。这里说下ansible的优缺点。</p><p>优点：</p><p>​            （1）python语言开发（意味着基本不需要搭建语言环境，开箱即用，因为大多，像red hat的centos系列装机都是自带python2.7版本的）</p><p>​            （2）基于ssh远程连接执行命令（也就意味着不需要在远程主机上安装任何代理端）</p><p>​            （3）使用YAML语法（学习简单，yaml配置文件格式清晰）</p><p>​            （4）内置模块（模块后面的配置会接触到。这里记住模块是<strong>幂等性</strong>的就可以了。幂等性举个例子就是：你在一台机器上创建用户“user01”，如果“user01”不存在，则创建他，如果“user01”存在，ansible就不会做任何事情。所以在同一台机器上执行同一个ansible playbook是安全的）</p><p>缺点：</p><p>​            （1）无web界面（其实是有<a href="https://www.ansible.com/products/tower" target="_blank" rel="noopener">ansible tower</a>可以使用的。但是据说是商业版才有的，暂时没有深入了解）</p><p>​            （2）因内置模块的特殊性，即使是简单任务也是要花一些时间来编写playbook的（其实熟悉了以后很快，重点还是前期的学习过程）</p><p>​            （3）速度中等（因为不是多通道执行任务，一个任务执行成功返回结果后才执行下一个任务）</p><p>注：上面有提到playbook，这里简单说下。直接使用ansible+命令是可以对目标主机进行操作的。但是如果命令很多，比如要先增加user01，然后为他分配组，为他增加ssh秘钥。一条一条输入显然不现实。而playbook就相当于ansible的剧本，将所有的步骤写在playbook中一次性去执行。</p><h4><span id="2ansible安装及基本文件配置">2.ansible安装及基本文件配置</span></h4><p>ansible的安装很简单，可以通过yum方式安装。这里可以参考官网文档：<a href="https://docs.ansible.com/" target="_blank" rel="noopener">docs.ansible.com</a></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@padim ~]#yum install ansible</span><br></pre></td></tr></table></figure><p>还可以通过github下载安装等等方式。</p><p>使用yum方式安装后，默认安装目录是在<strong>/etc/ansible/</strong>下。</p><h5><span id="21-hosts文件配置">2.1 hosts文件配置</span></h5><p>这里的hosts不是linux主机上的hosts文件。是指ansible安装目录下的hosts文件，这个hosts文件就是来规定你连接的主机ip，或者主机群组的。默认位置在下面要说到的 ansible.cfg 中指定。我这里的位置是：/etc/ansible/playbooks/hosts</p><p>下面举个hosts文件的例子：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[nginx]</span><br><span class="line">192.168.40.10</span><br><span class="line">192.168.40.11</span><br><span class="line">[mysql]</span><br><span class="line">192.168.40.20</span><br><span class="line">192.168.40.21</span><br><span class="line">[all]</span><br><span class="line">192.168.40.10</span><br><span class="line">192.168.40.11</span><br><span class="line">192.168.40.20</span><br><span class="line">192.168.40.21</span><br></pre></td></tr></table></figure><h5><span id="22-ansiblecfg文件配置">2.2 ansible.cfg文件配置</span></h5><p>首先配置ansible.cfg文件，相当于整个程序的默认启动配置文件。下面是我的配置：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[defaults]</span><br><span class="line">inventory       =/etc/ansible/playbooks/hosts</span><br><span class="line">remote_user     =root</span><br><span class="line">private_key_file=/root/.ssh/my_private</span><br><span class="line">host_key_checking=False</span><br></pre></td></tr></table></figure><p>如果不在这里配置的话，等要写playbook时，是需要再配置的。所以我们这里进行默认的统一配置，有非常多可以增加的项目。这里只说明，如何使用本地的私钥来连接目标服务器上的公钥。（几台服务器上的公钥都是统一的，相当于一把钥匙开好几个锁）</p><table><thead><tr><th>参数选项</th><th>参数说明</th></tr></thead><tbody><tr><td>inventory</td><td>指定hosts文件的路径</td></tr><tr><td>remote_user</td><td>远程连接使用的用户名，此处为root</td></tr><tr><td>private_key_file</td><td>私钥文件路径</td></tr><tr><td>host_key_checking</td><td>首次连接会提示输入yes来确认连接主机。这里选择False来关闭这个提示。</td></tr></tbody></table><h4><span id="3编写playbook">3.编写playbook</span></h4><p>playbook就是ansible的剧本，也是使用ansible中最重要的一环。我们把所有要进行操作的步骤，统一放在yaml文件中，让ansible去执行。</p><p>yaml文件格式编写时要注意缩进，因为yaml文件对缩进的要求是非常严格的。刚刚入门编写yaml可能会被缩进逼疯，经常调试半天还是有错误。不过只要多编写几个，熟悉了套路，yaml文件的优势就慢慢体现出来。主要是体现在易于阅读和更改。对后期维护等操作非常的有益。</p><p>下面直接贴出我的adduser.yaml配置文件，然后对文件一一进行解读：</p><h5><span id="31-adduseryaml">3.1 adduser.yaml</span></h5><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">- name:</span> <span class="string">增加指定用户并添加秘钥</span> <span class="string">清理自动生成的秘钥</span> </span><br><span class="line">  <span class="comment">#指定远程命令的主机组</span></span><br><span class="line"><span class="attr">  hosts:</span> <span class="string">all</span> </span><br><span class="line">  <span class="comment">#动作</span></span><br><span class="line"><span class="attr">  tasks:</span> </span><br><span class="line"><span class="attr">    - name:</span> <span class="string">增加用户user01</span></span><br><span class="line">      <span class="comment">#使用模块user</span></span><br><span class="line"><span class="attr">      user:</span> </span><br><span class="line">         <span class="comment">#指定增加用户名为：</span></span><br><span class="line"><span class="attr">         name:</span> <span class="string">user01</span> </span><br><span class="line">         <span class="comment">#增加用户说明</span></span><br><span class="line"><span class="attr">         comment:</span> <span class="string">developer</span> </span><br><span class="line">         <span class="comment">#用户所属组</span></span><br><span class="line"><span class="attr">         group:</span> <span class="string">dev</span> </span><br><span class="line">         <span class="comment">#登陆所使用的shell路径</span></span><br><span class="line"><span class="attr">         shell:</span> <span class="string">/bin/bash</span> </span><br><span class="line">         <span class="comment">#是否在.ssh/路径下生成id_rsa及id_rsa.pub</span></span><br><span class="line"><span class="attr">         generate_ssh_key:</span> <span class="literal">yes</span> </span><br><span class="line">         <span class="comment">#指定生成的路径和名称，公钥自动以.pub结尾</span></span><br><span class="line"><span class="attr">         ssh_key_file:</span> <span class="string">.ssh/id_rsa</span> </span><br><span class="line">         <span class="comment">#默认值present，表示用户需要存在</span></span><br><span class="line"><span class="attr">         state:</span> <span class="string">present</span> </span><br><span class="line"><span class="attr">    - name:</span> <span class="string">复制本机192.168.50.50指定路径文件到目标服务器上</span></span><br><span class="line">      <span class="comment">#使用copy模块</span></span><br><span class="line"><span class="attr">      copy:</span> </span><br><span class="line">         <span class="comment">#源路径，本机文件路径</span></span><br><span class="line"><span class="attr">         src:</span> <span class="string">/home/padim/.ssh/authorized_keys</span> </span><br><span class="line">         <span class="comment">#目标主机路径</span></span><br><span class="line"><span class="attr">         dest:</span> <span class="string">/home/user01/.ssh/authorized_keys</span> </span><br><span class="line">         <span class="comment">#文件所有人</span></span><br><span class="line"><span class="attr">         owner:</span> <span class="string">user01</span> </span><br><span class="line">         <span class="comment">#文件所有组</span></span><br><span class="line"><span class="attr">         group:</span> <span class="string">dev</span> </span><br><span class="line">         <span class="comment">#文件权限</span></span><br><span class="line"><span class="attr">         mode:</span> <span class="string">'0600'</span> </span><br><span class="line"><span class="attr">    - name:</span> <span class="string">清理自动生成的id_rsa文件</span> </span><br><span class="line">      <span class="comment">#使用file模块</span></span><br><span class="line"><span class="attr">      file:</span> </span><br><span class="line">         <span class="comment">#指定路径，删除多个文件时使用，&#123;&#123;item&#125;&#125;为变量，不可变</span></span><br><span class="line"><span class="attr">         path:</span> <span class="string">'/home/user01/.ssh/<span class="template-variable">&#123;&#123; item &#125;&#125;</span>'</span> </span><br><span class="line">         <span class="comment">#状态，删除</span></span><br><span class="line"><span class="attr">         state:</span> <span class="string">absent</span> </span><br><span class="line">         <span class="comment">#定义变量的多个值</span></span><br><span class="line"><span class="attr">      with_items:</span></span><br><span class="line"><span class="bullet">         -</span> <span class="string">id_rsa</span></span><br><span class="line"><span class="bullet">         -</span> <span class="string">id_rsa.pub</span></span><br></pre></td></tr></table></figure><p>以上文件基本都有注释了，这里说明几个地方：</p><table><thead><tr><th>参数名称</th><th>参数说明</th></tr></thead><tbody><tr><td><strong>name</strong></td><td>类似整个文件的说明，随意填写，清楚表达即可。</td></tr><tr><td><strong>tasks</strong></td><td>步骤。每一个tasks为一步，比如上面就是在一步里面完成创建user01。如果要再删除user01，可以在下面再新建一个tasks用来删除。</td></tr><tr><td><strong>tasks中的name</strong></td><td>一样是说明性语句，可随意填写。执行playbook时这项说明语句会打印在屏幕上，告诉你playbook的进展情况。</td></tr></tbody></table><p>编辑好playbook后直接检查并运行该文件就可以了，命令如下：</p><p>检查(使用check参数)：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@padim ~]#ansible-playbook --check adduser.yaml</span><br></pre></td></tr></table></figure><p>无报错后运行：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@padim ~]#ansible-playbook adduser.yaml</span><br></pre></td></tr></table></figure><h5><span id="32-deluseryaml">3.2 deluser.yaml</span></h5><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#删除用户</span></span><br><span class="line"><span class="attr">- name:</span> <span class="string">删除用户user01</span></span><br><span class="line">  <span class="comment">#指定执行的主机组</span></span><br><span class="line"><span class="attr">  hosts:</span> <span class="string">all</span></span><br><span class="line"><span class="attr">  tasks:</span></span><br><span class="line"><span class="attr">    - name:</span> <span class="string">删除用户user01</span></span><br><span class="line">      <span class="comment">#使用user模块</span></span><br><span class="line"><span class="attr">      user:</span>  </span><br><span class="line"><span class="attr">        name:</span> <span class="string">user01</span></span><br><span class="line">        <span class="comment">#absent参数代表删除</span></span><br><span class="line"><span class="attr">        state:</span> <span class="string">absent</span></span><br><span class="line">        <span class="comment">#删除家目录</span></span><br><span class="line"><span class="attr">        remove:</span> <span class="literal">yes</span></span><br></pre></td></tr></table></figure><h5><span id="33关于模块">3.3关于模块</span></h5><p>ansible的官方文档编写的已经是非常的详细了。而且每个功能或者说是模块的使用。官方都会在下面给出一个例子来详细说明，只要耐心的对例子进行阅读，很快就能明白模块的使用方法。下面给出几个链接供学习和参考：</p><p><a href="https://docs.ansible.com/ansible/latest/modules/list_of_all_modules.html" target="_blank" rel="noopener">ansible官方所有模块列表</a></p><p><a href="https://docs.ansible.com/ansible/latest/modules/user_module.html#user-module" target="_blank" rel="noopener">user模块</a></p><p><a href="https://docs.ansible.com/ansible/latest/modules/list_of_files_modules.html" target="_blank" rel="noopener">文件模块</a></p><p><a href="https://docs.ansible.com/ansible/latest/modules/shell_module.html#shell-module" target="_blank" rel="noopener">shell模块</a></p><p><a href="https://docs.ansible.com/ansible/latest/modules/user_module.html#user-module" target="_blank" rel="noopener">模块索引</a></p><p><a href="https://docs.ansible.com/ansible/latest/modules/copy_module.html#copy-module" target="_blank" rel="noopener">copy模块</a></p><p>因为本文旨在说明如果使用 ansible 批量批量添加用户及配置用户秘钥。所以以上列出一些相关的模块链接。如果有其他需求，对单独模块进行学习即可。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;使用自动化运维工具 ansible 为多台服务器添加用户，并配置秘钥。&lt;/p&gt;
    
    </summary>
    
      <category term="ansible" scheme="https://newpants_top/categories/ansible/"/>
    
    
      <category term="自动化运维" scheme="https://newpants_top/tags/%E8%87%AA%E5%8A%A8%E5%8C%96%E8%BF%90%E7%BB%B4/"/>
    
      <category term="ansible" scheme="https://newpants_top/tags/ansible/"/>
    
  </entry>
  
  <entry>
    <title>zabbix监控docker</title>
    <link href="https://newpants_top/2019/09/10/zabbix%E7%9B%91%E6%8E%A7docker/"/>
    <id>https://newpants_top/2019/09/10/zabbix监控docker/</id>
    <published>2019-09-10T05:53:56.000Z</published>
    <updated>2019-09-30T03:49:12.044Z</updated>
    
    <content type="html"><![CDATA[<p>使用 zabbix 对 docker 运行容器使用的 CPU 和内存情况等进行监控</p><a id="more"></a><!-- toc --><ul><li><a href="#1zabbix监控原理">1.zabbix监控原理</a></li><li><a href="#2增加键值">2.增加键值</a><ul><li><a href="#21查看agent端配置">2.1查看agent端配置</a></li><li><a href="#22配置键值">2.2配置键值</a></li></ul></li><li><a href="#3增加-python-脚本">3.增加 python 脚本</a></li><li><a href="#4server端进行简单测试">4.server端进行简单测试</a></li><li><a href="#5web界面增加监控模板">5.web界面增加监控模板</a><ul><li><a href="#51创建发现规则">5.1创建发现规则</a></li><li><a href="#52添加监控项原形">5.2添加监控项原形</a></li></ul></li><li><a href="#6为主机链接模板">6.为主机链接模板</a></li></ul><!-- tocstop --><p>官网有提供了一些监控 docker 信息的模板。具体可以通过点击 zabbix 主页的 share 进入官网网址后搜索下载，并按步骤进行安装即可（如下图）</p><p><img src="/2019/09/10/zabbix监控docker/zabbix_share1.png" alt></p><p>搜索框里直接搜索docker即可。还有各种各样的其他模板共使用。</p><p><img src="/2019/09/10/zabbix监控docker/zabbix_share2.png" alt></p><h4><span id="1zabbix监控原理">1.zabbix监控原理</span></h4><p>本文使用自建的 python 脚本对 docker 进行监控。zabbix 监控大致原理可以分为：</p><p>增加键值 –&gt; 采集数据 –&gt;  agent 端传递键值给server端 –&gt; web 界面增加模板 –&gt; 为主机添加模板 –&gt; 添加触发器/图形等</p><h4><span id="2增加键值">2.增加键值</span></h4><p>那第一步我们就是要来采集数据了。</p><p>采集数据有多种方式，可以是 shell 脚本、python 脚本、又或者是程序自带的信息界面</p><p>如：</p><p>redis 中： redis-cli -h 127.0.0.1 -p 端口号 -a 密码 </p><p>nginx 配置时增加’–with-http_stub_status_module’模块，配置 nginx.conf 后在地址 “<a href="http://127.0.0.1/status&quot;" target="_blank" rel="noopener">http://127.0.0.1/status&quot;</a> 中查看，诸如此类这样的命令，截取其中想要的信息保存到一个文件内读取。</p><p>注：脚本是放在 agent 端，增加键值等也是在 agent 端增加。</p><h5><span id="21查看agent端配置">2.1查看agent端配置</span></h5><p>首先找到 zabbix_agentd.conf 配置文件，在配置文件中搜索包含”Include”的行。如我的配置文件是：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Include=/etc/zabbix/zabbix_agentd.d/</span><br></pre></td></tr></table></figure><h5><span id="22配置键值">2.2配置键值</span></h5><p>然后在路径 /etc/zabbix/zabbix_agentd.d/ 下建立两个 python 脚本：</p><p><strong>docker_discovery.conf</strong>  （自动发现规则）</p><p><strong>docker_status.conf</strong> （获取状态的脚本）</p><p>注：自动发现规则主要是为了省事省力，试想你 docker 中有三个容器，名称分别是 nginx,node,php。那如果你一个个的去增加，工作效率极低，而是使用自动发现，通过脚本的编写来确定所有的容器名称。</p><p>docker_status.conf 文件中只要增加一行代码即可：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">UserParameter=docker_status[*],sudo /usr/bin/python /etc/zabbix/script/docker_monitor.py $1 $2</span><br></pre></td></tr></table></figure><p><strong>UserParameter :</strong> zabbix 增加自定义键值，此处不可更改</p><p><strong>docker_status[*] ：</strong>键值的名称，可以根据喜好来取名字，不过最好还是让人能一眼就看出你键值的意义。其中”[*]”代表任意值，是 shell 的语法。因为我们要监控特定容器的 CPU、负载、内存等使用的情况，最后的 $1 $2 的变量就是对此处赋值。</p><p><strong>sudo /usr/bin/python /etc/zabbix/script/docker_monitor.py ：</strong>指定了 python 的运行路径，sudo 运行（如果是 root 用户运行可去掉该项），还有我们 python 脚本的运行路径和s名称。此处为了整洁，我在 zabbix 目录下新建了 script 目录来存放这两个脚本。</p><p><strong>$1 $2 ：</strong>shell 脚本中的变量，$0 代表脚本名称，$1 $2 则是我们后面需要赋值给 docker_status[*] 的两个变量。容器名称和特定监控项（如 CPU 使用率，内存使用率等）</p><p>docker_discovery.conf 和上面的基本相同，不过是脚本不同：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">UserParameter=docker_discovery,python /etc/zabbix/script/docker_discovery.py</span><br></pre></td></tr></table></figure><h4><span id="3增加-python-脚本">3.增加 python 脚本</span></h4><p>按照2中的路径，在 /etc/zabbix/script/ 下建立： docker_discovery.py 和 docker_monitor.py</p><p>docker_discovery.py：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> simplejson <span class="keyword">as</span> json</span><br><span class="line">tname=os.popen(<span class="string">"""sudo docker ps | grep -v 'CONTAINER ID'|awk &#123;'print $NF'&#125;"""</span>)</span><br><span class="line">container_name=[]</span><br><span class="line"><span class="keyword">for</span> container <span class="keyword">in</span> tname.readlines():</span><br><span class="line">        rname=os.path.basename(container.strip())</span><br><span class="line">        container_name+=[&#123;<span class="string">'&#123;#CONTAINERNAME&#125;'</span>:rname&#125;]</span><br><span class="line"><span class="keyword">print</span> json.dumps(&#123;<span class="string">'data'</span>:container_name&#125;,sort_keys=<span class="literal">True</span>,indent=<span class="number">4</span>,separators=(<span class="string">','</span>,<span class="string">':'</span>))</span><br></pre></td></tr></table></figure><p>docker_monitor.py:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="keyword">import</span> docker</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> subprocess</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">check_container_stats</span><span class="params">(container_name,collect_item)</span>:</span></span><br><span class="line">        container_collect=docker_client.containers.get(container_name).stats(stream=<span class="literal">True</span>)</span><br><span class="line">        old_result=eval(container_collect.next())</span><br><span class="line">        new_result=eval(container_collect.next())</span><br><span class="line">        container_collect.close()</span><br><span class="line">        <span class="comment">#CPU使用百分比</span></span><br><span class="line">        <span class="keyword">if</span> collect_item == <span class="string">'cpu_percent'</span>:</span><br><span class="line">                cpu_total_usage=new_result[<span class="string">'cpu_stats'</span>][<span class="string">'cpu_usage'</span>][<span class="string">'total_usage'</span>] - old_result[<span class="string">'cpu_stats'</span>][<span class="string">'cpu_usage'</span>][<span class="string">'total_usage'</span>]</span><br><span class="line">                cpu_system_uasge=new_result[<span class="string">'cpu_stats'</span>][<span class="string">'system_cpu_usage'</span>] - old_result[<span class="string">'cpu_stats'</span>][<span class="string">'system_cpu_usage'</span>]</span><br><span class="line">                cpu_num=len(old_result[<span class="string">'cpu_stats'</span>][<span class="string">'cpu_usage'</span>][<span class="string">'percpu_usage'</span>])</span><br><span class="line">                result=round((float(cpu_total_usage)/float(cpu_system_uasge))*cpu_num*<span class="number">100.0</span>,<span class="number">2</span>)</span><br><span class="line">        <span class="comment">#内存使用量</span></span><br><span class="line">        <span class="keyword">elif</span> collect_item == <span class="string">'mem_usage'</span>:</span><br><span class="line">                result=new_result[<span class="string">'memory_stats'</span>][<span class="string">'usage'</span>]</span><br><span class="line"><span class="comment">#内存使用百分比</span></span><br><span class="line">        <span class="keyword">elif</span> collect_item == <span class="string">'mem_percent'</span>:</span><br><span class="line">                mem_usage=new_result[<span class="string">'memory_stats'</span>][<span class="string">'usage'</span>]</span><br><span class="line">                mem_limit=new_result[<span class="string">'memory_stats'</span>][<span class="string">'limit'</span>]</span><br><span class="line">                result=round(float(mem_usage)/float(mem_limit)*<span class="number">100.0</span>,<span class="number">2</span>)</span><br><span class="line">        <span class="keyword">return</span> result</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">        docker_client = docker.DockerClient(base_url=<span class="string">'unix://var/run/docker.sock'</span>, version=<span class="string">'1.27'</span>)</span><br><span class="line">        container_name=sys.argv[<span class="number">1</span>]</span><br><span class="line">        collect_item=sys.argv[<span class="number">2</span>]</span><br><span class="line">        <span class="keyword">print</span> check_container_stats(container_name,collect_item)</span><br></pre></td></tr></table></figure><p>python 版本是使用的是：Python 2.7.5</p><p>脚本的编写这里就不详细说了，如果有 python 基础，大部分的代码还是看得懂的。</p><p>建议直接复制上面两个脚本，并且记得下载脚本中所需的 python 包：<strong>docker、simplejson、subprocess</strong>等。并且增加脚本的可执行权限。否则会报错。</p><p>可以直接在终端执行”python /etc/zabbix/script/docker_discovery.py”检验代码是否有误，如下图：</p><p><img src="/2019/09/10/zabbix监控docker/docker_discovery.png" alt></p><p>可以看到我这里已经获取了三个容器，并且分别打印了他们的名称（就如同我们使用 docker ps 看到的一样）</p><p>docker_monitor.py 直接运行可不行，会报错：</p><p><img src="/2019/09/10/zabbix监控docker/docker_monitor1.png" alt></p><p>提示我们超出列表值，这是因为我们没有在后面接指定的”<strong>container_name</strong>“和”<strong>collect_item</strong>“。这也是”docker_status.conf”文件中为什么要在最后增加”$1 $2”的原因。</p><p>增加指定的两个变量后：</p><p><img src="/2019/09/10/zabbix监控docker/docker_monitor2.png" alt></p><p><strong>tb-nginx:</strong> 运行 docker_discovery.py获取到的容器名字</p><p><strong>cpu_percent:</strong>  docker_monitor.py中编写的”collect_item”值</p><p>可以看到返回1.45。即我们容器名为”tb-nginx“的 CPU 使用占比为：1.45%</p><h4><span id="4server端进行简单测试">4.server端进行简单测试</span></h4><p>以上的脚本都运行正常后，重启 zabbix-agent (不重启键值是不生效的)</p><p>然后在 zabbix-server 终端我们可以使用 zabbix 官方提供的 zabbix_get 进行测试（如果没有需要下载）</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">zabbix_get -s 192.168.40.10 -k docker_status[tb-nginx,mem_percent]</span><br></pre></td></tr></table></figure><p>192.168.40.10 ：就是你刚才增加键值的 agent 端，根据实际情况更改。</p><p>如果有正常返回值，那么就可以了，接下来配置 web 端。</p><h4><span id="5web界面增加监控模板">5.web界面增加监控模板</span></h4><p>打开 zabbix 的 web 界面，配置 –&gt; 模板 –&gt; 创建模板 </p><p><img src="/2019/09/10/zabbix监控docker/web1.png" alt></p><p>我这里已经添加好了，可以看到”已连接到”那里已经链接了几个模板。</p><p>名称、应用集、模板群组等这些都可根据个人喜好设定，方便管理和识别即可。</p><p>比较关键的是接下来”自动发现规则”这里。</p><h5><span id="51创建发现规则">5.1创建发现规则</span></h5><p><img src="/2019/09/10/zabbix监控docker/web2.png" alt></p><p><img src="/2019/09/10/zabbix监控docker/web3.png" alt></p><h5><span id="52添加监控项原形">5.2添加监控项原形</span></h5><p><img src="/2019/09/10/zabbix监控docker/web4.png" alt></p><p>两个监控项原形创建：</p><p><img src="/2019/09/10/zabbix监控docker/web5.png" alt></p><p><img src="/2019/09/10/zabbix监控docker/web6.png" alt></p><h4><span id="6为主机链接模板">6.为主机链接模板</span></h4><p>找到需要监控的主机，添加模板：</p><p><img src="/2019/09/10/zabbix监控docker/web7.png" alt></p><p>添加后点击更新。然后稍微等几分钟。点进监控项里查看，就可以看到我们自动发现的容器了。</p><p><img src="/2019/09/10/zabbix监控docker/web8.png" alt></p><p>有了监控项且没有报错，可以在 zabbix web 界面 –&gt;监测中 –&gt; 最新数据 中查看对应的值了。</p><p>然后接下来可以增加触发器、图形这些的。我这里图形是手动添加的，当然也可以自动添加，自动添加就是在增加 “docker自动发现模板”那里，再增加一个图形的模板。我这里需求的不太多，就手动添加了，效果图如下：</p><p><img src="/2019/09/10/zabbix监控docker/web10.png" alt></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;使用 zabbix 对 docker 运行容器使用的 CPU 和内存情况等进行监控&lt;/p&gt;
    
    </summary>
    
      <category term="zabbix" scheme="https://newpants_top/categories/zabbix/"/>
    
    
      <category term="docker" scheme="https://newpants_top/tags/docker/"/>
    
      <category term="zabbix" scheme="https://newpants_top/tags/zabbix/"/>
    
  </entry>
  
  <entry>
    <title>filebeat.yml配置详解</title>
    <link href="https://newpants_top/2019/09/06/filebeat-yml%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/"/>
    <id>https://newpants_top/2019/09/06/filebeat-yml配置详解/</id>
    <published>2019-09-06T08:16:36.000Z</published>
    <updated>2019-09-30T03:50:35.259Z</updated>
    
    <content type="html"><![CDATA[<p>filebeat.yml配置详解</p><a id="more"></a><!-- toc --><ul><li><a href="#1filebeat介绍">1.filebeat介绍</a></li><li><a href="#2示例文件及配置解析">2.示例文件及配置解析</a></li></ul><!-- tocstop --><h4><span id="1filebeat介绍">1.filebeat介绍</span></h4><p>filebeat 是 elastic beats 中的一个轻量型的采集器。beats 包含很多系列，如官网下图：</p><p><img src="/2019/09/06/filebeat-yml配置详解/beats.png" alt="beat系列"></p><p>基本从名字就可以看得出来其对应的功能。这里我们使用 filebeat 主要针对文件（也就是需要采集的log日志) 来进行采集。</p><p>filebeat 的原理是开启一个 prospectors(收割者)，对文件逐行进行采集。</p><h4><span id="2示例文件及配置解析">2.示例文件及配置解析</span></h4><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">filebeat.prospectors:</span><span class="comment">#采集 abc.com 下 nginx 的 access 日志 </span></span><br><span class="line"><span class="bullet">-</span> <span class="string">type</span> <span class="string">:</span> <span class="string">log</span></span><br><span class="line"><span class="attr">  enabled:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">  paths:</span></span><br><span class="line"><span class="bullet">     -</span> <span class="string">/data/server/wwwlog/nginx/abc.com.access.log</span></span><br><span class="line"><span class="attr">  tags:</span> <span class="string">["nginx_access"]</span></span><br><span class="line"><span class="attr">  tail_files:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">  scan_frequency:</span> <span class="number">30</span><span class="string">s</span></span><br><span class="line"><span class="attr">  fields:</span></span><br><span class="line"><span class="attr">    host:</span> <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span></span><br><span class="line"><span class="attr">    project:</span> <span class="string">abc.com</span></span><br></pre></td></tr></table></figure><table><thead><tr><th>参数选项</th><th>参数说明</th></tr></thead><tbody><tr><td>filebeat.prospectors</td><td>文件开头指定 filebeat 的采集方式，此处使用 prospectors</td></tr><tr><td>type : log</td><td>类型为：log</td></tr><tr><td>enabled: true</td><td>true 为开启，false 为关闭</td></tr><tr><td>paths:</td><td>指定路径</td></tr><tr><td>tags:</td><td>打标签，自定义名称，为后续在kibana查看时提供过滤与分类的效果</td></tr><tr><td>tail_files: true</td><td>开启此项，代表采集从文件最底部开始，选择 false 时 filebeat 会从文件头部开始采集</td></tr><tr><td>scan_frequency: 30s</td><td>对文件的扫描间隔（每30秒扫描一次文件是否改动，根据实际情况改动）</td></tr><tr><td>fields:</td><td>添加字段（用于 elasticsearch 过滤、分类，以及 kibana 中查看）</td></tr></tbody></table><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="bullet">-</span> <span class="string">type</span> <span class="string">:</span> <span class="string">log</span><span class="comment">#采集 abc.com 下 nginx 的 error 日志</span></span><br><span class="line"><span class="attr">  enabled:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">  paths:</span></span><br><span class="line"><span class="bullet">     -</span> <span class="string">/data/server/wwwlog/nginx/abc.com.error.log</span></span><br><span class="line"><span class="attr">  tags:</span> <span class="string">["nginx_error"]</span></span><br><span class="line"><span class="attr">  tail_files:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">  scan_frequency:</span> <span class="number">30</span><span class="string">s</span></span><br><span class="line"><span class="attr">  fields:</span></span><br><span class="line"><span class="attr">    host:</span> <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span></span><br><span class="line"><span class="attr">    project:</span> <span class="string">abc.com</span></span><br></pre></td></tr></table></figure><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="bullet">-</span> <span class="string">type</span> <span class="string">:</span> <span class="string">log</span><span class="comment">#采集 abc.com 下 nginx 的 cache 日志</span></span><br><span class="line"><span class="attr">  enabled:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">  paths:</span></span><br><span class="line"><span class="bullet">     -</span> <span class="string">/data/server/wwwcache/abc.com.cache/application.log</span></span><br><span class="line">  <span class="string">multiline.pattern:</span> <span class="string">'^[0-9]&#123;4&#125;/[0-9]&#123;2&#125;/[0-9]&#123;2&#125;'</span></span><br><span class="line">  <span class="string">multiline.negate:</span> <span class="literal">true</span></span><br><span class="line">  <span class="string">multiline.match:</span> <span class="string">after</span></span><br><span class="line"><span class="attr">  tags:</span> <span class="string">["wwwcache"]</span></span><br><span class="line"><span class="attr">  tail_files:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">  scan_frequency:</span> <span class="number">30</span><span class="string">s</span></span><br><span class="line"><span class="attr">  fields:</span></span><br><span class="line"><span class="attr">    host:</span> <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span></span><br><span class="line"><span class="attr">    project:</span> <span class="string">abc.com</span></span><br></pre></td></tr></table></figure><p>  multiline.pattern: ‘^[0-9]{4}/[0-9]{2}/[0-9]{2}’<br>  multiline.negate: true<br>  multiline.match: after</p><p>以上通过正规表达式，对日志多行进行合并。如下图效果(根据实际情况配置正规表达式，可对任意行进行合并保存在一个 message 中)：</p><p>cache 中日志不需要逐行采集，需要采集某一段</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span>2 /data/server/wwwroot/tui.tongbu.com/index.php(28): CApplication-&gt;run()</span><br><span class="line"><span class="meta">#</span>3 &#123;main&#125;</span><br><span class="line">REQUEST_URI=/apple-touch-icon-120x120-precomposed.png</span><br><span class="line">---</span><br><span class="line">2019/09/06 16:47:32 [error] [exception.CHttpException.404] CHttpException: Unable to resolve the request "apple-touch-icon-120x120.png". in /data/server/wwwroot/yii/framework/web/CWebApplication.php:286</span><br><span class="line">Stack trace:</span><br><span class="line"><span class="meta">#</span>0 /data/server/wwwroot/yii/framework/web/CWebApplication.php(141): CWebApplication-&gt;runController('apple-touch-ico...')</span><br><span class="line"><span class="meta">#</span>1 /data/server/wwwroot/yii/framework/base/CApplication.php(185): CWebApplication-&gt;processRequest()</span><br><span class="line"><span class="meta">#</span>2 /data/server/wwwroot/tui.tongbu.com/index.php(28): CApplication-&gt;run()</span><br><span class="line"><span class="meta">#</span>3 &#123;main&#125;</span><br><span class="line">REQUEST_URI=/apple-touch-icon-120x120.png</span><br><span class="line">---</span><br></pre></td></tr></table></figure><p>增加正规表达式后：</p><p><img src="/2019/09/06/filebeat-yml配置详解/wwwcache_kibana.png" alt="合并多行日志"></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;filebeat.yml配置详解&lt;/p&gt;
    
    </summary>
    
      <category term="ELK" scheme="https://newpants_top/categories/ELK/"/>
    
    
      <category term="filebeat" scheme="https://newpants_top/tags/filebeat/"/>
    
  </entry>
  
  <entry>
    <title>ELK+filebeat日志采集（搭建篇）</title>
    <link href="https://newpants_top/2019/08/30/ElkDeploy/"/>
    <id>https://newpants_top/2019/08/30/ElkDeploy/</id>
    <published>2019-08-30T03:14:03.000Z</published>
    <updated>2019-10-22T07:56:24.944Z</updated>
    
    <content type="html"><![CDATA[<p>ELK+filebeat日志采集（搭建篇）</p><a id="more"></a><!-- toc --><ul><li><a href="#1基本架构图">1.基本架构图</a></li><li><a href="#2此例版本号说明">2.此例版本号说明</a></li><li><a href="#3-java-环境配置">3. JAVA 环境配置</a></li><li><a href="#4rpm形式安装elk">4.RPM形式安装elk</a></li><li><a href="#5-安装-filebeat">5. 安装 filebeat</a></li><li><a href="#6配置文件证明连通性">6.配置文件证明连通性</a><ul><li><a href="#61配置-logstashyml-文件">6.1配置 logstash.yml 文件：</a></li><li><a href="#62配置elasticsearchyml">6.2配置elasticsearch.yml</a></li><li><a href="#63配置kibanayml">6.3配置kibana.yml</a></li></ul></li><li><a href="#7打开kibana添加索引验证">7.打开kibana添加索引验证</a></li></ul><!-- tocstop --><p><img src="/2019/08/30/ElkDeploy/elastic_top.png" alt></p><p>这里不进行配置文件配置更改的说明。全部使用默认配置文件，此篇主要旨在介绍正常安装及运行。</p><p><strong>每种程序的单独介绍可在以下查看（常用的一些配置和概念）：</strong></p><p><strong><a href="https://newpants.top/2019/10/22/elasticsearch配置及优化" target="_blank" rel="noopener">elasticsearch介绍及配置说明</a></strong></p><p><strong><a href>logstash介绍配置说明(待更新)</a></strong></p><p><strong><a href>kibana介绍及配置说明(待更新)</a></strong></p><p><strong><a href="https://newpants.top/2019/09/06/filebeat-yml配置详解" target="_blank" rel="noopener">filebeat介绍及配置说明</a></strong></p><p><a href="https://www.elastic.co/guide/index.html" target="_blank" rel="noopener">elastic官方文档地址</a>   #官方文档说明的都很详细</p><h3><span id="1基本架构图">1.基本架构图</span></h3><p><img src="/2019/08/30/ElkDeploy/Architecture_diagram.png" alt></p><p>elasticsearch： 一款基于 Lucene 的搜索服务器。可以理解为数据库，我们日后将要采集的日志都将储存在这里。</p><p>logstash： logstash 的主要功能是将数据按照我们的要求进行过滤和筛选。完成我们制定的工作发送给 elasticsearch 后以便我们查询。</p><p>kibana： 基于web的查看页面。已经开始提供越来越多的 api。以前的 elasticsearch 还需要 elasticsearch-head 或者直接服务器上面进行操作和查询。现 kibana 的控制台基本可以满足大部分需求。</p><p>filebeat： 采集工具。因为 logstash 非常的消耗系统资源，为了不影响业务服务器，使用 filebeat ，他非常轻量。基本不占用什么空间和系统资源。</p><p>大致流程：filebeat（采集）–&gt; logstash（过滤）–&gt; elasticsearch（储存）–&gt; kibana(查看)</p><h3><span id="2此例版本号说明">2.此例版本号说明</span></h3><table><thead><tr><th>软件</th><th>Java</th><th>Elasticsearch</th><th>Logstash</th><th>Kibana</th><th>Filebeat</th></tr></thead><tbody><tr><td>版本号</td><td>1.8.0_181</td><td>6.7.1</td><td>6.7.1</td><td>6.7.1</td><td>6.7.1</td></tr></tbody></table><p>因为采集量不大，且公司内部部分需求。所以此篇文章是在一台centos7服务器上搭建elasticsearch+logstash+kibana 。其他需要采集的机器上安装 filebeat 进行采集。</p><p>这里需要注意的是，elasticsearch 和 logstash 需要在 java 环境下运行。</p><p><strong>以下安装过程简单带过，网上已经有了很多，遇到问题可以简单进行百度分析。（官方建议最好保持elk+filebeat版本一致性，以避免不可预估的情况发生）</strong></p><h3><span id="3-java-环境配置">3. JAVA 环境配置</span></h3><p>此例使用压缩包形式安装，在<a href="https://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html" target="_blank" rel="noopener">orcale官网jdk下载</a>，按照需求选择需要下载的jdk版本，此例使用 jdk-8u201-linux-x64.tar.gz</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">tar -xvzf jdk-8u201-linux-x64.tar.gz     #解压</span><br><span class="line">mv jdk1.8.0_201/ /usr/jdk1.8.0_201       #移动解压包至/usr下</span><br><span class="line"></span><br><span class="line">vim /etc/profile     #编辑系统配置文件，添加 如下java 环境变量</span><br><span class="line">export JAVA_HOME=/usr/jdk1.8.0_201  #如果不生效，在jdk1.8.0_201加“/”，目录按照实际情况</span><br><span class="line">export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar</span><br><span class="line">export PATH=$PATH:$JAVA_HOME/bin</span><br><span class="line"></span><br><span class="line">source /etc/profile                       #重新加载环境变量</span><br><span class="line">java -version                              #验证</span><br></pre></td></tr></table></figure><h3><span id="4rpm形式安装elk">4.RPM形式安装elk</span></h3><p>在elastic官网：<a href="https://www.elastic.co/cn/" target="_blank" rel="noopener">elastic官网</a>，找到产品相应的下载页面。下载rpm包（当然也可以使用yum或者压缩包形式安装，个人认为rpm比较方便，关键在于可以统一版本）</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">rpm -ivh elasticsearch-6.7.1-x86_64.rpm</span><br><span class="line">rpm -ivh logstash-6.7.1.rpm</span><br><span class="line">rpm -ivh kibana-6.7.1-x86_64.rpm</span><br></pre></td></tr></table></figure><p>因资源有限且需求量不大，故本例三种程序都安装在一台 linux centos7 上。安装完成后，查看程序是否正常启动即可。启动顺序最好按照： </p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">systemctl start elasticsearch</span><br><span class="line">systemctl start logstash</span><br><span class="line">systemctl start kibana</span><br></pre></td></tr></table></figure><p>查看是否安装并启动成功</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">netstat -tunlp | grep 9200     #elasticsearch默认开放端口，有返回如下结果代表端口已启动</span><br><span class="line">tcp6     0      0  127.0.0.1:9200          :::*                LISTEN      12427/java</span><br><span class="line"></span><br><span class="line">netstat -tunlp | grep 9600#logstash默认开放端口，有返回如下结果代表端口已启动</span><br><span class="line">tcp6     0      0  127.0.0.1:9600          :::*                LISTEN      17905/java</span><br><span class="line"></span><br><span class="line">netstat -tunlp | grep 5601#kibana默认开放端口，有返回如下结果代表端口已启动</span><br><span class="line">tcp     0      0   127.0.0.1:5601          :::*                LISTEN      4666/node</span><br></pre></td></tr></table></figure><p>此时通过浏览器访问 127.0.0.1:9200 返回类似如下页面，证明 elasticsearch 安装并正常启动：</p><p><img src="/2019/08/30/ElkDeploy/elasticsearch_start.png" alt="4.elasticsearch_start.png"></p><p>此时通过浏览器访问 127.0.0.1:5601 即可看到 kibana 页面：</p><p><img src="/2019/08/30/ElkDeploy/kibana_start.png" alt="4.kibana_start.png"></p><p>logstash的验证相比前两种不太一样</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@study ~]# whereis logstash  #先查看logstash安装的默认位置</span><br><span class="line">logstash: /etc/logstash /usr/share/logstash</span><br><span class="line"></span><br><span class="line">#执行以下命令。说明：input和output是logstash的两个插件，stdin和stdout分别代表了标准输入和标准输出</span><br><span class="line">[root@study ~]# /usr/share/logstash/bin/logstash -e &apos;input &#123; stdin &#123; &#125; &#125; output &#123; stdout &#123; &#125;&#125;&apos;</span><br></pre></td></tr></table></figure><p>看到 {:port =&gt;9600}，我们在光标等待处随便输入点文字</p><p><img src="/2019/08/30/ElkDeploy/logstash-input.png" alt="logstash_input.png"></p><p>如果类似消息输出到屏幕则正常：</p><p><img src="/2019/08/30/ElkDeploy/logstash-output.png" alt></p><p>此时我们还没有用 filebeat 来收集日志，所以也没有生成对应的索引。故此时看到的都是空的。接来下就介绍在需要采集的机器上安装 filebeat 采集日志。</p><h3><span id="5-安装-filebeat">5. 安装 filebeat</span></h3><p>在目标采集机器上安装filebeat。因采集机器不同，分为 linux 和 windows 。</p><p>linux：</p><p>安装方式：RPM安装</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@study ~]#rpm -ivh filebeat-6.7.1-x86_64.rpm</span><br><span class="line">[root@study ~]#systemctl start filebeat</span><br></pre></td></tr></table></figure><p>对 filebeat.yml 进行简单的配置：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">filebeat.prospectors:  </span><br><span class="line"> - type : log</span><br><span class="line">   enabled: true  #选择true代表开启</span><br><span class="line">   paths:         #路径</span><br><span class="line">     - /data/*.log #所有.log结尾的日志</span><br><span class="line">   fields:#自定义字段，便于区分</span><br><span class="line">      host: 127.0.0.1</span><br><span class="line">   tail_files: true#从尾部开始采集，若选择false则会从头到尾把日志每行都读取</span><br><span class="line">   scan_frequency: 30s#扫描间隔</span><br><span class="line">   exclude_lines: [&quot;^#&quot;]#正则表达式：排除空行</span><br><span class="line">   tags: [&quot;nginx&quot;]#添加tags</span><br><span class="line">output.logstash:#输出插件到logstash</span><br><span class="line"> hosts: [&quot;127.0.0.1:5044&quot;]#hosts地址 本机为测试在本机上安装filebeat。按照实际情况填写</span><br></pre></td></tr></table></figure><p>对 filebeat.yml 文件进行测试：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@study ~]#cd 到filebeat的安装目录</span><br><span class="line">[root@study ~]#./filebeat test config#测试配置文件正确性</span><br><span class="line">[root@study ~]#./filebeat test output#测试配置文件输出的正确性(需要在开启logstash并且指定开放5044端口的前提下，后面会介绍logstash配置开放5044端口)</span><br><span class="line">如果存在异常会返回error。根据error进行调整。若全部正常，则重新启动filebeat</span><br><span class="line">[root@study ~]#systemctl restart filebeat</span><br></pre></td></tr></table></figure><p>windows:</p><p>安装方式：压缩包安装成系统服务</p><p>下载 filebeat-6.7.1-windows-x86_64.zip 解压到指定文件夹，配置文件基本于上述 linux 一样，”paths: “需要更改一下。其他的测试配置文件都相同。下面主要说下把 filebeat 安装成 windows 的服务启动项。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">1.将zip文件内容解压到C：\Program Files(或者其他路径，如果为其他路径要修改install-service-filebeat文件中的路径地址）</span><br><span class="line">2.将filebeat-&lt;version&gt;-windows目录重新命名为filebeat（必须为filebeat）</span><br><span class="line">3.以管理员身份打开PowerShell提示符</span><br><span class="line">4.在PowerShell下将Filebeat安装成Windows服务：</span><br><span class="line">cd ‘c:\Program Files\Filebeat’</span><br><span class="line">.\install-service-filebeat.ps1</span><br><span class="line">5.如果系统禁止脚本执行，则需要为当前会话设置执行策略以允许脚本执行，例如：</span><br><span class="line">PowerShell.exe -ExecutionPolicy UnRestricted -File .\install-service-filebeat.ps1</span><br></pre></td></tr></table></figure><p>这是在 windows 的服务中就可以看到名为 filebeat 的服务启动项了。启动即可。</p><h3><span id="6配置文件证明连通性">6.配置文件证明连通性</span></h3><p>上述 filebeat.yml 已经配置了输出文件到 logstash 的 5044 端口。5044端口是默认端口，此端口可随意更改，只要该端口可以通就可以。如果添加端口后无法进行通讯，修改防火墙策略增加端口放行，或直接关闭防火墙测试。</p><h4><span id="61配置-logstashyml-文件">6.1配置 logstash.yml 文件：</span></h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@study ~]#vim /etc/logstash/config/logstash.yml</span><br><span class="line"><span class="meta">#</span>修改或添加：</span><br><span class="line">http.host: "127.0.0.1"  #主机通讯地址，按实际情况而定</span><br><span class="line">http.port: 9600  #开放端口，默认端口，可更改</span><br><span class="line">path.config: /etc/logstash/conf.d/*.conf #指定配置文件路径</span><br></pre></td></tr></table></figure><p>然后我们在指定路径下配置一个名为 /etc/logstash/conf.d/test.conf 的文件如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">input&#123;    #input插件指定由beats输入，且开放端口号为：5044</span><br><span class="line"> beats&#123;</span><br><span class="line">   port =&gt; 5044</span><br><span class="line"> &#125;</span><br><span class="line">&#125;</span><br><span class="line">output &#123;</span><br><span class="line">        stdout &#123;</span><br><span class="line">                codec =&gt; rubydebug  #输出到当前屏幕，调试用。后面可以关掉</span><br><span class="line">        &#125;</span><br><span class="line">        elasticsearch&#123;#输出到 elasticsearch</span><br><span class="line">   hosts =&gt; ["127.0.0.1:9200"]#elasticsearch 的主机地址和端口号</span><br><span class="line">    index =&gt; "127.0.0.1-%&#123;+YYYY.MM&#125;"#自定义索引名称，如不指定，则默认 logstash*</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4><span id="62配置elasticsearchyml">6.2配置elasticsearch.yml</span></h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span>在elasticsearch.yml添加或修改如下内容</span><br><span class="line">network.host: 127.0.0.1#主机地址</span><br><span class="line">http.port: 9200#主机开放端口</span><br></pre></td></tr></table></figure><h4><span id="63配置kibanayml">6.3配置kibana.yml</span></h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">server.port: 5601    #kibana开放端口</span><br><span class="line">server.host: "127.0.0.1"#kibana主机地址</span><br><span class="line">elasticsearch.hosts: ["http://127.0.0.1:9200"]#kibana连接到的elasticsearch的主机地址及端口号</span><br></pre></td></tr></table></figure><h3><span id="7打开kibana添加索引验证">7.打开kibana添加索引验证</span></h3><p>如果一切顺利。重启这些服务。等待都完全启动后。在 filebeat 采集的路径日志中随便输入一些文字来验证。</p><p><strong>注：要使用 echo “xxx” &gt;&gt;  /data/*.log 的形式，而不是 vim 之后添加。因为filebeat是记录着文件的 PID 号。vim 打开保存后会找不到之前的文件 PID。故会重新采集指定路径的文件，造成每次都是从头开始读行文件。而 echo 不会改变文件的 PID 号。</strong></p><p> 如果在<strong>kibana-&gt;管理-&gt;创建索引模式</strong>中可以看到你指定的名为“127.0.0.1-*”的索引。就代表 elk+filebeat 全部运行成功了。</p><p><img src="/2019/08/30/ElkDeploy/kibana_index.png" alt="7.kibana_index.png"></p><p>(我这里没有截图，偷个懒，就用公司已经在用的索引作为图片说明了)</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;ELK+filebeat日志采集（搭建篇）&lt;/p&gt;
    
    </summary>
    
      <category term="ELK" scheme="https://newpants_top/categories/ELK/"/>
    
    
      <category term="elasticsearch" scheme="https://newpants_top/tags/elasticsearch/"/>
    
      <category term="filebeat" scheme="https://newpants_top/tags/filebeat/"/>
    
      <category term="logstash" scheme="https://newpants_top/tags/logstash/"/>
    
      <category term="kibana" scheme="https://newpants_top/tags/kibana/"/>
    
  </entry>
  
  <entry>
    <title>new pants</title>
    <link href="https://newpants_top/2019/08/28/new-pants/"/>
    <id>https://newpants_top/2019/08/28/new-pants/</id>
    <published>2019-08-28T08:39:41.000Z</published>
    <updated>2019-09-25T07:48:30.132Z</updated>
    
    <content type="html"><![CDATA[<p>生命因你而火热</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;生命因你而火热&lt;/p&gt;

      
    
    </summary>
    
      <category term="测试" scheme="https://newpants_top/categories/%E6%B5%8B%E8%AF%95/"/>
    
    
      <category term="pants" scheme="https://newpants_top/tags/pants/"/>
    
  </entry>
  
</feed>
